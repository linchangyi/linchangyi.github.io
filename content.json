{"meta":{"title":"Lincy's Blog","subtitle":"归去来兮，Just Do IT.","description":null,"author":"Lincy","url":"https://lincy.online"},"pages":[{"title":"","date":"2018-02-12T11:23:30.631Z","updated":"2018-02-12T11:23:30.631Z","comments":true,"path":"about/index.html","permalink":"https://lincy.online/about/index.html","excerpt":"","text":""},{"title":"","date":"2018-02-11T11:41:50.400Z","updated":"2018-02-11T11:41:50.400Z","comments":false,"path":"categories/index.html","permalink":"https://lincy.online/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-02-11T11:41:50.404Z","updated":"2018-02-11T11:41:50.404Z","comments":false,"path":"tags/index.html","permalink":"https://lincy.online/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"分布式服务zookeeper应用场景","slug":"分布式服务zookeeper应用场景","date":"2018-09-21T16:01:26.000Z","updated":"2018-09-21T17:24:30.766Z","comments":true,"path":"2018/09/22/分布式服务zookeeper应用场景/","link":"","permalink":"https://lincy.online/2018/09/22/分布式服务zookeeper应用场景/","excerpt":"","text":"数据发布订阅/配置中心实现配置信息的集中式管理和数据的动态更新 实现配置中心有两种模式：push 、pull。 zookeeper采用的是推拉相结合的方式。 客户端向服务器端注册自己需要关注的节点。一旦节点数据发生变化，那么服务器端就会向客户端发送watcher事件通知。客户端收到通知后，主动到服务器端获取更新后的数据。 配置中心数据要求： 数据量比较小 数据内容在运行时会发生动态变更 集群中的各个机器共享配置 配置中心实现原理 负载均衡把ZooKeeper作为一个服务的注册中心，在其中登记每个服务，每台服务器知道自己是属于哪个服务，在服务器启动时，自己向所属服务进行登记，这样，一个树形的服务结构就呈现出来了 服务的调用者到注册中心里面查找：能提供所需服务的服务器列表，然后自己根据负载均衡算法，从中选取一台服务器进行连接 调用者取到服务器列表后，就可以缓存到自己内部，省得下次再取，当服务器列表发生变化，例如某台服务器宕机下线，或者新加了服务器，ZooKeeper会自动通知调用者重新获取服务器列表 由于ZooKeeper并没有内置负载均衡策略，需要调用者自己实现，这个方案只是利用了ZooKeeper的树形数据结构、watcher机制等特性，把ZooKeeper作为服务的注册和变更通知中心，解决了Nginx负载均衡方案带来的问题:（1）配置维护的成本变高，因为节点太多（2）单点故障的风险增加了，因为热点服务的访问量很高，如果这个服务集群内的负载均衡服务出现问题，这个服务将失效 分布式锁通常实现分布式锁有几种方式: redis。 setNX 存在则会返回0， 不存在 数据方式去实现, 2种方式 创建一个表， 通过索引唯一的方式create table (id , methodname …) methodname增加唯一索引insert 一条数据XXX delete 语句删除这条记录 mysql innodb select for update zookeeper实现： 排他锁客户端写入临时节点，利用节点名称不能相同的特性 共享锁 利用有序节点特性。 分布式进程在读写一个共享数据时，可以先在某个公共目录下创建一个有序子目录，然后判断该目录id是否最小。 目录id最小则获得锁并消费共享数据，然后删除该目录。否则则等待，直到自己的目录id成为最小后，才获得锁。 zookeeper所有目录操作事件都可以注册监听器，所以分布式进程不必循环查询子目录判断自己的目录id是否最小，可以注册一个监听器在前一个目录上，监听前一个目录是否被删除。 命名服务master 选举","categories":[],"tags":[]},{"title":"分布式协调服务zookeeper","slug":"分布式协调服务zookeeper","date":"2018-09-17T15:58:44.000Z","updated":"2018-09-22T14:18:22.469Z","comments":true,"path":"2018/09/17/分布式协调服务zookeeper/","link":"","permalink":"https://lincy.online/2018/09/17/分布式协调服务zookeeper/","excerpt":"分布式环境的特点 分布式 并发性程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源。数据库、分布式存储。 无序性进程间的消息通信，会出现顺序不一致的情况。","text":"分布式环境的特点 分布式 并发性程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源。数据库、分布式存储。 无序性进程间的消息通信，会出现顺序不一致的情况。 分布式面临的问题 网络通信网络本身不可靠 网络分区（脑裂）当网络发生异常导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式架构的所有节点，只有部分节点能够正常通信。 三态成功、失败、超时 分布式事务ACID（原子性、一致性、隔离性、持久性） 中心化和去中心化冷备或者热备 分布式架构里面，很多的架构思想采用的是：当集群发生故障的时候，集群中的人群会自动“选举”出一个新的领导。最典型的是： zookeeper / etcd CAP/BASE 理论CAPC（一致性Consistency）：所有节点上的数据，时刻保持一致A（可用性Availability）：每个请求都能够收到一个响应，无论响应成功或者失败P（分区容错Partition-tolerance）：表示系统出现脑裂以后，可能导致某些Server与集群中的其他机器失去联系 CP / AP CAP理论仅适用于原子读写的Nosql场景，不适用于数据库系统 BASE基于CAP理论，CAP理论并不适用于数据库事务（因为更新一些错误的数据而导致数据出现紊乱，无论什么样的数据库高可用方案都是徒劳） ，虽然XA事务可以保证数据库在分布式系统下的ACID特性，但是会带来性能方面的影响； eBay尝试了一种完全不同的套路，放宽了对事务ACID的要求。提出了BASE理论Basically available ： 数据库采用分片模式， 把100W的用户数据分布在5个实例上。如果破坏了其中一个实例，仍然可以保证80%的用户可用 soft-state： 在基于client-server模式的系统中，server端是否有状态，决定了系统是否具备良好的水平扩展、负载均衡、故障恢复等特性。Server端承诺会维护client端状态数据，这个状态仅仅维持一小段时间, 这段时间以后，server端就会丢弃这个状态，恢复正常状态 Eventually consistent：数据的最终一致性 zookeeper能做什么数据的发布/订阅（配置中心:disconf）负载均衡（dubbo利用了zookeeper机制实现负载均衡）命名服务master选举(kafka、hadoop、hbase)分布式队列分布式锁 zookeeper的特性 顺序一致性从同一个客户端发起的事务请求，最终会严格按照顺序被应用到zookeeper中。 原子性所有的事务请求的处理结果在整个集群中的所有机器上的应用情况是一致的，也就是说，要么整个集群中的所有机器都成功应用了某一事务，要么全都不应用 可靠性一旦服务器成功应用了某一个事务数据，并且对客户端做了响应，那么这个数据在整个集群中一定是同步并且保留下来的。 实时性一旦一个事务被成功应用，客户端就能够立即从服务器端读取到事务变更后的最新数据状态；（zookeeper仅仅保证在一定时间内，近实时） zookeeper 安装单机环境安装 下载zookeeper的安装包http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gz 解压zookeepertar -zxvf zookeeper-3.4.10.tar.gz cd 到 ZK_HOME/conf , copy一份zoo.cfgcp zoo_sample.cfg zoo.cfg sh zkServer.sh{start|start-foreground|stop|restart|status|upgrade|print-cmd} sh zkCli.sh -server ip:port 集群环境zookeeper集群, 包含三种角色: leader / follower /observer observer 是一种特殊的zookeeper节点。可以帮助解决zookeeper的扩展性（如果大量客户端访问我们zookeeper集群，需要增加zookeeper集群机器数量。从而增加zookeeper集群的性能。 导致zookeeper写性能下降， zookeeper的数据变更需要半数以上服务器投票通过。造成网络消耗增加投票成本） observer不参与投票。 只接收投票结果。 不属于zookeeper的关键部位。 集群配置 每一行此配置表示一个集群中的一台服务器。其中id为Server ID，用来标识该机器在集群中的编号。同时，在所在服务器的数据目录（/tmp/zookeeper）下创建一个myid文件，该文件只有一行内容，并且是一个数字，就是对应每台服务器的Server ID数字。 比如server.1=IP1:2888:3888的myid中的内容就是1。不同服务器的ID需要保持不同，并且和zoo.cfg文件中server.id中的id和myid文件的内容保持一致。id的取值范围为1~255。 其中，server.id中配置参数的第一个port是集群中其他机器与Leader之间通信的端口，第二个port为当Leader宕机或其他故障时，集群进行重新选举Leader时使用的端口。 按照以上相同步骤，配置集群中的其他机器。每个集群的zoo.cfg文件都是相同的，可通过版本控制或其他工具保证每台zookeeper服务器的配置文件相同。集群中每台机器唯一不同的是server.id对应的myid文件中的数字不同。server.id=host:port:portid的取值范围： 1~255； 用id来标识该机器在集群中的机器序号2182是follower节点与leader节点交换信息的端口号；3181表示leader节点挂掉了, 需要一个端口来重新选举。 server.1=192.168.11.129:2182:3181server.2=192.168.11.131:2182:3181server.3=192.168.11.135:2182:3181 observer配置 peerType=observerserver.1=192.168.11.129:2182:3181:observerserver.2=192.168.11.131:2182:3181server.3=192.168.11.135:2182:3181 zoo.cfg tickTime=2000 zookeeper中最小的时间单位长度 （ms） initLimit=10 follower节点启动后与leader节点完成数据同步的时间 syncLimit=5 leader节点和follower节点进行心跳检测的最大延时时间 dataDir=/tmp/zookeeper 表示zookeeper服务器存储快照文件的目录 dataLogDir 表示配置 zookeeper事务日志的存储路径，默认指定在dataDir目录下 clientPort 表示客户端和服务端建立连接的端口号： 2181 zookeeper 的一些概念zookeeper的数据模型和文件系统类似，每一个节点称为：znode. 是zookeeper中的最小数据单元。每一个znode上都可以 保存数据和挂载子节点。 从而构成一个层次化的属性结构 节点特性： 持久化节点 ： 节点创建后会一直存在zookeeper服务器上，直到主动删除 持久化有序节点 ：每个节点都会为它的一级子节点维护一个顺序 临时节点 ： 临时节点的生命周期和客户端的会话保持一致。当客户端会话失效，该节点自动清理 临时有序节点 ： 在临时节点上多了一个顺序性特性 zookee 的命令操作 create [-s] [-e] path data acl-s 表示节点是否有序-e 表示是否为临时节点默认情况下，是持久化节点 ACL zookeeper提供控制节点访问权限的功能，用于有效的保证zookeeper中数据的安全性。避免误操作而导致系统出现重大事故。 CREATE /READ/WRITE/DELETE/ADMIN get path [watch]获得指定 path的信息 Watcherzookeeper提供了分布式数据发布/订阅,zookeeper允许客户端向服务器注册一个watcher监听。当服务器端的节点触发指定事件的时候会触发watcher。服务端会向客户端发送一个事件通知 watcher的通知是一次性，一旦触发一次通知后，该watcher就失效 set path data [version]修改节点 path对应的data乐观锁的概念数据库里面有一个 version 字段去控制数据行的版本号 delete path [version]删除节点 stat信息cversion = 0 子节点的版本号aclVersion = 0 表示acl的版本号，修改节点权限dataVersion = 1 表示的是当前节点数据的版本号 czxid 节点被创建时的事务IDmzxid 节点最后一次被更新的事务IDpzxid 当前节点下的子节点最后一次被修改时的事务ID ctime = Sat Aug 05 20:48:26 CST 2017mtime = Sat Aug 05 20:48:50 CST 2017 cZxid = 0x500000015ctime = Sat Aug 05 20:48:26 CST 2017mZxid = 0x500000016mtime = Sat Aug 05 20:48:50 CST 2017pZxid = 0x500000015cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0 创建临时节点的时候，会有一个sessionId 。 该值存储的就是这个sessioniddataLength = 3 数据值长度numChildren = 0 子节点数 Java API权限控制模式schema：授权对象ip : 192.168.1.1Digest : username:passwordworld : 开放式的权限控制模式，数据节点的访问权限对所有用户开放。 world:anyonesuper ：超级用户，可以对zookeeper上的数据节点进行操作 连接状态KeeperStat.Expired 在一定时间内客户端没有收到服务器的通知， 则认为当前的会话已经过期了。KeeperStat.Disconnected 断开连接的状态KeeperStat.SyncConnected 客户端和服务器端在某一个节点上建立连接，并且完成一次version、zxid同步KeeperStat.authFailed 授权失败事件类型NodeCreated 当节点被创建的时候，触发NodeChildrenChanged 表示子节点被创建、被删除、子节点数据发生变化NodeDataChanged 节点数据发生变化NodeDeleted 节点被删除None 客户端和服务器端连接状态发生变化的时候，事件类型就是None zookeeper的实际应用场景 订阅发布 watcher机制 统一配置管理（disconf） 分布式锁 redis zookeeper 数据库 负载均衡 ID生成器 分布式队列 统一命名服务 master选举 master选举 zookeeper 集群角色 leader 事务请求的唯一调度者和处理者，保证集群事务处理的顺序性 集群内部各个服务器的调度者 follower 处理客户端非事务请求，以及转发事务请求给leader服务器 参与事务请求提议（proposal）的投票（客户端的一个事务请求，需要半数服务器投票通过以后才能通知leader commit； leader会发起一个提案，要求follower投票） 参与leader选举的投票 observer观察zookeeper集群中最新状态的变化并将这些状态同步到observer服务器上。增加observer不影响集群中事务处理能力，同时还能提升集群的非事务处理能力 zookeeper 集群组成一般由2n+1太服务器组成 leader选举三种算法： leaderElection AuthFastLeaderElection FastLeaderElection（默认） FastLeaderElection 选举流程几个概念: serverid : 在配置server集群的时候，给定服务器的标识id（myid） zxid : 服务器在运行时产生的数据ID， zxid的值越大，表示数据越新 Epoch: 选举的轮数 server的状态：Looking、 Following、Observering、Leading 选举流程，第一次初始化启动的时候服务器状态为Looking 所有在集群中的server都会 推荐自己为leader，然后 把（myid、zxid、epoch）作为广播信息，广播给集群中的其他server, 然后 等待其他服务器返回 每个服务器都会 接收来自集群中的其他服务器的投票。集群中的每个服务器在接受到投票后，开始判断投票的有效性 判断逻辑时钟(Epoch) ，如果Epoch大于自己当前的Epoch，说明自己保存的Epoch是过期。更新Epoch，同时clear其他服务器发送过来的选举数据。判断是否需要更新当前自己的选举情况 如果Epoch小于目前的Epoch，说明对方的epoch过期了，也就意味着对方服务器的选举轮数是过期的。这个时候，只需要讲自己的信息发送给对方 如果epoch等于目前的epoch，根据规则来判断是否有资格获得leader 接收来自其他服务器的投票后，针对每一个投票，都需要将别人的投票和自己的投票进行PK zxid，zxid最大的服务器优先","categories":[],"tags":[]},{"title":"分布式通信协议-HTTP","slug":"分布式通信协议-HTTP","date":"2018-08-30T15:34:31.000Z","updated":"2018-09-22T02:55:36.746Z","comments":true,"path":"2018/08/30/分布式通信协议-HTTP/","link":"","permalink":"https://lincy.online/2018/08/30/分布式通信协议-HTTP/","excerpt":"HTTP协议概述 客户端和服务端","text":"HTTP协议概述 客户端和服务端 资源html/文本、word、avi等等 媒体类型MIME类型。text/html、image/jpeg、application/json等等 URI和URLURI：服务器资源的名字。index.htmlURL:网络资源描述 http://lincy.online/2018/08/30/分布式通信协议-HTTP schema: http/https/ftp host: web服务器的IP地址或域名。 path: 资源访问路径。 query-string: 查询参数。 method，方法get/put/delete/post/patch/head 报文 状态码 1XX 提示信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器端的错误 缓存 HTTPShttps工作原理 第一步，使用对称加解密 第二步，密钥是公开的，所有的客户端都可以拿到 第三步 针对不同的客户端使用不同的密钥 问题：协商过程是没有加密的，所以还会出现被截断的问题 第四步：使用非对称加密（公钥、私钥） 客户端如何拿到公钥： 服务器端把公钥发送给每一个客户端 服务器端把公钥放到远程服务器，客户端可以请求到 让浏览器保存所有的公钥（不现实） 第五步 公钥被调包的问题按照上面的方案，永远存在。 第六步：使用第三方机构来解决 通过第三方机构，使用第三方机构的私钥对我们【需要传输的公钥】进行加密 问题：数字证书有可能颁发给了窃密者 第七步：数字证里面包含的内容： 公司信息、网站信息、数字证书的算法、公钥 http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html https握手过程： 客户端发起一个https请求a) 客户端支持的加密方式b) 客户端生成的随机数（第一个随机数）c) 协议版本号 服务端收到请求后，拿到随机数，返回a) 证书（颁发机构（CA）、证书内容本身的数字签名（使用第三方机构的私钥加密）、证书持有者的公钥、证书签名用到的hash算法）b) 生成一个随机数，返回给客户端（第二个随机数） 客户端拿到证书以后做验证a) 根据颁发机构找到本地的跟证书b) 根据CA得到根证书的公钥，通过公钥对数字签名解密，得到证书的内容摘要 Ac) 用证书提供的算法对证书内容进行摘要，得到摘要 Bd) 通过A和B的对比，也就是验证数字签名 验证通过以后，生成一个随机数（第三个随机数），通过证书内的公钥对这个随机数加密，发送给服务器端 （随机数1+2+3）通过对称加密得到一个密钥。（会话密钥） 通过会话密钥对内容进行对称加密传输 RESTful 在REST中，一切的内容都被认为是一种资源 每个资源都由URI唯一标识 使用统一的接口处理资源请求（POST/GET/PUT/DELETE/HEAD） 无状态","categories":[],"tags":[]},{"title":"分布式通信-序列化","slug":"分布式通信-序列化","date":"2018-08-30T14:06:59.000Z","updated":"2018-08-30T15:34:00.853Z","comments":true,"path":"2018/08/30/分布式通信-序列化/","link":"","permalink":"https://lincy.online/2018/08/30/分布式通信-序列化/","excerpt":"Java序列化机制 —— Serialize接口 数据结果大、传输效率低 不能跨语言","text":"Java序列化机制 —— Serialize接口 数据结果大、传输效率低 不能跨语言 如何实现Java序列化操作： 实现Serializable接口 ObjectInputStream： 读取字节数据转换成对象 ObjectOuputStream： 将对象转换成直接数据 serialVersionUID的作用：保证序列化的对象和反序列化后的对象是同一个，对类的签名。 transient 关键字：不参与序列化。父子类问题如果父类没有实现序列化，而子类实现列序列化。那么父类中的成员没办法做序列化操作 序列化的存储规则对同一个对象进行多次写入，打印出的第一次存储结果和第二次存储结果，只多了5个字节的引用关系, 并不会导致文件累加。 XML对象序列化 跨语言，容易理解 基于XML的SOAP协议和对应的WebService框架在很长一段时间成为主流的技术。 基于JSON的HTTP REST接口 相比XML更简单易用，基本上取代了复杂的Web Service接口，成为分布式框架中远程通信的首要选择。 仍然存在占用空间大、性能低的问题。 主流的序列化技术 JSON XML Protobuf 字节数小 速度快 Hessian 序列化速度比protobuf更快，但是字节数更大 ProtoStuff MsgPack thrift FST Avro","categories":[],"tags":[]},{"title":"分布式通信协议","slug":"分布式通信协议","date":"2018-08-29T18:26:33.000Z","updated":"2018-08-30T15:04:54.535Z","comments":true,"path":"2018/08/30/分布式通信协议/","link":"","permalink":"https://lincy.online/2018/08/30/分布式通信协议/","excerpt":"网络协议tcp/ip TCP五层模型 OSI七层 OSI模型多了表达层、会话层","text":"网络协议tcp/ip TCP五层模型 OSI七层 OSI模型多了表达层、会话层 tcp三次握手 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手协议三次握手耳熟能详，四次挥手估计就听得比较少了，所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。 udp协议tcp通信原理首先，对于TCP通信来说，每个TCP Socket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态。 接收缓冲区把数据缓存到内核，若应用进程一直没有调用Socket的read方法进行读取，那么该数据会一直被缓存在接收缓冲区内。不管进程是否读取Socket，对端发来的数据都会经过内核接收并缓存到Socket的内核接收缓冲区。read索要做的工作，就是把内核接收缓冲区中的数据复制到应用层用户的Buffer里。 进程调用Socket的send发送数据的时候，一般情况下是讲数据从应用层用户的Buffer里复制到Socket的内核发送缓冲区，然后send就会在上层返回。换句话说，send返回时，数据不一定会被发送到对端。 滑动窗口协议发送方和接收方都会维护一个数据帧的序列，这个序列被称作窗口。发送方的窗口大小由接收方确认，目的是控制发送速度，以免接收方的缓存不够大导致溢出，同时控制流量也可以避免网络拥塞。下面图中的4,5,6号数据帧已经被发送出去，但是未收到关联的ACK，7,8,9帧则是等待发送。可以看出发送端的窗口大小为6，这是由接受端告知的（事实上必须考虑拥塞窗口cwnd，这里暂且考虑cwnd&gt;rwnd）。此时如果发送端收到4号ACK，则窗口的左边缘向右收缩，窗口的右边缘则向右扩展，此时窗口就向前“滑动了”，即数据帧10也可以被发送 明白了Socket读写数据的底层原理，我们就很容易理解“阻塞模式”：对于读取Socket数据的过程而言，如果接收缓冲区为空，则调用Socket的read方法的线程会阻塞，知道有数据进入接收缓冲区；而对于写数据到Socket中的线程来说，如果待发送的数据长度大于发送缓冲区空余长度，则会阻塞在write方法上，等待发送缓冲区的报文被发送到网络上，然后继续发送下一段数据，循环上述过程直到数据都被写入到发送缓冲区为止 从前面分析的过程来看，传统的Socket阻塞模式直接导致每个Socket都必须绑定一个线程来操作数据，参与通信的任意一方如果处理数据的速度较慢，会直接拖累到另一方，导致另一方的线程不得不浪费大量的时间在I/O等待上，所以这就是Socket阻塞模式的“缺陷”。 但是这种模式在少量的TCP连接通信的情况下，双方都可以快速的传输数据，这个时候的性能是最高的。 BIO（同步阻塞）NIO（同步非阻塞）AIO（异步非阻塞） Multicst(组播) 单播 广播 组播 java api socket操作","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://lincy.online/tags/分布式/"}]},{"title":"分布式架构概述","slug":"分布式架构概述","date":"2018-08-29T17:00:40.000Z","updated":"2018-08-30T15:04:38.554Z","comments":true,"path":"2018/08/30/分布式架构概述/","link":"","permalink":"https://lincy.online/2018/08/30/分布式架构概述/","excerpt":"特点：高并发、海量数据什么是分布式 任务分解 节点通信","text":"特点：高并发、海量数据什么是分布式 任务分解 节点通信 分布式架构发展第一版 第二版单机负载越来越高，数据库和应用服务器分离 第三版应用服务器做集群 引入问题: session共享 session sticky session replication session 集中存储（db、缓存） cookie (保存在cookie，不保存在服务端) access_token(userid/token/timestamp) 请求转发第四版数据库高性能操作 引入问题： 数据库读写分离 数据库的数据同步 数据库路由（mycat） 第五版 引入问题： 搜索引擎的索引数据同步？实时增量同步？定时全量同步? 第六版用户无上限，解决方式： 缓存 限流 降级 第七版数据库的水平/垂直拆分 第八版应用拆分 SOA 微服务","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://lincy.online/tags/分布式/"}]},{"title":"HashMap源码解析","slug":"HashMap源码解析","date":"2018-07-12T12:08:26.000Z","updated":"2018-07-17T17:10:27.403Z","comments":true,"path":"2018/07/12/HashMap源码解析/","link":"","permalink":"https://lincy.online/2018/07/12/HashMap源码解析/","excerpt":"","text":"本文基于JDK1.8 HashMap 数据结构在JDK1.8中HashMap进行了优化，桶除了链表，还新增了红黑树的数据结构，加快查找速度 类声明 HashMap 构造函数 initialCapacity：初始容量。 loadFactor（默认值为0.75）：负载因子。负载因子表示哈希表在扩充容量之前可以达到多满的尺度，负载因子越大，填充程度越高。 public HashMap() public HashMap(int initialCapacity) public HashMap(int initialCapacity, float loadFactor) 看一下第三个构造函数： public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } shreshold指HashMap容量达到多少时，HashMap会扩容，根据以上描述，可以很简单的认为 shreshold = capacity * loadFactor。 在初始化HashMap时shreshold先被赋值为initial capacity。 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } put方法 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&#39;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 如果HashMap为空，则初始化 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } resize()方法初始化表大小或扩容 final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // capacity &gt; 0 的情况，对应需要扩容的情景 if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { // 如果原先容量已经到了最大值，则无法扩容，直接返回 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // shreshold翻倍 newThr = oldThr &lt;&lt; 1; } // capacity==0的情况，HashMap刚刚经过初始化还没有值的情景 else if (oldThr &gt; 0) // 构造函数（2）（3）初始化HashMap时threshold被设定为initialCapacity newCap = oldThr; else { // zero initial threshold signifies using defaults //threshold==0, 使用默认配置，对应无参构造函数（1）的情景 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) // 桶中只有一个元素 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 桶为红黑树 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order // 桶为数组 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; }","categories":[],"tags":[{"name":"JDK源码","slug":"JDK源码","permalink":"https://lincy.online/tags/JDK源码/"}]},{"title":"深入理解JVM-（5）Class文件的结构","slug":"深入理解JVM-（5）Class文件的结构","date":"2018-04-03T08:18:40.000Z","updated":"2018-07-17T17:10:27.415Z","comments":true,"path":"2018/04/03/深入理解JVM-（5）Class文件的结构/","link":"","permalink":"https://lincy.online/2018/04/03/深入理解JVM-（5）Class文件的结构/","excerpt":"Class文件结构","text":"Class文件结构 magic魔数，4个字节，表明这是一个Class文件，0xCAFEBABE 版本号minor_version，major_version各两个字节 Class文件版本号 常量池constant_pool_count，u2常量池容量计数（从1开始），第0项表达“不引用任何一个常量池项目”。如:0x0016(十进制的22)标识有21常量，索引值范围为1~21. constant_pool 字面量(Literal) 接近于Java语言的常量概念，如文本字符串、final的常量值 符号引用 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 常量池的项目类型 例子（下图）： 0x07从上图可知为：CONSTANT_Class_info类型常量。而COMSTANT_Class_info的结构如下图，tag就是0x07，name_index（代表这个类或接口的全限定名）（0x0002）指向常量池的第二项。 看第二项的tag标识0x01，从上面的常量池的类型图可以看出，此项为CONSTANT_UTF8_info。CONSTANT_Utf8_info的结构如下： 所以第二项的内容三部分如下: 第三部分的utf编码转换为字符串为org/fenixsoft/clazz/TestClass，就是第一个常量（CONSTANT_Class_info）的值。 以此类推，可以得到所有的常量的值。 可以使用javap工具输出TestClass.class的文件字节码内容（省略了常量池意外的信息）： 常量池的14种常量的结构： 访问标志在常量池结束后，紧接着2个字节代表访问标志，用于识别类或接口层次的访问信息。 access_flags一共有16个标志位可用，当前只定义了其中8个。 类索引、父类索引与接口索引集合 类索引、父类索引是一个u2类型的数据（只能继承一个父类），指向一个Constant_class_info常量，通过constant_class_info常量中的索引值找到定义在constant_utf8_info中的全限定名字符串。 接口索引集合是一组u2类型的数据（可以实现多个接口）。入口的第一项——一个u2类型的数据标识接口索引的数量。如果没有实现任何接口，则计数器为0。 字段表集合在所有字段表之前有一个u2类型的数据fields_count为字段计数器，表示这个类有多少字段。 字段表（field_info），描述接口或者类中声明的变量。 字段表结构 access_flags: 标志位，如下图 字段访问标志 name_index（简单名称）和descriptor_index（描述符）都是对常量池的引用。inc()方法和m字段的简单名称分别是inc和m。描述符比较复杂，用来描述字段的数据类型、方法的参数列表（包括数量、类型、顺序）和返回值。 描述符标识字符含义 举几个例子： int[]的描述符为[I。（[表示数组） java.lang.String[][]的描述符为：[[Ljava/lang/String; 方法void inc()的描述符为()V 方法java.lang.String toString()的描述符为()Ljava/lang/String; 方法int indexOf(char[]source,int sourceOffset,int sourceCount,char[]target,int targetOffset,int targetCount,int fromIndex)的描述符为([CII[CIII)I 还有一部分是属性表集合，attribute_info，将在下面介绍。 方法表集合基本上同字段表结合一样。在字段表集合里已经有涉及。 属性表集合虚拟机规范预定义的属性（Java SE 7） 虚拟机预定义的属性类型(1) 虚拟机预定义的属性类型(2) 属性表结构","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（4）内存分配与回收策略","slug":"深入理解JVM-（4）内存分配与回收策略","date":"2018-03-15T09:13:09.000Z","updated":"2018-07-17T17:10:27.414Z","comments":true,"path":"2018/03/15/深入理解JVM-（4）内存分配与回收策略/","link":"","permalink":"https://lincy.online/2018/03/15/深入理解JVM-（4）内存分配与回收策略/","excerpt":"对象优先分配在Eden","text":"对象优先分配在Eden 使用JDK7实验新生代的GC： public class CH03_05 { private static final int _1MB = 1024 * 1024; /** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC */ public static void testAllocation() { byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; // 出现一次Minor GC allocation4 = new byte[4 * _1MB]; } public static void main(String args[]) { testAllocation(); } } gc日志如下： [GC[DefNew: 7801K-&gt;524K(9216K), 0.0050620 secs] 7801K-&gt;6668K(19456K), 0.0050979 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 5034K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 55% used [0x00000000f9a00000, 0x00000000f9e67560, 0x00000000fa200000) from space 1024K, 51% used [0x00000000fa300000, 0x00000000fa3832f0, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2970K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 13% used [0x00000000fae00000, 0x00000000fb0e6a58, 0x00000000fb0e6c00, 0x00000000fc2c0000) allocation1、2、3在Eden区占用了6M的空间。在分配allocation4时，发现新生代无法容纳，发生一次Minor GC。而survivor区无法并无法容纳2M的大小，因此将allocation1、2、3移动到老年代。gc后，将allocation4分配eden区。 大对象直接进入老年代-XX:PretenureSizeThreshold=3145728 ：大于3M的对象直接进入老年代 长期存活的对象直接进入老年代 private static final int _1MB = 1024 * 1024; /** * VM参数：-verbose:gc -Xms40M -Xmx40M -Xmn20M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 * -XX:+PrintTenuringDistribution */ @SuppressWarnings(&quot;unused&quot;) public static void testTenuringThreshold() { byte[] allocation1, allocation2, allocation3; allocation1 = new byte[_1MB / 4]; // 什么时候进入老年代决定于XX:MaxTenuringThreshold设置 allocation2 = new byte[8 * _1MB]; allocation3 = new byte[8 * _1MB]; allocation3 = null; allocation3 = new byte[8 * _1MB]; } public static void main(String[] args) { testTenuringThreshold(); } MaxTenuringThreshold=1，第一回收，allocation1依然在新生代（新生代占用784K）；第二次回收，allocation1已经转移到老年代（新生代0K）: [GC[DefNew Desired survivor size 1048576 bytes, new threshold 1 (max 1) - age 1: 804672 bytes, 804672 total : 10432K-&gt;785K(18432K), 0.0059603 secs] 10432K-&gt;8977K(38912K), 0.0059928 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC[DefNew Desired survivor size 1048576 bytes, new threshold 1 (max 1) - age 1: 760 bytes, 760 total : 9643K-&gt;0K(18432K), 0.0023646 secs] 17835K-&gt;8975K(38912K), 0.0023892 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 18432K, used 8468K [0x00000000f8600000, 0x00000000f9a00000, 0x00000000f9a00000) eden space 16384K, 51% used [0x00000000f8600000, 0x00000000f8e45000, 0x00000000f9600000) from space 2048K, 0% used [0x00000000f9600000, 0x00000000f96002f8, 0x00000000f9800000) to space 2048K, 0% used [0x00000000f9800000, 0x00000000f9800000, 0x00000000f9a00000) tenured generation total 20480K, used 8975K [0x00000000f9a00000, 0x00000000fae00000, 0x00000000fae00000) the space 20480K, 43% used [0x00000000f9a00000, 0x00000000fa2c3ce8, 0x00000000fa2c3e00, 0x00000000fae00000) compacting perm gen total 21248K, used 3098K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb106b08, 0x00000000fb106c00, 0x00000000fc2c0000) 如果设置MaxTenuringThreshold=15(默认为15), 第二次gc新生代仍然有784K: [GC[DefNew Desired survivor size 1048576 bytes, new threshold 15 (max 15) - age 1: 804672 bytes, 804672 total : 10432K-&gt;785K(18432K), 0.0061502 secs] 10432K-&gt;8977K(38912K), 0.0061935 secs] [Times: user=0.02 sys=0.02, real=0.01 secs] [GC[DefNew Desired survivor size 1048576 bytes, new threshold 15 (max 15) - age 1: 968 bytes, 968 total - age 2: 802008 bytes, 802976 total : 9643K-&gt;784K(18432K), 0.0015832 secs] 17835K-&gt;8976K(38912K), 0.0016100 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 18432K, used 9252K [0x00000000f8600000, 0x00000000f9a00000, 0x00000000f9a00000) eden space 16384K, 51% used [0x00000000f8600000, 0x00000000f8e45000, 0x00000000f9600000) from space 2048K, 38% used [0x00000000f9600000, 0x00000000f96c40a0, 0x00000000f9800000) to space 2048K, 0% used [0x00000000f9800000, 0x00000000f9800000, 0x00000000f9a00000) tenured generation total 20480K, used 8192K [0x00000000f9a00000, 0x00000000fae00000, 0x00000000fae00000) the space 20480K, 40% used [0x00000000f9a00000, 0x00000000fa200010, 0x00000000fa200200, 0x00000000fae00000) compacting perm gen total 21248K, used 3098K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb106b08, 0x00000000fb106c00, 0x00000000fc2c0000) 空间分配担保发生MinorGC之前，检查老年代可用连续空间是否大于新生代的所有对象总空间。 是，那么MinorGC可以确保是安全的 否。 查看HandlePromotionFailure设置值是否允许担保失败。 允许。检查老年代最大连续空间是否大于历次晋升到老年代对象的平均大小： 大于，尝试进行一次MinorGC，尽管是有风险的。 小于，直接FullGC 不允许。FullGC。 JDK6 Update24之后，HandlePromotionFailure不再起作用，只要老年代最大连续空间大于新生代对象总大小或历次平均大小，就进行MinorGC","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（3）GC算法","slug":"深入理解JVM-（3）GC算法","date":"2018-03-02T13:02:17.000Z","updated":"2018-07-17T17:10:27.413Z","comments":true,"path":"2018/03/02/深入理解JVM-（3）GC算法/","link":"","permalink":"https://lincy.online/2018/03/02/深入理解JVM-（3）GC算法/","excerpt":"标记清除算法标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象","text":"标记清除算法标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 缺点： 效率低 产生大量不连续的内存碎片 复制算法将内存分为大小相等的两块，每次只使用其中的一块。当一块用完了，就将或者的对象复制到另外一块上面，然后把另一块一次清理掉 优点： 简单效率高 不产生内存碎片 缺点：浪费了一半的内存空间 新生代就是用这种算法来回收对象的，不过新生代的对象大多存活时间都很短（98%活不过下一次gc），所以不要按1：1的比例来划分内存空间，而是： 将内存分为一块较大的Eden空间和两块较小的Survior空间（默认是8：1，这样只浪费10%的空间），每次使用Eden和其中的一块Survior。 回收时，将Eden和Survior中还存活着的对象一次性拷贝到另一块Survior上，最后清理掉Eden和刚刚的Survior。 但是没办法保证每次都只有10%的对象存活，有时还需要以来其他内存（老年代）分配担保。如果一块Survior无法容纳一次新生代gc存活下来的对象，那么这些对象将直接进入老年代 标记-整理算法标记-整理算法适用于存活率较高的老年代。(不适用复制算法，存活率高要复制的内存多，且浪费的空间大) 标记过程和标记清除算法一样，后续步骤让所有存活的对象都向一端移动，然后清理掉边界以外的内存 分代收集算法根据各个年特点代采用合适的清除算法：新生代采用复制算法，老年代采用标记-清除算法。 垃圾收集器 连线表明它们可以搭配使用 Serial收集器最基本最悠久的收集器，单线程收集器，新生代采用复制算法。gc时，必须暂停其他所有的工作线程（Stop The World）。单个CPU环境下，效率较高，对于运行在Client模式下的虚拟机是个好选择。 ParNew收集器Serial收集器的多线程版本 Parallel Scavenge收集器 是一个新生代收集器，采用复制算法 关注点与其他收集器不同，CMS等收集器关注的是尽可能地缩短垃圾收集时用户线程的等待时间，而Parallel Scavenge收集器目的是达到一个可控制的吞吐量（throughput=运行用户代码时间/(运行用户代码时间+垃圾收集时间)）。 停顿时间短适合与用户交互的程序；而高吞吐量可以最高效率的利用cpu时间，适合后台运算而不需要太多交互的任务。 两个参数： -XX：MaxGCPauseMillis，最大垃圾收集停顿时间（尽力保证） -XX：GCTimeRatio，吞吐量大小 -XX：+UseAdaptiveSizePolice，开关参数，不需要手工指定新生代大小（-Xmn）、Eden和Survior的比例（-XX:SurviorRatio）、晋升老年代对象年龄（-XX：PretenureSizeThreshold）等细节参数，虚拟机会根据收集的系统性能信息，动态调整这些参数。如果对虚拟机不熟，可以打开这个开关，然后使用MaxGCPauseMillis或GCTimeRatio给虚拟机设立一个优化目标，具体细节参数调节由虚拟机完成。 Serial Old收集器Serial收集器的老年代版本 Parallel Old收集器Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。 CMS收集器（Concurrent Mark Sweep）以获取最短回收停顿时间为目标的收集器，重视服务的相应速度，符合B/S系统服务端的需求。基于标记-清除算法（Mark Sweep）。分为四个步骤： 初始标记 标记GC Roots能直接关联到的对象，速度很快（stop the world） 并发标记 进行GC Roots Tracing 重新标记 修正并发标记阶段期间，用户程序继续运行而导致标记产生变动的那一部分对象的标记记录（stop the world） 并发清除 整个过程耗时最长的并发标记和并发清除过程，收集线程可以和用户线程一起工作，总体上cms收集器的回收过程是与用户线程一起并发地执行的。 CMS收集器 CMS收集器仍然有三个显著的缺点： 对cpu资源非常敏感 默认回收线程数=（cpu数量+3）/4，当cpu数量&gt;=4时，收集线程占用的cpu资源&lt;25%；但是当cpu资源不足4时，比如2，那么回收线程将占用50%的cpu资源，导致用户线程速度降低50%。 无法处理浮动垃圾（Floating Garbage，并发清理阶段，用户线程产生的新垃圾），可能出现“concurrent mode failure”而导致另一次Full GC的产生。由于垃圾收集阶段用户线程仍然在运行，所以需要预留空间提供程序运作使用。因此默认设置下，CMS在老年代使用了68%的空间后就会被激活（-XX:CMSInitiatingOccuPancyFraction参数可以用来设置这个比例值）。如果应用老年代增长不是很快，可以提高出发百分比，以便降低内存回收次数获得更好性能。要是CMS运行期间预留的内存空间无法满足程序需求，就会出现一次“Concurrent Mode Failure”，这时候虚拟机会临时启用Serial Old收集器来重新进行老年代的收集，这样停顿时间就更长了。因此-XX：CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量“Concurrent Mode Failure”，降低性能。 标记-清除算法，产生大量空间碎片，往往出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间，从而触发Full GC。CMS提供了一个-XX：+UseCMSCompactAtFullCollection开关参数，用于在Full GC后二外进行一个碎片整理过程，但停顿时间变常了。因此还提供了另一个参数-XX：CMSFullGCsBeforeComapction，用于设置执行多少次Full GC后，跟着来一次压缩。 G1收集器基于标记-整理算法，不会产生空间碎片。可以非常精确控制停顿，可以明确指定在一个长度为M毫秒的时间片段内，消耗在GC的时间不超过N好眠。 G1收集器，避免了全区域的垃圾收集（前面介绍的都是全区域的垃圾收集），它将整个Java堆划分为多个大小固定的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个优先队列，每次根据允许的收集时间，优先回收垃圾最多的区域（Garbage First）。区域划分有优先级的区域回收，保证了G1收集器在有限的时间内可以获得最高的收集效率。 GC常用参数总结 CMS收集器","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（2）垃圾回收, 对象已死？","slug":"深入理解JVM-（2）垃圾回收","date":"2018-03-02T09:06:31.000Z","updated":"2018-07-17T17:10:27.410Z","comments":true,"path":"2018/03/02/深入理解JVM-（2）垃圾回收/","link":"","permalink":"https://lincy.online/2018/03/02/深入理解JVM-（2）垃圾回收/","excerpt":"引用计数法算法：引用计数为0即为死对象缺陷: 无法解决循环引用的问题，JDK不采用这种方法。","text":"引用计数法算法：引用计数为0即为死对象缺陷: 无法解决循环引用的问题，JDK不采用这种方法。 根搜索算法根对象——GC Roots： 虚拟机栈中引用的对象（栈帧中的本地变量表） 方法去中的静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（Native方法）的引用的对象 不能从GC Roots追溯到的对象，为可回收的对象。 引用 强引用 类似 “Object obj = new Object()”，只要强引用还在，就不会被回收 软引用 JDK中提供的SoftReference类——还有用，但并非必须的对象。在内存溢出之前，会把软引用对象列进回收范围，进行二次回收，如果还是没有足够的内存，才会抛出内存溢出异常。 弱引用 WeakReference——非必需对象，只能生存到下一次垃圾收集之前。无论当前内存是否足够，都会回收掉弱引用对象。 虚引用 PhantomReference——完全不会对对象的生存构成影响，也无法通过其获取对象实例，唯一的目的是对象被垃圾回收时收到一个系统通知。 生还是死根搜索算法中不可达的对象，并非“非死不可”，可以通过finalize()方法自救： finalize执行流程 不建议使用finalize(), 应使用try-finally, 更好更及时。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（1）Java内存结构","slug":"深入理解JVM-（1）Java内存结构","date":"2018-03-02T07:50:26.000Z","updated":"2018-07-17T17:10:27.409Z","comments":true,"path":"2018/03/02/深入理解JVM-（1）Java内存结构/","link":"","permalink":"https://lincy.online/2018/03/02/深入理解JVM-（1）Java内存结构/","excerpt":"运行时数据区域","text":"运行时数据区域 程序计数器线程私有， 当前线程所执行的字节码的行号指示器，可以通过改变这个计数器的值来选取吓一跳需要执行的字节码指令。 虚拟机栈线程私有，生命周期与线程相同。描述Java方法执行的内存模型，每个方法被执行都会创建一个栈帧用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法从调用到执行完成的过程，对应一个栈帧再虚拟机栈中从入栈到出栈的过程。 如果请求的栈深度超过虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈动态扩展无法申请得到足够的内存，将会排除OutOfMemoryError。 本地方法栈跟虚拟机栈类似，本地方法栈服务于Native方法 Java堆被所有线程共享，目的是存放对象实例(对象实例不一定都分配在Java堆上，也可能在栈上——逃逸分析、栈上分配)。 GC的主要区域。通过-Xms和-Xmx控制扩展大小，无法扩展时，抛出OutOfMemoryError。 方法区线程共享，存储类信息、常量、静态变量、即时编译器编译后的代码等数据。习惯称为永久代。垃圾收集在这个区域较少出现，但数据也并非“永久”存在。 可能会抛出OutOfMemoryError。典型场景如Spring和Hibernate对类增强时，用到CGLib字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以载入内存。 运行时常量池属于方法区的一部分，存放编译器生成的各种字面量和符号引用。 直接内存堆外内存。NIO基于通道（channel）与缓冲区（buffer），使用Nativ函数直接分配堆外内存。因为避免了在Java堆和Navite堆中来回复制数据，所以可以提高性能。 对象的引用两种方式: 通过句柄 通过直接指针 直接指针速度优于句柄方式，因为少了一次寻址。Sun HotSpot（JDK默认）采用直接指针方式。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"New Year's Day","slug":"New-Year-s-Day","date":"2018-02-15T16:35:59.000Z","updated":"2018-02-16T06:25:45.952Z","comments":true,"path":"2018/02/16/New-Year-s-Day/","link":"","permalink":"https://lincy.online/2018/02/16/New-Year-s-Day/","excerpt":"","text":"2018I will be with you againI will begin again","categories":[{"name":"生活","slug":"生活","permalink":"https://lincy.online/categories/生活/"}],"tags":[]},{"title":"责任链模式","slug":"责任链模式","date":"2018-02-13T05:25:29.000Z","updated":"2018-02-13T15:10:50.721Z","comments":true,"path":"2018/02/13/责任链模式/","link":"","permalink":"https://lincy.online/2018/02/13/责任链模式/","excerpt":"","text":"/** * 职责接口 * @author LinChangyi * @date 2018/2/13 **/ public abstract class Handler { /** * 持有后继的职责对象 */ protected Handler successor; public void setSuccessor(Handler successor) { this.successor = successor; } /** * 处理请求的方法 * 可以根据需求传入参数 */ public abstract void handleRequest(); } /** * @author LinChangyi * @date 2018/2/13 **/ public class ConcreteHandler1 extends Handler{ @Override public void handleRequest() { //根据某些条件来判断是否属于自己的职责范围 //判断条件比如，从外部传入的参数，或者这里主动去获取的外部数据 //如从数据库中获取等，下面只是个示意 boolean someCondition = false; if(someCondition){ //属于自己的职责 System.out.println(&quot;ConcreteHandler1 handle request&quot;); } else { if(this.successor!=null){ this.successor.handleRequest(); } } } } /** * @author LinChangyi * @date 2018/2/13 **/ public class Client { public static void main(String[] args){ //组装责任链 Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); handler1.setSuccessor(handler2); //提交请求 handler1.handleRequest(); } }","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"SpringBoot启动过程分析","slug":"SpringBoot启动过程分析","date":"2018-02-09T03:49:43.000Z","updated":"2018-03-10T09:15:46.521Z","comments":true,"path":"2018/02/09/SpringBoot启动过程分析/","link":"","permalink":"https://lincy.online/2018/02/09/SpringBoot启动过程分析/","excerpt":"入口@SpringBootApplication public class SpringbootstarterApplication { public static void main(String[] args) { SpringApplication.run(SpringbootstarterApplication.class, args); } }","text":"入口@SpringBootApplication public class SpringbootstarterApplication { public static void main(String[] args) { SpringApplication.run(SpringbootstarterApplication.class, args); } } 初始化private void initialize(Object[] sources) { //sources为入口的传入的class if (sources != null &amp;&amp; sources.length &gt; 0) { this.sources.addAll(Arrays.asList(sources)); } //是否web应用 this.webEnvironment = deduceWebEnvironment(); //应用上下文初始化器 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //应用监听器监听器，使用观察者模式实现 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 加载的初始化器和监听器如下： 初始化器和监听器是如何创建的？可以看到初始化器和监听器的创建都是通过 getSpringFactoriesInstances 这个方法： private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // SpringFactoriesLoader读取spring.factories文件，找到类名 Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); //根据上面找到的类名，创建实例 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; } springboot的一个jar包底下的\\META-INF\\spring.factories配置的初始化器和监听器: spring.factories一部分配置 运行SpringApplition.java public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); FailureAnalyzers analyzers = null; configureHeadlessProperty(); //SpringApplicationRunListener，也是通getSpringFactoriesInstances方式加载。 //是SpringApplicationRunListener的集合，监测应用上下文环境的事件： //starting, environmentPrepared, contextPrepared, contextLoaded, finished SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //初始化一些配置 prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } return context; } catch (Throwable ex) { handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); } } …未完待续","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://lincy.online/tags/springboot/"}]},{"title":"丙州三调","slug":"行摄/丙州大桥","date":"2018-02-06T15:28:38.000Z","updated":"2018-02-06T15:47:49.331Z","comments":true,"path":"2018/02/06/行摄/丙州大桥/","link":"","permalink":"https://lincy.online/2018/02/06/行摄/丙州大桥/","excerpt":"丙州大桥，傍晚时分，瞎拍几张","text":"丙州大桥，傍晚时分，瞎拍几张","categories":[{"name":"生活","slug":"生活","permalink":"https://lincy.online/categories/生活/"}],"tags":[{"name":"行摄","slug":"行摄","permalink":"https://lincy.online/tags/行摄/"}]},{"title":"命令模式","slug":"命令模式","date":"2018-02-06T08:19:40.000Z","updated":"2018-02-06T12:06:26.301Z","comments":true,"path":"2018/02/06/命令模式/","link":"","permalink":"https://lincy.online/2018/02/06/命令模式/","excerpt":"命令模式","text":"命令模式 优点： command子类可以快速扩展 调用者和接收者间解耦，调用者只需要调用command的execute方法，不需要了解接收者 //通用Receiver类 public abstract class Receiver { public abstract void doSomething(); } //具体Receiver类 public class ConcreteReciver1 extends Receiver{ //每个接收者都必须处理一定的业务逻辑 public void doSomething(){ } } public class ConcreteReciver2 extends Receiver{ //每个接收者都必须处理一定的业务逻辑 public void doSomething(){ } } //抽象Command类 public abstract class Command { public abstract void execute(); } //具体的Command类 public class ConcreteCommand1 extends Command { //对哪个Receiver类进行命令处理 private Receiver receiver; //构造函数传递接收者 public ConcreteCommand1(Receiver _receiver){ this.receiver = _receiver; } //必须实现一个命令 public void execute() { //业务处理 this.receiver.doSomething(); } } public class ConcreteCommand2 extends Command { //哪个Receiver类进行命令处理 private Receiver receiver; //构造函数传递接收者 public ConcreteCommand2(Receiver _receiver){ this.receiver = _receiver; } //必须实现一个命令 public void execute() { //业务处理 this.receiver.doSomething(); } } //调用者Invoker类 public class Invoker { private Command command; public void setCommand(Command _command){ this.command = _command; } public void action() { this.command.execute(); } } //场景类 public class Client { public static void main(String[] args){ Invoker invoker = new Invoker(); Receiver receiver = new ConcreteReceiver1(); Command command = new ConcreteCommand1(receiver); invoker.setCommand(command); invoker.action(); } }","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"zookeeper学习笔记（2）Paxos Made Simple【翻译】","slug":"zookeeper学习笔记/zookeeper学习笔记（2）paxos协议","date":"2018-01-18T08:50:04.000Z","updated":"2018-02-12T11:23:30.380Z","comments":true,"path":"2018/01/18/zookeeper学习笔记/zookeeper学习笔记（2）paxos协议/","link":"","permalink":"https://lincy.online/2018/01/18/zookeeper学习笔记/zookeeper学习笔记（2）paxos协议/","excerpt":"原文 Paxos Made Simple摘自 Paxos Made Simple论文翻译","text":"原文 Paxos Made Simple摘自 Paxos Made Simple论文翻译 【这篇论文我翻一下来，首先感觉还是不好懂，很多地方结论的得出不够清楚，需要读者自己思考其中的原因。要理解Paxos算法，个人建议先搜索下介绍算法的中文文章，大致了解下Paxos算法要做什么，然后就再读下论文，应该会有所感悟。】 Paxos Made SimpleLeslie Lamport01 Nov 2001 说明【说明这部分是我自己加的，下面这几个词大量出现与论文的主体部分，提前了解它们的含义有助于后面对于算法原理和流程的理解。】 议案(proposal):由提议人提出，由审批人进行初审和复审，包括议案编号和议案内容。内容(value):议案的内容。编号(id):议案的编号，全局唯一。提议人(proposer):提出议案，接收审批人的初审和复审意见。审批人(acceptoer):接收议案，根据规则决定初审和复审结果，返回给提议人。执行人(learner):一旦议案成为决议，就要通知所有执行人。初审(accept):议案的第一轮审核，通过后可以进行复审。复审(chossen):议案的第二轮审核，通过后将成为决议。 摘要Paxos算法，当用简明英语表述时，灰常简单。【大神的第一篇论文用在虚构的希腊岛屿Paxos上的人们通过议会表决法律来解释Paxos算法，群众纷纷表示太难理解了。大神表示你们这群渣渣不懂我的幽默，既然如此，我就用简明英语再表述一遍，哼！】 1 介绍Paxos算法的目标是实现一个具有容错能力的分布式系统。人们觉得这一算法哪一理解，也许对许多读者来说，算法最初使用希腊语表述的。[5]事实上，这一算法是分布式算法中最简单直观的算法之一。【Google Chubby的作者Mike Burrows:there is only one consensus protocol, and that’s Paxos– all other approaches are just broken versions of Paxos.】这一算法的核心是论文[5]中提到的一致性算法“synod”。下一章我们将看到这一算法如何严格遵守我们制定的规则。最后一章会通过将一致性算法应用于构建分布式系统的确定状态机（这是分布式理论的文章最常常引用的论文的内容[4]）来对Paxos算法进行完整的解释。 2 一致性算法2.1 问题的提出假设我们有一组服务器，他们都可以提出议案。一致性算法要保证被提出的多个议案中最终只有一个议案可以通过审核成为决议。如果没有议案提出，就不会产生决议。如果一个议案成为决议，那么所有process都应当知道这个决议。那么，要保证一致性就要满足： 所有被提出的议案中只有一个议案可以成为决议只有一个议案成为决议，且服务器永远不知道一个议案成为了决议，除非这个议案真的成为了决议这一过程的运行时间并不重要，但要保证最终将会有某个议案成为决议，并且，一旦议案成为决议，所有服务器都能够知道这一决议。 我们用三类代理人代表一致性算法中的三个角色：提议人、审批人和执行人。在具体实现中，单个服务器可以扮演多种代理人，我们不需要关心他们之间的对应关系。【同一台服务器，可以即是提议人，又是审批人或执行人。】 假设代理间通过消息通信。这里我们使用传统的异步、非拜占庭模型【不考虑拜占庭问题，代理间通信可能丢失或重复，但不会被篡改】： 服务器运行效率不确定，可能停机或重启。因为当决议产生后所有服务器都有可能停机重启，所以服务器必须能够做到即使停机重启也可以记住某些信息，否则停机重启的问题将无法解决。消息传递时间任意，消息可以重复发送，允许丢失，但不允许修改。 2.2 选择决议只有一个审批人的状况是最简单的。提议人向审批人发送议案，审批人选择接收到的第一个议案作为决议。这个方案无法解决单机失效问题，如果审批人停机，整个系统将被阻塞。 因此，我们来尝试另一种选择决议的方式：让多个审核人共同参与决议的产生。提议人向一部分审核人发送议案，审核人可能会初审通过这一议案。当足够多的审核人初审通过这一议案时，议案就可以进行复审了。多少人算足够多？为了保证只有一个议案成为决议，足够多的人必须包括审核人的多数派，即半数以上的审批人。因为任何两个多数派集合中至少有一个成员是公共的，因此只要保证一个审批人同一时间最多只能初审通过一条议案【这里指的是审批人承认这一议案通过初审，当该议案进行复审时，也会通过复审的状态】，就可以保证最终只有一个议案可以成为决议。 (在大量论文中都涉及了多数派的研究，最早出现于[3]) 在不存在服务器停机或消息丢失的前提下，我们希望即使只发起了一个议案，这个议案仍可以成为决议。因此我们需要满足以下条件： P1.对于接收到的第一个议案，审核人必须初审通过。 但是这一条件会产生一个问题。不同提议人几乎同时提出不同的议案，导致每个审批人都初审通过了一个议案，但是没有一个议案同时被半数以上的审批人初审通过。即使只有两个议案，审批人有2n+1个，且他们分别被n个审批人初审通过，那么最后一个审批人的停机就可能导致无法产生决议。 条件P1以及决议的产生必须经过多数派审核这一条件表明审批人应当可以先后初审通过多条议案。我们通过为每一个议案分配一个编号来追踪不同的议案，这样一个议案就包括议案编号和议案内容两部分。为了防止混淆，我们要求不同议案的编号也必须不同。关于这点如何保证依赖于具体实现，我们这里只是假设他成立。【google的编号生成算法在附录，有兴趣的可以看下】当一项议案被审批人中的多数派初审通过后，这项议案的内容将进入复审阶段。 我们允许多个议案进入复审阶段，但是我们必须保证这些议案的内容是相同的。通过引入议案编号，我们可以保证以下条件： P2.如果一个编号为n内容为v的议案【下文用议案（n,v）替代】进入复审阶段，那么所有进入复审阶段的议案编号大于n的议案，他们的议案内容也为v。【条件P2以及后续P2的强化条件都在保证一件事：多个提议人可以提出多个议案，议案编号各不相同，但是这些议案的内容最终都会一样】 由于议案编号是有序的，条件P2严格保证了只有一个议案内容可以成为决议。 要进入复审阶段并最终成为决议，议案必须被至少一个审批人初审通过。因此要满足条件P2,我们只要满足以下条件： P2a.如果议案（n,v）进入复审阶段，那么所有通过初审的编号大于n的议案的议案内容为v。 我们仍需要满足条件P1以保证会有决议产生。因为通信是异步的，一个议案可能被任何尚未收到过议案的审批人初审通过，这违背了条件P2a。要保证P1和P2a同时有效，需要把P2a加强为以下条件： P2b.如果议案（n,v）进入复审阶段，那么任何提议人提出的编号大于n的议案，议案内容为v。 因为一个议案首先要由提议人提出才有可能被审批人初审通过，所以条件P2b保证了条件P2a也就保证条件P2. 在找到方法满足P2b前，我们先研究如何使这一条件成立。假设议案（m,v）进入复审阶段，如何使议案编号为n且n&gt;m的任意议案的议案内容为v 。我们使用对n使用数学归纳法证明，这样我们要证明议案n的内容为v，就要需要额外的假设条件：任意编号在m和n-1区间内的议案的内容为v。因为议案（m,v）已经进入复审阶段，那么必然有一个多数派的审批人集合C，集合中的每个审批人都对议案m初审通过。把这一结论与额外条件结合，议案m进入复审阶段表明： 每个集合C中的审批人都初审通过一个编号在m和n-1区间内的议案，并且所有编号在m和n-1区间内的议案内容为v。 【要理解这一部分，需要了解算法的具体执行过程。对于编号m到n-1的议案，议案的内容为v，提议人是怎么样决定议案内容的呢？提议人必然是通过向集合C中的某些成员发送初审请求并通过初步审核后，从回复信息中获知这一信息的。这就是上半句话的解释】 因为任意审批人多数派的集合S和集合C至少有一个成员相同，那么只要保证以下条件成立，议案n的内容就可以保证为v： P2c.对任意内容v和编号n，议案（n,v）如果被某个提议人发出，那么必然有一个审批人的多数派集合S，他们要么 （a） S中的任何审批人都没有收到过编号小于n的议案，或者 （b） 集合S中所有审批人初审通过的编号小于n的议案中编号最大的那个议案的议案内容为v。 我们可以证明满足条件P2c即可满足条件P2b。 要保证条件P2c，当一个提议人想要发出一个编号为n的议案时，他必须知道已经或将要通过多数派审批人初步审核的编号小于n的议案中编号最大的那个议案的内容。要知道已经通过初审的议案很简单，但是预测未来的初审结果很难。为了规避预测未来这一难题，审批人必须保证不会有允许这样的初审结果出现。也就是说，提议人要求审批人一旦初审通过编号为n的议案将不得再初审通过编号小于n的议案。因此发出议案的算法如下： 1. 一个提议人生成一个新的议案编号n并发给一半以上的任意审批人，要求他们回复： （a） 保证不再审核通过【包括初审和复审】编号小于n的议案，且 （b） 如果已经初审通过了议案，把编号小于n且编号最大的那个议案的编号和内容回复给我。 这一过程称为编号为n的议案的初审请求。 2. 如果提议人收到了半数以上的初审通过回复，那么他将发起一个议案，议案的编号为n，内容为v，【请注意，此时才决定议案内容，之前初步审核只是要确认议案编号是否可用】如果审批人的回复中包括议案，v就是这些议案中编号最大的那个议案的内容，如果审批人的回复中不包括议案，那么提议人可以自己设置一个议案内容。 提议人向多数派审批人发送已经通过初审的议案（初审的多数派和这次审核的多数派成员可以不同），我们称第二次审核的过程为复审。 以上就是提议人的算法，审批人呢？他接受两种审批请求：初审请求和复审请求。审批人可以拒绝任意请求而不会对系统造成损害，我们应当说清楚在什么情况下审批人可以回复一个请求。在不违背初审通过时的承诺【保证不再审核通过编号小于n的议案】的前提下，他既可以初审通过又可以复审通过一个议案。换句话说： P1a.一个审批人可以初审或复审通过一个议案（n,v），当且仅当他从未初审通过一个编号大于n的议案。【当审批人从未收到任何议案时，他可以初审通过收到的任何议案，这符合条件P1.所以】P1a包含了P1. 我们现在拥有完整的决议产生算法并且满足我们设定的条件——议案编号唯一。最终算法仍需要一些优化。 假设审批人收到了一个编号为n的初审请求，但是他已经初审通过了编号大于n的议案，因此已经保证过不对编号为n的议案做出回应。因为他不会初审通过这一议案，所以他没有必要对初审请求做出回应。因此我们让审批人忽略这一初审请求，同时，审批人也会忽略再次收到的已经初审通过的议案的初审请求。 这一优化要求审批人必须且只需记住他收到过的编号最高的议案以及他初审通过的编号最高的议案。因为P2c条件在某些角色停机的情况下仍要保证有效，审批人即使在停机重启后仍要记的这些信息。注意提议人可以随时放弃当前的议案或者忘掉之前提出过的议案，但是他必须保证议案的编号唯一且递增。 把提议人和审批人的算法结合在一起，我们得到下面两个阶段的算法： 阶段1 （a） 提议人生成议案编号n，向半数以上审批人发送编号为n的初审请求。 （b） 如果审批人收到的初审请求编号n大于他之前初审通过的议案编号，将回复两个信息：一个是保证不再对编号小于n的议案做出回应【包括初审和复审】，二是如果之前初审通过了议案，将其中编号最大的议案的编号和内容回复给提议人。 阶段2（a） 如果提议人收到了半数以上的审批人的初审通过回复，他将会以议案（n,v）发送复审请求。对于议案内容v，如果审批人的初审回复中包含议案，那么v就是这些议案中编号最大的那个议案的内容，如果初审回复中不包含议案，提议人可以自行决定议案内容v。 （b） 如果审批人收到了编号为n的议案的复审请求，只要他没有初审通过编号大于n的议案【从而做出过保证】，他会复审通过这一议案。 提议人可以在遵守算法规则的前提下提出多个议案。他可以在协议的任意阶段随时放弃某个议案。（算法不会因此出现问题，即使审核请求或回复在议案被抛弃后才接收到）如果其他提议人开始发起编号更高的议案，也许放弃当前编号较低的议案是个好主意。【不管编号更高的议案能否通过多数派的初审，都意味着当前编号的议案不会得到半数以上的通过回复，发送请求和等待回复将是浪费时间】因此，如果审批人因为保证过不再回复编号较小的议案而忽略某些议案时，他应当通知提议人：你的议案编号太小了，放弃当前议案，选一个更大的编号，重新发送申请。这是一个性能方面的优化，不会影响算法的正常运行。 2.3 产生决议后如何通知执行人要随时知道一个决议是否产生了，执行人必须能随时获悉是否有一个议案被半数以上审批人复审通过。首先想到的算法是，让审批人每次复审通过一条议案，就给所有执行人发送一条消息。这使得执行人可以实时了解当前审核情况，但是这要求每个审批人和每个执行人通信，通信规模是两者数量的乘积。 非拜占庭问题的假设使得执行人获得消息变得简单。我们可以选出一个执行人代表，所有审批人都与执行人代表进行通信，而当决议产生时，执行人代表再把决议通知其他执行人。这里需要一轮额外的通信以通知所有执行人当前决议。而且这一做法更不可靠，因为执行人代表也可能停机。但是他的通信量仅仅是两者数量之和。更进一步，我们可以让审批人和多个执行人代表通信，每个执行人代表都可以在决议产生后通知其他执行人。多个执行人代表可以使系统更加稳定但是通信的复杂度也会提高。 由于允许通信失败，执行人可能无法得知进入复审阶段议案的内容。执行人可以向所有审批人询问当前初审通过的议案，但是某个审批人停机就可能导致没有一个议案被半数以上审批人初审通过。在这一情况下，只有当新的议案进入复审阶段时，执行人才能知晓议案内容。如果执行人需要知道当前是否有进入复审阶段的议案的内容，他可以要求提议人根据上面的算法发起一个议案。【这个新议案的议案编号足够大，发起初审请求后能够得到半数以上审批人的回复，他们的回复中如果有议案，议案编号最大的那个议案内容就是目前进入复审阶段的议案内容。提议人可以继续发起复审请求，也可以放弃当前议案。最终产生的决议内容是不会发生变化的。】 2.4 保证算法的进行很容易就可以想到一个场景，两个提议人轮流发起编号递增的提议并通过初步审核，虽然按照算法规则，他们的提议内容是相同的，但是由于复审请求时，审批人已经初审通过了另一个编号更高的议案，导致自己的复审请求无法通过，因此永远无法产生决议。提议人p的议案n1通过初审，然后提议人q的议案n2通过初审，n2&gt;n1；提议人p的复审请求将被忽略，因为审批人已经保证过不再回复编号小于n2的议案。然后提议人p将议案编号提高为n3，n3&gt;n2，并通过初步审核，导致q的复审请求也被忽略。这样重复下去，永远无法产生决议。【活锁】 要保证算法进行下去，必须选出一个提议人代表，只有他可以发出议案。如果提议人代表可以和半数以上的审核人成功通信，并且他提出的议案编号比所有已经提出过的议案的编号都大，他就可以成功让议案变成决议。如果通过审核人的忽略回复得知已经存在某些编号更高的议案，提议人代表会放弃当前议案，增大议案编号然后重新进行步骤一的初步审核，最终，提议人代表能够选出一个足够大的编号用于产生决议。 如果分布式系统中足够多的部分正常工作（至少一个提议人、半数以上审批人、工作正常的通信网络），通过选举选出一个提议人代表就可以保证系统正常运行。Fischer,lynch和Patterson[1]的著名研究结果表明，可靠地选举算法要么是随机的，要么是实时的-比如使用超时机制。【另一篇文章中关于FLP理论与Paxos算法的讨论：其实仔细回忆Paxos论文会发现，Paxos中存在活锁，理论上的活锁会导致Paxos算法无法满足Termination属性，也就不算一个正确的一致性算法。Lamport在自己的论文中也提到“FLP结果表明，不存在完全满足一致性的异步算法…”，因此他建议通过Leader来代替Paxos中的Proposer，而Leader则通过随机或其他方式来选定（Paxos中假如随机过程会极大降低FLP发生的概率）。也就是说Paxos算法其实也不算理论上完全正确的，只是在工程实现中避免了一些理论上存在的问题。但这丝毫不影响Paxos的伟大性！】但是，不管选举成功还是失败，系统安全性都可以得到保障。 2.5 实现Paxos算法[5]建立在一组通过网络通信的服务器上。在此一致性算法中，每个服务器都可以是提议人、审批人或执行人。算法选举出一个提议人代表防止活锁出现、选出一个执行人代表降低通信复杂度。Paxos一致性算法中的审核请求和审核回复都以普通消息的形式发送（审核回复带有相应的议案编号防止出现消息发送失败、延迟或重复时导致提议人的混乱）。持久化存储保证即使停机后仍可以保存数据，用来保存审核人必须记住的信息。审核人在发送审核回复消息前，会先在持久化存储中存储这些消息。 最后要描述的是实现任意两个议案编号不相同的机制。不同的提议人从互不相交的集合中选择编号，因此两个提议人不会生成相同的编号。每个提议人都会存储他们发出过的最大的议案编号，当他们再次开始步骤一的初步审核申请时，会选择一个比之前议案编号更大的编号。 3 有限状态机的实现实现分布式系统的一个方案是由一组客户端向中心服务器发送指令。中心服务器作为确定状态自动机按一定顺序执行接收的指令。状态机根据当前状态和接收到的指令产生输出结果和新的状态。例如，分布式银行系统的客户端可能是出纳员，而状态机的状态可能是所有账户余额的集合。提现操作会向状态机发出指令，当且仅当账户余额不小于提现金额时，减少账户余额数量【新的状态】，并返回提现前后的余额【输出】。 单个中心服务器无法解决单机失效问题。因此我们使用一组中心服务器，每个服务器都是一个独立的状态机。因为状态机属于确定状态自动机，所以当输入命令的内容和顺序相同时，这些状态的状态变化和输出也是相同的。因此客户端的指令发送给任何服务器都是有效的。 要保证所有服务器执行相同的状态机指令序列，我们执行多轮paxos一致性算法，第i轮产生的决议作为指令序列中第i条状态机指令。每个服务器都将作为提议人、审核人和执行人参与到算法中。我们假设服务器组不发生变动，每一轮算法执行都是用同一组服务器。 通常，某个服务器会被选出作为提议人代表，在每一轮算法执行时，只有代表可以提出议案。客户端向代表发送指令，由提议人代表决定指令应该何时执行。如果代表决定某条指令应当成为指令队列中第135条指令，他会把这条指令作为议案内容发送给审核人，最终形成决议。一般情况下总是可以成功的。但也有失败的可能，如果出现通信失败、停机或者另一个服务器误以为自己也是提议人代表，并且希望另一条指令成为第135条指令。但是Paxos算法保证至多只有一条指令可以成为第135条指令。 产生这一结果的关键是，在Paxos一致性算法中，决议必须要经过复审才可以产生。回想一下，当议案通过初审时，提议人自己也不确定议案内容是什么，他必须根据审批人的回复来决定要么使用之前的议案内容、要么自己决定议案内容。 现在我将描述正常情况下Paxos状态机如何工作。稍后，再来讨论可能出现的风险。考虑上一个代表停机，新的代表刚刚选出的情况。（系统启动状态是一个特殊状态，此时还没有任何议案提出） 新的提议人代表，作为执行人，应当知道已经产生的指令队列中的大部分指令。假设他知道指令1-134号，138号和139号，即第1轮到134轮，138轮和139轮算法执行的结果。（我们稍后会看到这种指令空缺是如何产生的）然后他开始执行空缺的135-137轮算法以及139轮以后的算法的初审阶段。假设只有135轮和140轮的议案初审通过的回复中包含指令信息，其他轮的初审回复不包含指令信息【这里是指135轮和140轮之前已经进行过，在初审通过的返回信息中包含了之前已经进入复审阶段的议案，而进入复审阶段的议案是包含议案内容的，因此不需要等待客户端发送指令请求来决定议案内容，可以直接发起复审请求】。提议人代表之后会执行135轮和140轮的复审阶段，最终产生135号指令和140号指令。 提议人代表以及所有从提议人代表处了解到所有指令的服务器都可以执行1-135号指令。但是，138号-140号指令不能执行，因为136号和137号指令还没有产生。提议人可以用接下来收到的两条客户端指令请求作为136号和137号指令。但是为了立即弥补指令空缺，我们用‘no-op’指令作为136号和137号指令的议案内容，这一指令不会对状态机状态产生影响。一旦这两条no-op指令被选出为决议，指令138号-140号就可以执行了。 第1号-140号指令都已经产生。提议人代表也已经完成了所有编号大于140的指令的初审阶段，提议人代表可以自由决定复审阶段应当使用的议案内容。他把接下来收到的第一个客户端指令请求作为141号指令进行复审。接着把收到的下一条客户端指令作为142号，以此类推。 提议人代表不需要等待141号指令产生就可以发起142号指令的复审请求。有可能提议人发出的所有141号指令复审请求都发送失败，可能142号指令已经产生了，执行人还不知道141号指令的内容是什么。当执行人没有收到关于141号指令的复审请求回复时，他会再次发送请求。如果一切正常，141号指令就会成功产生。然而，这次仍有可能失败，导致指令队列中出现空缺。综上，如果一个提议人可以一次产生长度为α的指令队列，那么当指令1到指令i产生后，他可以继续产生指令i+1到i+α。最坏的情况是产生一个α-1大小的指令空缺。【i+1轮到i+α-1轮的算法执行都没有成功，i+α轮执行成功】 新产生的提议人代表要执行无限多次初审请求【初审请求为了确定议案的编号，不需要知道议案的内容，也就是说在收到初审通过的回复前，提议人也不知道指令内容是什么，由于整个系统中只有一个提议人发送请求，初审请求一般是一次通过的】，在上面的场景中，提议人要执行135轮-137轮以及139轮之后算法的初审阶段。通过在审核回复中添加额外的信息【当前算法执行轮数】，提议人就可以在不同算法执行轮中使用相同的议案编号。在初审阶段，仅当某个议案进入复审阶段时，审批人在回复给其他提议人的初审通过消息中会附带该议案的议案编号和议案内容。因此，审批人对于每一轮算法执行过程中的消息回复都可以非常精简。【仅包括算法执行轮数和已经进入复审的议案内容】即使执行无穷多次初审阶段也不会造成任何问题。 由于提议人代表停机并选择新的提议人是非常罕见的情况，产生状态机指令序列的效率，也就是在指令/决议上达成一致的效率仅仅取决于算法执行的复审阶段。可以证明，在允许失效的情况下【停机、消息发送失败】，Paxos算法比其他任何算法都更加高效。因此，Paxos算法绝对是一致性算法的最佳选择。 以上讨论假设提议人代表在系统中一直在线，除了当前代表停机和选出新代表间的短暂时间。在特殊情况下，新代表的选举也可能失败。如果没有提议人代表在线，就无法产生新的指令。如果多个服务器都认为自己是代表，那么他们会在算法执行的每一轮都提出议案，导致活锁，同样使得指令无法产生。然而算法的安全性是可以保证的，两个服务器也许会提出不同的议案，但是他们的议案内容必然是相同的。选出单个的提议人代表只是为了避免活锁的出现。 如果服务器组可以变动，必须有办法确定哪些服务器参与了某一轮算法的执行。最简单的方法是通过改变状态机状态来实现。当前服务器组作为状态信息的一部分，当服务器发生变化时，可以通过状态机指令修改状态来记录。在执行完第i条指令后，通过标明将要参与第i+α轮算法执行的服务器组，就可以保证执行人代表可以提前发布α条指令的初审请求。这样就实现了一个简单地arbitrarily sophisticated reconfiguration algorithm。 参考文献 [1] Michael J. Fischer, Nancy Lynch, and Michael S. Paterson. Impossibility of distributed consensus with one faulty process. Journal of the ACM, 32(2):374–382, April 1985. [2] Idit Keidar and Sergio Rajsbaum. On the cost of fault-tolerant consensus when there are no faults—a tutorial. TechnicalReport MIT-LCS-TR-821, Laboratory for Computer Science, Massachusetts Institute Technology, Cambridge, MA, 02139, May 2001. also published in SIGACT News 32(2) (June 2001). [3] Leslie Lamport. The implementation of reliable distributed multiprocess systems. Computer Networks, 2:95–114, 1978. [4] Leslie Lamport. Time, clocks, and the ordering of events in a distributed system. Communications of the ACM, 21(7):558–565, July 1978. [5] Leslie Lamport. The part-time parliament. ACM Transactions on Com- puter Systems, 16(2):133–169, May 1998. 附录 议案编号生成算法 在Google的Chubby论文中给出了这样一种方法： 假设有n个proposer，每个编号为ir(0&lt;=ir&lt;n)，proposol编号的任何值s都应该大于他已知的最大值，并且满足：s %n = ir =&gt; s = m*n + ir proposer已知的最大值来自两部分：proposer自己对编号自增后的值和接收到acceptor的reject后所得到的值 以3个proposer P1、P2、P3为例，开始m=0,编号分别为0，1，2 P1提交的时候发现了P2已经提交，P2编号为1 &gt; P1的0，因此P1重新计算编号：new P1 = 1*3+0 = 4 P3以编号2提交，发现小于P1的4，因此P3重新编号：new P3 = 1*3+2 = 5 作者：哇噜噜大王没有巴 链接：https://www.jianshu.com/p/6d01a8d2df9f 來源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://lincy.online/tags/zookeeper/"}]},{"title":"zookeeper学习笔记（1）2PC和3PC","slug":"zookeeper学习笔记/zookeeper学习笔记（1）2PC和3PC","date":"2018-01-18T03:02:33.000Z","updated":"2018-02-12T11:23:30.374Z","comments":true,"path":"2018/01/18/zookeeper学习笔记/zookeeper学习笔记（1）2PC和3PC/","link":"","permalink":"https://lincy.online/2018/01/18/zookeeper学习笔记/zookeeper学习笔记（1）2PC和3PC/","excerpt":"","text":"分布式系统的挑战事务ACID 原子性 一致性 隔离性 未授权读取，允许脏读 授权读取，允许不可重复读 可重复读取，允许幻读 串行化 持久性 CAP理论分布式系统不可能同时满足C（一致性），A（可用性），P（分区容错性） BASE理论对CAP中一致性和可用性权衡的结果，无法做到强一致性 Basically Avalible，基本可用 Soft State，软状态 相对于硬状态，存在中间状态 Eventually consistent，最终一致性 一致性协议2PC与3PC角色：参与者，协调者 2PC 阶段一 提交事务请求（也称为投票阶段） 事务询问 协调者向参与者发送事务内容，询问是否可以执行事务，等待响应 执行事务 执行事务，记录undo和redo信息到事务日志中 参与者向协调者反馈事务询问的相应 如果成功执行事务，反馈yes 如果执行失败，反馈no 阶段二 执行事务请求 包含两种可能： 得到的反馈都是yes，则执行事务提交： 发送提交请求：协调者向所有参与者发送commit请求 事务提交：参与者收到commit请求，执行commit操作 反馈commit结果：完成事务提交之后，向协调者发送ack消息 完成事务：协调者收到所有参与则的ack后，完成事务 任意一个参与者反馈了no，或者协调者等待反馈超时，那么就中断事务： 向所有参与者发送rollback回滚请求 参与者收到rollback请求，根据undo信息回滚 反馈回滚结果：参与者回滚之后，向协调者发送ack消息 协调者收到所有参与者反馈的ack消息后，完成事务中断 优点简单，实现方便 缺点 同步阻塞 二阶段执行阶段，所有参与者都处于阻塞阶段，等待其他参与者的响应（阶段一） 单点问题 协调者 脑裂，数据不一致 阶段二协调者崩溃，导致只有部分参与者收到commit请求，数据不一致 太过保守 参与者发生故障，协调者只能通过超时机制感知 3PC阶段一：CanCommit 事务询问：协调者向参与者发送CanCommit请求 反馈yes或者no：参与者向协调反馈是否可以执行事务 阶段二：PreCommit包含两种可能： 执行事务提交，参与者反馈的都是yes 发送预提交请求 协调者向所有参与者发出preCommit请求，进入Prepared阶段 事务预提交 参与者接收到preCommit请求，执行事务操作，记录undo和redo信息到事务日志 参与者反馈事务执行的响应 如果参与者成功执行了操作，向协调者发送ack响应，同时等待协调者的最终指令：commit或者abort 中断事务，任意参与者反馈了no，或者等待超时 发送中断请求 协调者发送abort请求 中断事务 收到协调者的abort请求，或者等待协调者请求超时，参与者中断事务 阶段三：DoCommit也包含两种可能： 执行提交 发送提交请求 协调者收到所有参与者的ack，从“预提交”状态转换到“提交”状态，向参与者发送doCommit请求 事务提交 参与者收到doCommit请求，执行事务提交操作 反馈事务提交结果 参与者向协调者发送ack消息 完成事务 协调者收到所有的ack，完成事务 中断事务，任意一个参与者反聩了no，或者协调者接收反馈超时 发送中断请求 协调者发送abort请求 事务回滚 参与者收到abort请求后，根据undo信息回滚 反馈回滚结果 参与者回滚后，发送ack消息 中断事务 协调者收到所有ack后，中断事务 注意：进入阶段三，协调者crash或者网络出现故障，参与者无法收到协调者的abort或者doCommit请求，会在等待超时后进行事务提交（这点在2PC协议中，参与者会一直阻塞下去） 优点降低了2PC参与者的阻塞范围 缺点参与者收到preCommit后，如果协调者crash或者网络出现分区，此时协调者和参与者无法通信，此时参与者仍然将提交事务，会导致不一致性","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://lincy.online/tags/zookeeper/"}]},{"title":"服务器性能指标","slug":"性能指标","date":"2018-01-17T08:24:50.000Z","updated":"2018-02-13T15:13:08.050Z","comments":true,"path":"2018/01/17/性能指标/","link":"","permalink":"https://lincy.online/2018/01/17/性能指标/","excerpt":"","text":"吞吐率（throughout） web服务器单位时间内处理的请求数，单位req/s 吞吐量 一次性能测试过程中网络传输的数据量的总和 事务，tps（Transaction per second） 就是用户某一步或几步操作的集合。不过，我们要保证它有一个完整意义。比如用户对某一个页面的一次请求，用户对某系统的一次登录，淘宝用户对商品的一次确认支付过程。这些我们都可以看作一个事务。那么如何衡量服务器对事务的处理能力。又引出一个概念—-TPS 每秒钟系统能够处理事务或交易的数量，它是衡量系统处理能力的重要指标。 点击率是tps的一种特定情况，一次鼠标点击，客户端可能向服务器发送多个请求。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[]},{"title":"vim正则替换技巧","slug":"vim正则替换技巧","date":"2017-05-09T06:51:34.000Z","updated":"2018-03-10T09:15:46.525Z","comments":true,"path":"2017/05/09/vim正则替换技巧/","link":"","permalink":"https://lincy.online/2017/05/09/vim正则替换技巧/","excerpt":"","text":"通过以下命令：:.,+6s/ r&#39;\\(.*\\)&#39;/ re.compile(&#39;\\1&#39;)/将就可以批量将python中 r&#39;...&#39;的 字符串批量替换成 re.compile(&#39;...&#39;) 其中使用\\(和\\)包含起来，后面可以使用\\1,\\2指代","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"vim","slug":"vim","permalink":"https://lincy.online/tags/vim/"}]},{"title":"python装饰器","slug":"python装饰器","date":"2017-03-20T02:19:09.000Z","updated":"2018-07-17T17:10:27.407Z","comments":true,"path":"2017/03/20/python装饰器/","link":"","permalink":"https://lincy.online/2017/03/20/python装饰器/","excerpt":"","text":"import functools # 不带参数的装饰器 def log(func): @functools.wraps(func) def wrapper(*args, **kw): print(&#39;call %s&#39; % func.__name__) return func(*args, **kw) return wrapper # 带参数的装饰器 def log2(name): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print(&#39;%s call %s&#39; % (name, func.__name__)) return func(*args, **kw) return wrapper return decorator # 兼容带参数和不带参数 def log3(p): def build_wrapper(func, name=None): @functools.wraps(func) def wrapper(*args, **kw): print(&#39;%s call %s&#39; % (name if name else &#39;somebody&#39;, func.__name__)) return func(*args, **kw) return wrapper if callable(p): # 不带参数 return build_wrapper(p) else: # 带参数 def decorator(func): return build_wrapper(func, p) return decorator @log def test(): print(&#39;test!&#39;) # 输出： # call test # test! @log2(&#39;Tom&#39;) def test2(): print(&#39;test2&#39;) # 输出： # Tom call test2 # test2 @log3 def test3(): print(&#39;test3&#39;) # 输出： # somebody call test3 # test3 @log3(&#39;Jim&#39;) def test4(): print(&#39;test4&#39;) # 输出： # Jim call test4 # test4 if __name__ == &#39;__main__&#39;: test() test2() test3() test4()","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"https://lincy.online/tags/python/"}]},{"title":"观察者模式","slug":"观察者模式","date":"2017-03-05T08:42:54.000Z","updated":"2018-03-10T09:15:46.537Z","comments":true,"path":"2017/03/05/观察者模式/","link":"","permalink":"https://lincy.online/2017/03/05/观察者模式/","excerpt":"","text":"public interface Observer { /** * 观察者更新方法 * 拉模式：传入整个Subject对象，让观察者自行操作 * 推模式：Subject知道Observer所需要的数据，只传入相应参数 */ void update(Subject subject); } public class ConcreteObserver implements Observer{ @Override public void update(Subject subject) { System.out.println(&quot;观察者被调用了&quot;); } } public class Subject { /** * 观察者 */ private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); public void addObserver(Observer observer){ this.observers.add(observer); } public void removeObserver(Observer observer){ this.observers.remove(observer); } public void notifyObservers(){ for (Observer observer: observers){ observer.update(this); } } } 优点： 动态注册，动态联动 广播 需要注意循环广播的发生","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"代理模式","slug":"代理模式","date":"2017-02-27T09:25:20.000Z","updated":"2018-03-01T15:26:05.486Z","comments":true,"path":"2017/02/27/代理模式/","link":"","permalink":"https://lincy.online/2017/02/27/代理模式/","excerpt":"静态代理 代理模式","text":"静态代理 代理模式 public interface Subject { void request(); } public interface Subject { void request(); } public class Proxy implements Subject{ private RealSubject subject; public Proxy(RealSubject subject) { this.subject = subject; } @Override public void request() { //在调用目标对象方法之前，执行一些功能处理 subject.request(); //在调用目标对象方法之后，执行一些功能处理 } } 动态代理（Java动态代理）public class DynamicProxy implements InvocationHandler{ private Subject subject; public Subject getInstance(Subject subject) { this.subject = subject; return (Subject) Proxy.newProxyInstance(subject.getClass().getClassLoader(), subject.getClass().getInterfaces(), this); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //在调用目标对象方法之前，执行一些功能处理 return method.invoke(proxy, args); //在调用目标对象方法之后，执行一些功能处理 } } public class Client { public static void main(String[] args){ Subject subject = new RealSubject(); new DynamicProxy().getInstance(subject).request(); } }","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]}]}
{"meta":{"title":"Lincy's Blog","subtitle":"归去来兮，Just Do IT.","description":null,"author":"Lincy","url":"https://lincy.online"},"pages":[{"title":"","date":"2018-02-12T11:23:30.631Z","updated":"2018-02-12T11:23:30.631Z","comments":true,"path":"about/index.html","permalink":"https://lincy.online/about/index.html","excerpt":"","text":""},{"title":"","date":"2018-02-11T11:41:50.400Z","updated":"2018-02-11T11:41:50.400Z","comments":false,"path":"categories/index.html","permalink":"https://lincy.online/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-02-11T11:41:50.404Z","updated":"2018-02-11T11:41:50.404Z","comments":false,"path":"tags/index.html","permalink":"https://lincy.online/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"[转载]领域驱动设计在互联网业务开发中的实践","slug":"转载-领域驱动设计在互联网业务开发中的实践","date":"2018-10-22T03:25:36.000Z","updated":"2018-10-22T21:57:24.436Z","comments":true,"path":"2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/","link":"","permalink":"https://lincy.online/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/","excerpt":"美团技术团队： https://tech.meituan.com 前言至少30年以前，一些软件设计人员就已经意识到领域建模和设计的重要性，并形成一种思潮，Eric Evans将其定义为领域驱动设计（Domain-Driven Design，简称DDD）。在互联网开发“小步快跑，迭代试错”的大环境下，DDD似乎是一种比较“古老而缓慢”的思想。然而，由于互联网公司也逐渐深入实体经济，业务日益复杂，我们在开发中也越来越多地遇到传统行业软件开发中所面临的问题。本文就先来讲一下这些问题，然后再尝试在实践中用DDD的思想来解决这些问题。","text":"美团技术团队： https://tech.meituan.com 前言至少30年以前，一些软件设计人员就已经意识到领域建模和设计的重要性，并形成一种思潮，Eric Evans将其定义为领域驱动设计（Domain-Driven Design，简称DDD）。在互联网开发“小步快跑，迭代试错”的大环境下，DDD似乎是一种比较“古老而缓慢”的思想。然而，由于互联网公司也逐渐深入实体经济，业务日益复杂，我们在开发中也越来越多地遇到传统行业软件开发中所面临的问题。本文就先来讲一下这些问题，然后再尝试在实践中用DDD的思想来解决这些问题。 问题过度耦合业务初期，我们的功能大都非常简单，普通的CRUD就能满足，此时系统是清晰的。随着迭代的不断演化，业务逻辑变得越来越复杂，我们的系统也越来越冗杂。模块彼此关联，谁都很难说清模块的具体功能意图是啥。修改一个功能时，往往光回溯该功能需要的修改点就需要很长时间，更别提修改带来的不可预知的影响面。 下图是一个常见的系统耦合病例。 订单服务接口中提供了查询、创建订单相关的接口，也提供了订单评价、支付、保险的接口。同时我们的表也是一个订单大表，包含了非常多字段。在我们维护代码时，牵一发而动全身，很可能只是想改下评价相关的功能，却影响到了创单核心路径。虽然我们可以通过测试保证功能完备性，但当我们在订单领域有大量需求同时并行开发时，改动重叠、恶性循环、疲于奔命修改各种问题。 上述问题，归根到底在于系统架构不清晰，划分出来的模块内聚度低、高耦合。 有一种解决方案，按照演进式设计的理论，让系统的设计随着系统实现的增长而增长。我们不需要作提前设计，就让系统伴随业务成长而演进。这当然是可行的，敏捷实践中的重构、测试驱动设计及持续集成可以对付各种混乱问题。重构——保持行为不变的代码改善清除了不协调的局部设计，测试驱动设计确保对系统的更改不会导致系统丢失或破坏现有功能，持续集成则为团队提供了同一代码库。 在这三种实践中，重构是克服演进式设计中大杂烩问题的主力，通过在单独的类及方法级别上做一系列小步重构来完成。我们可以很容易重构出一个独立的类来放某些通用的逻辑，但是你会发现你很难给它一个业务上的含义，只能给予一个技术维度描绘的含义。这会带来什么问题呢？新同学并不总是知道对通用逻辑的改动或获取来自该类。显然，制定项目规范并不是好的idea。我们又闻到了代码即将腐败的味道。 事实上，你可能意识到问题之所在。在解决现实问题时，我们会将问题映射到脑海中的概念模型，在模型中解决问题，再将解决方案转换为实际的代码。上述问题在于我们解决了设计到代码之间的重构，但提炼出来的设计模型，并不具有实际的业务含义，这就导致在开发新需求时，其他同学并不能很自然地将业务问题映射到该设计模型。设计似乎变成了重构者的自娱自乐，代码继续腐败，重新重构……无休止的循环。 用DDD则可以很好地解决领域模型到设计模型的同步、演化，最后再将反映了领域的设计模型转为实际的代码。 注：模型是我们解决实际问题所抽象出来的概念模型，领域模型则表达与业务相关的事实；设计模型则描述了所要构建的系统。 贫血症和失忆症 贫血领域对象 贫血领域对象（Anemic Domain Object）是指仅用作数据载体，而没有行为和动作的领域对象。 在我们习惯了J2EE的开发模式后，Action/Service/DAO这种分层模式，会很自然地写出过程式代码，而学到的很多关于OO理论的也毫无用武之地。使用这种开发方式，对象只是数据的载体，没有行为。以数据为中心，以数据库ER设计作驱动。分层架构在这种开发模式下，可以理解为是对数据移动、处理和实现的过程。 以笔者最近开发的系统抽奖平台为例： 场景需求 奖池里配置了很多奖项，我们需要按运营预先配置的概率抽中一个奖项。实现非常简单，生成一个随机数，匹配符合该随机数生成概率的奖项即可。 贫血模型实现方案 先设计奖池和奖项的库表配置。 设计AwardPool和Award两个对象，只有简单的get和set属性的方法 class AwardPool { int awardPoolId; List&lt;Award&gt; awards; public List&lt;Award&gt; getAwards() { return awards; } public void setAwards(List&lt;Award&gt; awards) { this.awards = awards; } ...... } class Award { int awardId; int probability;//概率 ...... } Service代码实现 设计一个LotteryService，在其中的drawLottery()方法写服务逻辑 AwardPool awardPool = awardPoolDao.getAwardPool(poolId);//sql查询，将数据映射到AwardPool对象 for (Award award : awardPool.getAwards()) { //寻找到符合award.getProbability()概率的award } 按照我们通常思路实现，可以发现：在业务领域里非常重要的抽奖，我的业务逻辑都是写在Service中的，Award充其量只是个数据载体，没有任何行为。简单的业务系统采用这种贫血模型和过程化设计是没有问题的，但在业务逻辑复杂了，业务逻辑、状态会散落到在大量方法中，原本的代码意图会渐渐不明确，我们将这种情况称为由贫血症引起的失忆症。 更好的是采用领域模型的开发方式，将数据和行为封装在一起，并与现实世界中的业务对象相映射。各类具备明确的职责划分，将领域逻辑分散到领域对象中。继续举我们上述抽奖的例子，使用概率选择对应的奖品就应当放到AwardPool类中。 为什么选择DDD软件系统复杂性应对解决复杂和大规模软件的武器可以被粗略地归为三类：抽象、分治和知识。 分治 把问题空间分割为规模更小且易于处理的若干子问题。分割后的问题需要足够小，以便一个人单枪匹马就能够解决他们；其次，必须考虑如何将分割后的各个部分装配为整体。分割得越合理越易于理解，在装配成整体时，所需跟踪的细节也就越少。即更容易设计各部分的协作方式。评判什么是分治得好，即高内聚低耦合。 抽象 使用抽象能够精简问题空间，而且问题越小越容易理解。举个例子，从北京到上海出差，可以先理解为使用交通工具前往，但不需要一开始就想清楚到底是高铁还是飞机，以及乘坐他们需要注意什么。 知识 顾名思义，DDD可以认为是知识的一种。 DDD提供了这样的知识手段，让我们知道如何抽象出限界上下文以及如何去分治。 与微服务架构相得益彰微服务架构众所周知，此处不做赘述。我们创建微服务时，需要创建一个高内聚、低耦合的微服务。而DDD中的限界上下文则完美匹配微服务要求，可以将该限界上下文理解为一个微服务进程。 上述是从更直观的角度来描述两者的相似处。 在系统复杂之后，我们都需要用分治来拆解问题。一般有两种方式，技术维度和业务维度。技术维度是类似MVC这样，业务维度则是指按业务领域来划分系统。 微服务架构更强调从业务维度去做分治来应对系统复杂度，而DDD也是同样的着重业务视角。如果两者在追求的目标（业务维度）达到了上下文的统一，那么在具体做法上有什么联系和不同呢？ 我们将架构设计活动精简为以下三个层面： 业务架构——根据业务需求设计业务模块及其关系 系统架构——设计系统和子系统的模块 技术架构——决定采用的技术及框架 以上三种活动在实际开发中是有先后顺序的，但不一定孰先孰后。在我们解决常规套路问题时，我们会很自然地往熟悉的分层架构套（先确定系统架构），或者用PHP开发很快（先确定技术架构），在业务不复杂时，这样是合理的。 跳过业务架构设计出来的架构关注点不在业务响应上，可能就是个大泥球，在面临需求迭代或响应市场变化时就很痛苦。 DDD的核心诉求就是将业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分解耦，可以自由地选择合适的技术架构，去中心化地治理技术和数据。 可以参见下图来更好地理解双方之间的协作关系： 如何实践DDD我们将通过上文提到的抽奖平台，来详细介绍我们如何通过DDD来解构一个中型的基于微服务架构的系统，从而做到系统的高内聚、低耦合。 首先看下抽奖系统的大致需求：运营——可以配置一个抽奖活动，该活动面向一个特定的用户群体，并针对一个用户群体发放一批不同类型的奖品（优惠券，激活码，实物奖品等）。用户-通过活动页面参与不同类型的抽奖活动。 设计领域模型的一般步骤如下： 根据需求划分出初步的领域和限界上下文，以及上下文之间的关系； 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象； 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根； 为聚合根设计仓储，并思考实体或值对象的创建方式； 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。 战略建模战略和战术设计是站在DDD的角度进行划分。战略设计侧重于高层次、宏观上去划分和集成限界上下文，而战术设计则关注更具体使用建模工具来细化上下文。 领域现实世界中，领域包含了问题域和解系统。一般认为软件是对现实世界的部分模拟。在DDD中，解系统可以映射为一个个限界上下文，限界上下文就是软件对于问题域的一个特定的、有限的解决方案。 限界上下文 限界上下文 一个由显示边界限定的特定职责。领域模型便存在于这个边界之内。在边界内，每一个模型概念，包括它的属性和操作，都具有特殊的含义。 一个给定的业务领域会包含多个限界上下文，想与一个限界上下文沟通，则需要通过显示边界进行通信。系统通过确定的限界上下文来进行解耦，而每一个上下文内部紧密组织，职责明确，具有较高的内聚性。 一个很形象的隐喻：细胞质所以能够存在，是因为细胞膜限定了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。 划分限界上下文划分限界上下文，不管是Eric Evans还是Vaughn Vernon，在他们的大作里都没有怎么提及。 显然我们不应该按技术架构或者开发任务来创建限界上下文，应该按照语义的边界来考虑。 我们的实践是，考虑产品所讲的通用语言，从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求里提取一些动词，观察动词和对象之间的关系；我们将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的界限上下文。形成之后，我们可以尝试用语言来描述下界限上下文的职责，看它是否清晰、准确、简洁和完整。简言之，限界上下文应该从需求出发，按领域划分。 前文提到，我们的用户划分为运营和用户。其中，运营对抽奖活动的配置十分复杂但相对低频。用户对这些抽奖活动配置的使用是高频次且无感知的。根据这样的业务特点，我们首先将抽奖平台划分为C端抽奖和M端抽奖管理平台两个子域，让两者完全解耦。 在确认了M端领域和C端的限界上下文后，我们再对各自上下文内部进行限界上下文的划分。下面我们用C端进行举例。 产品的需求概述如下： 1. 抽奖活动有活动限制，例如用户的抽奖次数限制，抽奖的开始和结束的时间等； 2. 一个抽奖活动包含多个奖品，可以针对一个或多个用户群体； 3. 奖品有自身的奖品配置，例如库存量，被抽中的概率等，最多被一个用户抽中的次数等等； 4. 用户群体有多种区别方式，如按照用户所在城市区分，按照新老客区分等； 5. 活动具有风控配置，能够限制用户参与抽奖的频率。 根据产品的需求，我们提取了一些关键性的概念作为子域，形成我们的限界上下文。 首先，抽奖上下文作为整个领域的核心，承担着用户抽奖的核心业务，抽奖中包含了奖品和用户群体的概念。 在设计初期，我们曾经考虑划分出抽奖和发奖两个领域，前者负责选奖，后者负责将选中的奖品发放出去。但在实际开发过程中，我们发现这两部分的逻辑紧密连接，难以拆分。并且单纯的发奖逻辑足够简单，仅仅是调用第三方服务进行发奖，不足以独立出来成为一个领域。 对于活动的限制，我们定义了活动准入的通用语言，将活动开始/结束时间，活动可参与次数等限制条件都收拢到活动准入上下文中。 对于抽奖的奖品库存量，由于库存的行为与奖品本身相对解耦，库存关注点更多是库存内容的核销，且库存本身具备通用性，可以被奖品之外的内容使用，因此我们定义了独立的库存上下文。 由于C端存在一些刷单行为，我们根据产品需求定义了风控上下文，用于对活动进行风控。最后，活动准入、风控、抽奖等领域都涉及到一些次数的限制，因此我们定义了计数上下文。 可以看到，通过DDD的限界上下文划分，我们界定出抽奖、活动准入、风控、计数、库存等五个上下文，每个上下文在系统中都高度内聚。 上下文映射图在进行上下文划分之后，我们还需要进一步梳理上下文之间的关系。 康威（梅尔·康威）定律 任何组织在设计一套系统（广义概念上的系统）时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。 康威定律告诉我们，系统结构应尽量的与组织结构保持一致。这里，我们认为团队结构（无论是内部组织还是团队间组织）就是组织结构，限界上下文就是系统的业务结构。因此，团队结构应该和限界上下文保持一致。 梳理清楚上下文之间的关系，从团队内部的关系来看，有如下好处： 任务更好拆分，一个开发人员可以全身心的投入到相关的一个单独的上下文中； 沟通更加顺畅，一个上下文可以明确自己对其他上下文的依赖关系，从而使得团队内开发直接更好的对接。 从团队间的关系来看，明确的上下文关系能够带来如下帮助： 每个团队在它的上下文中能够更加明确自己领域内的概念，因为上下文是领域的解系统； 对于限界上下文之间发生交互，团队与上下文的一致性，能够保证我们明确对接的团队和依赖的上下游。 限界上下文之间的映射关系 合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损。 共享内核（Shared Kernel）：两个上下文依赖部分共享的模型。 客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖。 遵奉者（Conformist）：下游上下文只能盲目依赖上游上下文。 防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互。 开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问。 发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。 大泥球（Big Ball of Mud）：混杂在一起的上下文关系，边界不清晰。 另谋他路（SeparateWay）：两个完全没有任何联系的上下文。 上文定义了上下文映射间的关系，经过我们的反复斟酌，抽奖平台上下文的映射关系图如下： 由于抽奖，风控，活动准入，库存，计数五个上下文都处在抽奖领域的内部，所以它们之间符合“一荣俱荣，一损俱损”的合作关系（PartnerShip，简称PS）。 同时，抽奖上下文在进行发券动作时，会依赖券码、平台券、外卖券三个上下文。抽奖上下文通过防腐层（Anticorruption Layer，ACL）对三个上下文进行了隔离，而三个券上下文通过开放主机服务（Open Host Service）作为发布语言（Published Language）对抽奖上下文提供访问机制。 通过上下文映射关系，我们明确的限制了限界上下文的耦合性，即在抽奖平台中，无论是上下文内部交互（合作关系）还是与外部上下文交互（防腐层），耦合度都限定在数据耦合（Data Coupling）的层级。 战术建模——细化上下文梳理清楚上下文之间的关系后，我们需要从战术层面上剖析上下文内部的组织关系。首先看下DDD中的一些定义。 实体 当一个对象由其标识（而不是属性）区分时，这种对象称为实体（Entity）。 例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。 在实践上建议将属性的验证放到实体中。 值对象 当一个对象用于对事务进行描述而没有唯一标识时，它被称作值对象（Value Object）。 例：比如颜色信息，我们只需要知道{“name”:”黑色”，”css”:”#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。 值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。 它具有不变性、相等性和可替换性。 在实践中，需要保证值对象创建后就不能被修改，即不允许外部再修改其属性。在不同上下文集成时，会出现模型概念的公用，如商品模型会存在于电商的各个上下文中。在订单上下文中如果你只关注下单时商品信息快照，那么将商品对象视为值对象是很好的选择。 聚合根 Aggregate(聚合）是一组相关对象的集合，作为一个整体被外界访问，聚合根（Aggregate Root）是这个聚合的根节点。 聚合是一个非常重要的概念，核心领域往往都需要用聚合来表达。其次，聚合在技术上有非常高的价值，可以指导详细设计。 聚合由根实体，值对象和实体组成。 如何创建好的聚合？ 边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。 设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。 通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。 聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List&lt;值对象&gt;，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。 领域服务 一些重要的领域行为或操作，可以归类为领域服务。它既不是实体，也不是值对象的范畴。 当我们采用了微服务架构风格，一切领域逻辑的对外暴露均需要通过领域服务来进行。如原本由聚合根暴露的业务逻辑也需要依托于领域服务。 领域事件 领域事件是对领域内发生的活动进行的建模。 抽奖平台的核心上下文是抽奖上下文，接下来介绍下我们对抽奖上下文的建模。 在抽奖上下文中，我们通过抽奖(DrawLottery)这个聚合根来控制抽奖行为，可以看到，一个抽奖包括了抽奖ID（LotteryId）以及多个奖池（AwardPool），而一个奖池针对一个特定的用户群体（UserGroup）设置了多个奖品（Award）。 另外，在抽奖领域中，我们还会使用抽奖结果（SendResult）作为输出信息，使用用户领奖记录（UserLotteryLog）作为领奖凭据和存根。 谨慎使用值对象 在实践中，我们发现虽然一些领域对象符合值对象的概念，但是随着业务的变动，很多原有的定义会发生变更，值对象可能需要在业务意义具有唯一标识，而对这类值对象的重构往往需要较高成本。因此在特定的情况下，我们也要根据实际情况来权衡领域对象的选型。 DDD工程实现在对上下文进行细化后，我们开始在工程中真正落地DDD。 模块模块（Module）是DDD中明确提到的一种控制限界上下文的手段，在我们的工程中，一般尽量用一个模块来表示一个领域的限界上下文。 如代码中所示，一般的工程中包的组织方式为{com.公司名.组织架构.业务.上下文.*}，这样的组织结构能够明确的将一个上下文限定在包的内部。 import com.company.team.bussiness.lottery.*;//抽奖上下文 import com.company.team.bussiness.riskcontrol.*;//风控上下文 import com.company.team.bussiness.counter.*;//计数上下文 import com.company.team.bussiness.condition.*;//活动准入上下文 import com.company.team.bussiness.stock.*;//库存上下文 代码演示1 模块的组织 对于模块内的组织结构，一般情况下我们是按照领域对象、领域服务、领域资源库、防腐层等组织方式定义的。 import com.company.team.bussiness.lottery.domain.valobj.*;//领域对象-值对象 import com.company.team.bussiness.lottery.domain.entity.*;//领域对象-实体 import com.company.team.bussiness.lottery.domain.aggregate.*;//领域对象-聚合根 import com.company.team.bussiness.lottery.service.*;//领域服务 import com.company.team.bussiness.lottery.repo.*;//领域资源库 import com.company.team.bussiness.lottery.facade.*;//领域防腐层 代码演示2 模块的组织 每个模块的具体实现，我们将在下文中展开。 领域对象前文提到，领域驱动要解决的一个重要的问题，就是解决对象的贫血问题。这里我们用之前定义的抽奖（DrawLottery）聚合根和奖池（AwardPool）值对象来具体说明。 抽奖聚合根持有了抽奖活动的id和该活动下的所有可用奖池列表，它的一个最主要的领域功能就是根据一个抽奖发生场景（DrawLotteryContext），选择出一个适配的奖池，即chooseAwardPool方法。 chooseAwardPool的逻辑是这样的：DrawLotteryContext会带有用户抽奖时的场景信息（抽奖得分或抽奖时所在的城市），DrawLottery会根据这个场景信息，匹配一个可以给用户发奖的AwardPool。 package com.company.team.bussiness.lottery.domain.aggregate; import ...; public class DrawLottery { private int lotteryId; //抽奖id private List&lt;AwardPool&gt; awardPools; //奖池列表 //getter &amp; setter public void setLotteryId(int lotteryId) { if(id&lt;=0){ throw new IllegalArgumentException(&quot;非法的抽奖id&quot;); } this.lotteryId = lotteryId; } //根据抽奖入参context选择奖池 public AwardPool chooseAwardPool(DrawLotteryContext context) { if(context.getMtCityInfo()!=null) { return chooseAwardPoolByCityInfo(awardPools, context.getMtCityInfo()); } else { return chooseAwardPoolByScore(awardPools, context.getGameScore()); } } //根据抽奖所在城市选择奖池 private AwardPool chooseAwardPoolByCityInfo(List&lt;AwardPool&gt; awardPools, MtCifyInfo cityInfo) { for(AwardPool awardPool: awardPools) { if(awardPool.matchedCity(cityInfo.getCityId())) { return awardPool; } } return null; } //根据抽奖活动得分选择奖池 private AwardPool chooseAwardPoolByScore(List&lt;AwardPool&gt; awardPools, int gameScore) {...} } 代码演示3 DrawLottery 在匹配到一个具体的奖池之后，需要确定最后给用户的奖品是什么。这部分的领域功能在AwardPool内。 package com.company.team.bussiness.lottery.domain.valobj; import ...; public class AwardPool { private String cityIds;//奖池支持的城市 private String scores;//奖池支持的得分 private int userGroupType;//奖池匹配的用户类型 private List&lt;Awrad&gt; awards;//奖池中包含的奖品 //当前奖池是否与城市匹配 public boolean matchedCity(int cityId) {...} //当前奖池是否与用户得分匹配 public boolean matchedScore(int score) {...} //根据概率选择奖池 public Award randomGetAward() { int sumOfProbablity = 0; for(Award award: awards) { sumOfProbability += award.getAwardProbablity(); } int randomNumber = ThreadLocalRandom.current().nextInt(sumOfProbablity); range = 0; for(Award award: awards) { range += award.getProbablity(); if(randomNumber&lt;range) { return award; } } return null; } } 代码演示4 AwardPool 与以往的仅有getter、setter的业务对象不同，领域对象具有了行为，对象更加丰满。同时，比起将这些逻辑写在服务内（例如**Service），领域功能的内聚性更强，职责更加明确。 资源库领域对象需要资源存储，存储的手段可以是多样化的，常见的无非是数据库，分布式缓存，本地缓存等。资源库（Repository）的作用，就是对领域的存储和访问进行统一管理的对象。在抽奖平台中，我们是通过如下的方式组织资源库的。 //数据库资源 import com.company.team.bussiness.lottery.repo.dao.AwardPoolDao;//数据库访问对象-奖池 import com.company.team.bussiness.lottery.repo.dao.AwardDao;//数据库访问对象-奖品 import com.company.team.bussiness.lottery.repo.dao.po.AwardPO;//数据库持久化对象-奖品 import com.company.team.bussiness.lottery.repo.dao.po.AwardPoolPO;//数据库持久化对象-奖池 import com.company.team.bussiness.lottery.repo.cache.DrawLotteryCacheAccessObj;//分布式缓存访问对象-抽奖缓存访问 import com.company.team.bussiness.lottery.repo.repository.DrawLotteryRepository;//资源库访问对象-抽奖资源库 代码演示5 Repository组织结构 资源库对外的整体访问由Repository提供，它聚合了各个资源库的数据信息，同时也承担了资源存储的逻辑（例如缓存更新机制等）。 在抽奖资源库中，我们屏蔽了对底层奖池和奖品的直接访问，而是仅对抽奖的聚合根进行资源管理。代码示例中展示了抽奖资源获取的方法（最常见的Cache Aside Pattern）。 比起以往将资源管理放在服务中的做法，由资源库对资源进行管理，职责更加明确，代码的可读性和可维护性也更强。 package com.company.team.bussiness.lottery.repo; import ...; @Repository public class DrawLotteryRepository { @Autowired private AwardDao awardDao; @Autowired private AwardPoolDao awardPoolDao; @AutoWired private DrawLotteryCacheAccessObj drawLotteryCacheAccessObj; public DrawLottery getDrawLotteryById(int lotteryId) { DrawLottery drawLottery = drawLotteryCacheAccessObj.get(lotteryId); if(drawLottery!=null){ return drawLottery; } drawLottery = getDrawLotteyFromDB(lotteryId); drawLotteryCacheAccessObj.add(lotteryId, drawLottery); return drawLottery; } private DrawLottery getDrawLotteryFromDB(int lotteryId) {...} } 代码演示6 DrawLotteryRepository 防腐层亦称适配层。在一个上下文中，有时需要对外部上下文进行访问，通常会引入防腐层的概念来对外部上下文的访问进行一次转义。 有以下几种情况会考虑引入防腐层： 需要将外部上下文中的模型翻译成本上下文理解的模型。 不同上下文之间的团队协作关系，如果是供奉者关系，建议引入防腐层，避免外部上下文变化对本上下文的侵蚀。 该访问本上下文使用广泛，为了避免改动影响范围过大。 如果内部多个上下文对外部上下文需要访问，那么可以考虑将其放到通用上下文中。 在抽奖平台中，我们定义了用户城市信息防腐层(UserCityInfoFacade)，用于外部的用户城市信息上下文（微服务架构下表现为用户城市信息服务）。 以用户信息防腐层举例，它以抽奖请求参数(LotteryContext)为入参，以城市信息(MtCityInfo)为输出。 package com.company.team.bussiness.lottery.facade; import ...; @Component public class UserCityInfoFacade { @Autowired private LbsService lbsService;//外部用户城市信息RPC服务 public MtCityInfo getMtCityInfo(LotteryContext context) { LbsReq lbsReq = new LbsReq(); lbsReq.setLat(context.getLat()); lbsReq.setLng(context.getLng()); LbsResponse resp = lbsService.getLbsCityInfo(lbsReq); return buildMtCifyInfo(resp); } private MtCityInfo buildMtCityInfo(LbsResponse resp) {...} } 代码演示7 UserCityInfoFacade 领域服务上文中，我们将领域行为封装到领域对象中，将资源管理行为封装到资源库中，将外部上下文的交互行为封装到防腐层中。此时，我们再回过头来看领域服务时，能够发现领域服务本身所承载的职责也就更加清晰了，即就是通过串联领域对象、资源库和防腐层等一系列领域内的对象的行为，对其他上下文提供交互的接口。 我们以抽奖服务为例（issueLottery），可以看到在省略了一些防御性逻辑（异常处理，空值判断等）后，领域服务的逻辑已经足够清晰明了。 package com.company.team.bussiness.lottery.service.impl import ...; @Service public class LotteryServiceImpl implements LotteryService { @Autowired private DrawLotteryRepository drawLotteryRepo; @Autowired private UserCityInfoFacade UserCityInfoFacade; @Autowired private AwardSendService awardSendService; @Autowired private AwardCounterFacade awardCounterFacade; @Override public IssueResponse issueLottery(LotteryContext lotteryContext) { DrawLottery drawLottery = drawLotteryRepo.getDrawLotteryById(lotteryContext.getLotteryId());//获取抽奖配置聚合根 awardCounterFacade.incrTryCount(lotteryContext);//增加抽奖计数信息 AwardPool awardPool = lotteryConfig.chooseAwardPool(bulidDrawLotteryContext(drawLottery, lotteryContext));//选中奖池 Award award = awardPool.randomChooseAward();//选中奖品 return buildIssueResponse(awardSendService.sendAward(award, lotteryContext));//发出奖品实体 } private IssueResponse buildIssueResponse(AwardSendResponse awardSendResponse) {...} } 代码演示8 LotteryService 数据流转 在抽奖平台的实践中，我们的数据流转如上图所示。首先领域的开放服务通过信息传输对象（DTO）来完成与外界的数据交互；在领域内部，我们通过领域对象（DO）作为领域内部的数据和行为载体；在资源库内部，我们沿袭了原有的数据库持久化对象（PO）进行数据库资源的交互。同时，DTO与DO的转换发生在领域服务内，DO与PO的转换发生在资源库内。 与以往的业务服务相比，当前的编码规范可能多造成了一次数据转换，但每种数据对象职责明确，数据流转更加清晰。 上下文集成通常集成上下文的手段有多种，常见的手段包括开放领域服务接口、开放HTTP服务以及消息发布-订阅机制。 在抽奖系统中，我们使用的是开放服务接口进行交互的。最明显的体现是计数上下文，它作为一个通用上下文，对抽奖、风控、活动准入等上下文都提供了访问接口。同时，如果在一个上下文对另一个上下文进行集成时，若需要一定的隔离和适配，可以引入防腐层的概念。这一部分的示例可以参考前文的防腐层代码示例。 分离领域接下来讲解在实施领域模型的过程中，如何应用到系统架构中。 我们采用的微服务架构风格，与Vernon在《实现领域驱动设计》并不太一致，更具体差异可阅读他的书体会。 如果我们维护一个从前到后的应用系统： 下图中领域服务是使用微服务技术剥离开来，独立部署，对外暴露的只能是服务接口，领域对外暴露的业务逻辑只能依托于领域服务。而在Vernon著作中，并未假定微服务架构风格，因此领域层暴露的除了领域服务外，还有聚合、实体和值对象等。此时的应用服务层是比较简单的，获取来自接口层的请求参数，调度多个领域服务以实现界面层功能。 随着业务发展，业务系统快速膨胀，我们的系统属于核心时： 应用服务虽然没有领域逻辑，但涉及到了对多个领域服务的编排。当业务规模庞大到一定程度，编排本身就富含了业务逻辑（除此之外，应用服务在稳定性、性能上所做的措施也希望统一起来，而非散落各处），那么此时应用服务对于外部来说是一个领域服务，整体看起来则是一个独立的限界上下文。 此时应用服务对内还属于应用服务，对外已是领域服务的概念，需要将其暴露为微服务。 注：具体的架构实践可按照团队和业务的实际情况来，此处仅为作者自身的业务实践。除分层架构外，如CQRS架构也是不错的选择 以下是一个示例。我们定义了抽奖、活动准入、风险控制等多个领域服务。在本系统中，我们需要集成多个领域服务，为客户端提供一套功能完备的抽奖应用服务。这个应用服务的组织如下： package ...; import ...; @Service public class LotteryApplicationService { @Autowired private LotteryRiskService riskService; @Autowired private LotteryConditionService conditionService; @Autowired private LotteryService lotteryService; //用户参与抽奖活动 public Response&lt;PrizeInfo, ErrorData&gt; participateLottery(LotteryContext lotteryContext) { //校验用户登录信息 validateLoginInfo(lotteryContext); //校验风控 RiskAccessToken riskToken = riskService.accquire(buildRiskReq(lotteryContext)); ... //活动准入检查 LotteryConditionResult conditionResult = conditionService.checkLotteryCondition(otteryContext.getLotteryId(),lotteryContext.getUserId()); ... //抽奖并返回结果 IssueResponse issueResponse = lotteryService.issurLottery(lotteryContext); if(issueResponse!=null &amp;&amp; issueResponse.getCode()==IssueResponse.OK) { return buildSuccessResponse(issueResponse.getPrizeInfo()); } else { return buildErrorResponse(ResponseCode.ISSUE_LOTTERY_FAIL, ResponseMsg.ISSUE_LOTTERY_FAIL) } } private void validateLoginInfo(LotteryContext lotteryContext){...} private Response&lt;PrizeInfo, ErrorData&gt; buildErrorResponse (int code, String msg){...} private Response&lt;PrizeInfo, ErrorData&gt; buildSuccessResponse (PrizeInfo prizeInfo){...} } 代码演示9 LotteryApplicationService 结语在本文中，我们采用了分治的思想，从抽象到具体阐述了DDD在互联网真实业务系统中的实践。通过领域驱动设计这个强大的武器，我们将系统解构的更加合理。 但值得注意的是，如果你面临的系统很简单或者做一些SmartUI之类，那么你不一定需要DDD。尽管本文对贫血模型、演进式设计提出了些许看法，但它们在特定范围和具体场景下会更高效。读者需要针对自己的实际情况，做一定取舍，适合自己的才是最好的。 本篇通过DDD来讲述软件设计的术与器，本质是为了高内聚低耦合，紧靠本质，按自己的理解和团队情况来实践DDD即可。 另外，关于DDD在迭代过程中模型腐化的相关问题，本文中没有提及，将在后续的文章中论述，敬请期待。 鉴于作者经验有限，我们对领域驱动的理解难免会有不足之处，欢迎大家共同探讨，共同提高。 参考书籍 Eric Evans.领域驱动设计.赵俐 盛海艳 刘霞等译.人民邮电出版社，2016.Vaughn Vernon.实现领域驱动设计.滕云译.电子工业出版社，2014. 作者简介文彬、子维，美团资深研发工程师，毕业于南京大学，现从事美团外卖营销相关的研发工作。最后打波硬广，美团外卖上海研发中心长期招聘前端、客户端、后端、数据仓库和数据挖掘相关的工程师，欢迎有兴趣的同学发送简历到wenbin.lu@dianping.com。","categories":[],"tags":[]},{"title":"VMware centos 无法连接网络问题解决","slug":"VMware-centos-无法连接网络问题解决","date":"2018-10-04T14:25:43.000Z","updated":"2018-10-04T14:44:08.823Z","comments":true,"path":"2018/10/04/VMware-centos-无法连接网络问题解决/","link":"","permalink":"https://lincy.online/2018/10/04/VMware-centos-无法连接网络问题解决/","excerpt":"","text":"问题VMware 安装 CentOS 虚拟机，使用NAT模式联网，无法联网 解决方法执行命令 dhclient -v 添加到启动任务 在 /etc/init.d/下创建文件，命名 “net-autostart” #!/bin/bash # Solution for &quot;No Internet Connection from VMware&quot; # ### BEGIN INIT INFO # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 ### END INIT INFO dhclient -v 更改权限chmod 755 net-autostart 自动启动chkconfig --add net-autostart","categories":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://lincy.online/categories/杂七杂八/"}],"tags":[]},{"title":"分布式服务治理-Dubbo","slug":"分布式服务治理-Dubbo","date":"2018-09-23T09:26:52.000Z","updated":"2018-10-10T00:05:43.458Z","comments":true,"path":"2018/09/23/分布式服务治理-Dubbo/","link":"","permalink":"https://lincy.online/2018/09/23/分布式服务治理-Dubbo/","excerpt":"","text":"Dubbo 是什么Dubbo是一个分布式的服务框架，提供高性能的以及透明化的RPC远程服务调用解决方法，以及SOA服务治理方案。 远程通信 集群容错 服务的自动发现 负债均衡 架构 节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 调用关系说明 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo 架构具有以下几个特点，分别是连通性、健壮性、伸缩性、以及向未来架构的升级性。 连通性 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小 监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示 服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间不包含网络开销 服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间包含网络开销 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表 注册中心和监控中心都是可选的，服务消费者可以直连服务提供者 健壮性 监控中心宕掉不影响使用，只是丢失部分采样数据 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务 注册中心对等集群，任意一台宕掉后，将自动切换到另一台 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯 服务提供者无状态，任意一台宕掉后，不影响使用 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 伸缩性 注册中心为对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心 服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者 升级性当服务集群规模进一步扩大，带动IT治理结构进一步升级，需要实现动态部署，进行流动计算，现有分布式服务架构不会带来阻力。下图是未来可能的一种架构： 节点角色说明 节点 角色说明 Deployer 自动部署服务的本地代理 Repository 仓库用于存储服务应用发布包 Scheduler 调度中心基于访问压力自动增减服务提供者 Admin 统一管理控制台 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心","categories":[],"tags":[]},{"title":"分布式服务zookeeper应用场景","slug":"分布式服务zookeeper应用场景","date":"2018-09-21T16:01:26.000Z","updated":"2018-09-22T14:22:30.450Z","comments":true,"path":"2018/09/22/分布式服务zookeeper应用场景/","link":"","permalink":"https://lincy.online/2018/09/22/分布式服务zookeeper应用场景/","excerpt":"数据发布订阅/配置中心实现配置信息的集中式管理和数据的动态更新 实现配置中心有两种模式：push 、pull。 zookeeper采用的是推拉相结合的方式。 客户端向服务器端注册自己需要关注的节点。一旦节点数据发生变化，那么服务器端就会向客户端发送watcher事件通知。客户端收到通知后，主动到服务器端获取更新后的数据。 配置中心数据要求： 数据量比较小 数据内容在运行时会发生动态变更 集群中的各个机器共享配置 配置中心实现原理","text":"数据发布订阅/配置中心实现配置信息的集中式管理和数据的动态更新 实现配置中心有两种模式：push 、pull。 zookeeper采用的是推拉相结合的方式。 客户端向服务器端注册自己需要关注的节点。一旦节点数据发生变化，那么服务器端就会向客户端发送watcher事件通知。客户端收到通知后，主动到服务器端获取更新后的数据。 配置中心数据要求： 数据量比较小 数据内容在运行时会发生动态变更 集群中的各个机器共享配置 配置中心实现原理 负载均衡把ZooKeeper作为一个服务的注册中心，在其中登记每个服务，每台服务器知道自己是属于哪个服务，在服务器启动时，自己向所属服务进行登记，这样，一个树形的服务结构就呈现出来了 服务的调用者到注册中心里面查找：能提供所需服务的服务器列表，然后自己根据负载均衡算法，从中选取一台服务器进行连接 调用者取到服务器列表后，就可以缓存到自己内部，省得下次再取，当服务器列表发生变化，例如某台服务器宕机下线，或者新加了服务器，ZooKeeper会自动通知调用者重新获取服务器列表 由于ZooKeeper并没有内置负载均衡策略，需要调用者自己实现，这个方案只是利用了ZooKeeper的树形数据结构、watcher机制等特性，把ZooKeeper作为服务的注册和变更通知中心，解决了Nginx负载均衡方案带来的问题:（1）配置维护的成本变高，因为节点太多（2）单点故障的风险增加了，因为热点服务的访问量很高，如果这个服务集群内的负载均衡服务出现问题，这个服务将失效 分布式锁通常实现分布式锁有几种方式: redis。 setNX 存在则会返回0， 不存在 数据方式去实现, 2种方式 创建一个表， 通过索引唯一的方式create table (id , methodname …) methodname增加唯一索引insert 一条数据XXX delete 语句删除这条记录 mysql innodb select for update zookeeper实现： 排他锁客户端写入临时节点，利用节点名称不能相同的特性 共享锁 利用有序节点特性。 分布式进程在读写一个共享数据时，可以先在某个公共目录下创建一个有序子目录，然后判断该目录id是否最小。 目录id最小则获得锁并消费共享数据，然后删除该目录。否则则等待，直到自己的目录id成为最小后，才获得锁。 zookeeper所有目录操作事件都可以注册监听器，所以分布式进程不必循环查询子目录判断自己的目录id是否最小，可以注册一个监听器在前一个目录上，监听前一个目录是否被删除。 命名服务master 选举","categories":[],"tags":[]},{"title":"分布式协调服务zookeeper","slug":"分布式协调服务zookeeper","date":"2018-09-17T15:58:44.000Z","updated":"2018-10-13T02:35:37.876Z","comments":true,"path":"2018/09/17/分布式协调服务zookeeper/","link":"","permalink":"https://lincy.online/2018/09/17/分布式协调服务zookeeper/","excerpt":"分布式环境的特点 分布式 并发性程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源。数据库、分布式存储。 无序性进程间的消息通信，会出现顺序不一致的情况。","text":"分布式环境的特点 分布式 并发性程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源。数据库、分布式存储。 无序性进程间的消息通信，会出现顺序不一致的情况。 分布式面临的问题 网络通信网络本身不可靠 网络分区（脑裂）当网络发生异常导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式架构的所有节点，只有部分节点能够正常通信。 三态成功、失败、超时 分布式事务ACID（原子性、一致性、隔离性、持久性） 中心化和去中心化冷备或者热备 分布式架构里面，很多的架构思想采用的是：当集群发生故障的时候，集群中的人群会自动“选举”出一个新的领导。最典型的是： zookeeper / etcd CAP/BASE 理论CAPC（一致性Consistency）：所有节点上的数据，时刻保持一致A（可用性Availability）：每个请求都能够收到一个响应，无论响应成功或者失败P（分区容错Partition-tolerance）：表示系统出现脑裂以后，可能导致某些Server与集群中的其他机器失去联系 CP / AP CAP理论仅适用于原子读写的Nosql场景，不适用于数据库系统 BASE基于CAP理论，CAP理论并不适用于数据库事务（因为更新一些错误的数据而导致数据出现紊乱，无论什么样的数据库高可用方案都是徒劳） ，虽然XA事务可以保证数据库在分布式系统下的ACID特性，但是会带来性能方面的影响； eBay尝试了一种完全不同的套路，放宽了对事务ACID的要求。提出了BASE理论Basically available ： 数据库采用分片模式， 把100W的用户数据分布在5个实例上。如果破坏了其中一个实例，仍然可以保证80%的用户可用 soft-state： 在基于client-server模式的系统中，server端是否有状态，决定了系统是否具备良好的水平扩展、负载均衡、故障恢复等特性。Server端承诺会维护client端状态数据，这个状态仅仅维持一小段时间, 这段时间以后，server端就会丢弃这个状态，恢复正常状态 Eventually consistent：数据的最终一致性 zookeeper能做什么数据的发布/订阅（配置中心:disconf）负载均衡（dubbo利用了zookeeper机制实现负载均衡）命名服务master选举(kafka、hadoop、hbase)分布式队列分布式锁 zookeeper的特性 顺序一致性从同一个客户端发起的事务请求，最终会严格按照顺序被应用到zookeeper中。 原子性所有的事务请求的处理结果在整个集群中的所有机器上的应用情况是一致的，也就是说，要么整个集群中的所有机器都成功应用了某一事务，要么全都不应用 可靠性一旦服务器成功应用了某一个事务数据，并且对客户端做了响应，那么这个数据在整个集群中一定是同步并且保留下来的。 实时性一旦一个事务被成功应用，客户端就能够立即从服务器端读取到事务变更后的最新数据状态；（zookeeper仅仅保证在一定时间内，近实时） zookeeper 安装单机环境安装 下载zookeeper的安装包http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gz 解压zookeepertar -zxvf zookeeper-3.4.10.tar.gz cd 到 ZK_HOME/conf , copy一份zoo.cfgcp zoo_sample.cfg zoo.cfg sh zkServer.sh{start|start-foreground|stop|restart|status|upgrade|print-cmd} sh zkCli.sh -server ip:port 集群环境zookeeper集群, 包含三种角色: leader / follower /observer observer 是一种特殊的zookeeper节点。可以帮助解决zookeeper的扩展性（如果大量客户端访问我们zookeeper集群，需要增加zookeeper集群机器数量。从而增加zookeeper集群的性能。 导致zookeeper写性能下降， zookeeper的数据变更需要半数以上服务器投票通过。造成网络消耗增加投票成本） observer不参与投票。 只接收投票结果。 不属于zookeeper的关键部位。 集群配置 每一行此配置表示一个集群中的一台服务器。其中id为Server ID，用来标识该机器在集群中的编号。同时，在所在服务器的数据目录（/tmp/zookeeper）下创建一个myid文件，该文件只有一行内容，并且是一个数字，就是对应每台服务器的Server ID数字。 比如server.1=IP1:2888:3888的myid中的内容就是1。不同服务器的ID需要保持不同，并且和zoo.cfg文件中server.id中的id和myid文件的内容保持一致。id的取值范围为1~255。 其中，server.id中配置参数的第一个port是集群中其他机器与Leader之间通信的端口，第二个port为当Leader宕机或其他故障时，集群进行重新选举Leader时使用的端口。 按照以上相同步骤，配置集群中的其他机器。每个集群的zoo.cfg文件都是相同的，可通过版本控制或其他工具保证每台zookeeper服务器的配置文件相同。集群中每台机器唯一不同的是server.id对应的myid文件中的数字不同。server.id=host:port:portid的取值范围： 1~255； 用id来标识该机器在集群中的机器序号2182是follower节点与leader节点交换信息的端口号；3181表示leader节点挂掉了, 需要一个端口来重新选举。 server.1=192.168.11.129:2182:3181server.2=192.168.11.131:2182:3181server.3=192.168.11.135:2182:3181 observer配置 peerType=observerserver.1=192.168.11.129:2182:3181:observerserver.2=192.168.11.131:2182:3181server.3=192.168.11.135:2182:3181 zoo.cfg tickTime=2000 zookeeper中最小的时间单位长度 （ms） initLimit=10 follower节点启动后与leader节点完成数据同步的时间 syncLimit=5 leader节点和follower节点进行心跳检测的最大延时时间 dataDir=/tmp/zookeeper 表示zookeeper服务器存储快照文件的目录 dataLogDir 表示配置 zookeeper事务日志的存储路径，默认指定在dataDir目录下 clientPort 表示客户端和服务端建立连接的端口号： 2181 zookeeper 的一些概念zookeeper的数据模型和文件系统类似，每一个节点称为：znode. 是zookeeper中的最小数据单元。每一个znode上都可以 保存数据和挂载子节点。 从而构成一个层次化的属性结构 节点特性： 持久化节点 ： 节点创建后会一直存在zookeeper服务器上，直到主动删除 持久化有序节点 ：每个节点都会为它的一级子节点维护一个顺序 临时节点 ： 临时节点的生命周期和客户端的会话保持一致。当客户端会话失效，该节点自动清理 临时有序节点 ： 在临时节点上多了一个顺序性特性 zookee 的命令操作 create [-s] [-e] path data acl-s 表示节点是否有序-e 表示是否为临时节点默认情况下，是持久化节点 ACL zookeeper提供控制节点访问权限的功能，用于有效的保证zookeeper中数据的安全性。避免误操作而导致系统出现重大事故。 CREATE /READ/WRITE/DELETE/ADMIN get path [watch]获得指定 path的信息 Watcherzookeeper提供了分布式数据发布/订阅,zookeeper允许客户端向服务器注册一个watcher监听。当服务器端的节点触发指定事件的时候会触发watcher。服务端会向客户端发送一个事件通知 watcher的通知是一次性，一旦触发一次通知后，该watcher就失效 set path data [version]修改节点 path对应的data乐观锁的概念数据库里面有一个 version 字段去控制数据行的版本号 delete path [version]删除节点 stat信息cversion = 0 子节点的版本号aclVersion = 0 表示acl的版本号，修改节点权限dataVersion = 1 表示的是当前节点数据的版本号 czxid 节点被创建时的事务IDmzxid 节点最后一次被更新的事务IDpzxid 当前节点下的子节点最后一次被修改时的事务ID ctime = Sat Aug 05 20:48:26 CST 2017mtime = Sat Aug 05 20:48:50 CST 2017 cZxid = 0x500000015ctime = Sat Aug 05 20:48:26 CST 2017mZxid = 0x500000016mtime = Sat Aug 05 20:48:50 CST 2017pZxid = 0x500000015cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0 创建临时节点的时候，会有一个sessionId 。 该值存储的就是这个sessioniddataLength = 3 数据值长度numChildren = 0 子节点数 Java API权限控制模式schema：授权对象ip : 192.168.1.1Digest : username:passwordworld : 开放式的权限控制模式，数据节点的访问权限对所有用户开放。 world:anyonesuper ：超级用户，可以对zookeeper上的数据节点进行操作 连接状态KeeperStat.Expired 在一定时间内客户端没有收到服务器的通知， 则认为当前的会话已经过期了。KeeperStat.Disconnected 断开连接的状态KeeperStat.SyncConnected 客户端和服务器端在某一个节点上建立连接，并且完成一次version、zxid同步KeeperStat.authFailed 授权失败事件类型NodeCreated 当节点被创建的时候，触发NodeChildrenChanged 表示子节点被创建、被删除、子节点数据发生变化（子节点删除、新增的时候才会触发，子节点数据变更不会触发）NodeDataChanged 节点数据发生变化NodeDeleted 节点被删除None 客户端和服务器端连接状态发生变化的时候，事件类型就是None zookeeper的实际应用场景 订阅发布 watcher机制 统一配置管理（disconf） 分布式锁 redis zookeeper 数据库 负载均衡 ID生成器 分布式队列 统一命名服务 master选举 master选举 zookeeper 集群角色 leader 事务请求的唯一调度者和处理者，保证集群事务处理的顺序性 集群内部各个服务器的调度者 follower 处理客户端非事务请求，以及转发事务请求给leader服务器 参与事务请求提议（proposal）的投票（客户端的一个事务请求，需要半数服务器投票通过以后才能通知leader commit； leader会发起一个提案，要求follower投票） 参与leader选举的投票 observer观察zookeeper集群中最新状态的变化并将这些状态同步到observer服务器上。增加observer不影响集群中事务处理能力，同时还能提升集群的非事务处理能力 zookeeper 集群组成zk集群要求集群的机器数为奇数（2n+1），并且任何时刻，存活的机器必须大于n+1，否则集群挂掉； leader选举三种算法： leaderElection AuthFastLeaderElection FastLeaderElection（默认） FastLeaderElection 选举流程几个概念: serverid : 在配置server集群的时候，给定服务器的标识id（myid） zxid : 服务器在运行时产生的数据ID， zxid的值越大，表示数据越新 Epoch: 选举的轮数 server的状态：Looking、 Following、Observering、Leading 选举流程，第一次初始化启动的时候服务器状态为Looking 所有在集群中的server都会 推荐自己为leader，然后 把（myid、zxid、epoch）作为广播信息，广播给集群中的其他server, 然后 等待其他服务器返回 每个服务器都会 接收来自集群中的其他服务器的投票。集群中的每个服务器在接受到投票后，开始判断投票的有效性 判断逻辑时钟(Epoch) ，如果Epoch大于自己当前的Epoch，说明自己保存的Epoch是过期。更新Epoch，同时clear其他服务器发送过来的选举数据。判断是否需要更新当前自己的选举情况 如果Epoch小于目前的Epoch，说明对方的epoch过期了，也就意味着对方服务器的选举轮数是过期的。这个时候，只需要讲自己的信息发送给对方 如果epoch等于目前的epoch，根据规则来判断是否有资格获得leader 接收来自其他服务器的投票后，针对每一个投票，都需要将别人的投票和自己的投票进行PK zxid，zxid最大的服务器优先 ZAB协议ZAB协议（Zookeeper atomic broadcast），基于paxos协议的一个改进。 在zookeeper 的主备模式下，通过zab协议来保证集群中各个副本数据的一致性 zookeeper使用的是单一的主进程来接收并处理所有的事务请求，并采用zab协议， 把数据的状态变更以事务请求的形式广播到其他的节点 zab协议在主备模型架构中，保证了同一时刻只能有一个主进程来广播服务器的状态变更 所有的事务请求必须由全局唯一的服务器来协调处理，这个的服务器叫leader，其他的叫follower。 leader节点主要负责把客户端的事务请求转化成一个事务提议（proposal），并分发给集群中的所有follower节点, 再等待所有follower节点的反馈。一旦超过半数服务器进行了正确的反馈，那么leader就会commit这条消息 ZAB协议的工作原理 什么情况下zab协议会进入 崩溃恢复 模式 当服务器启动时 当leader服务器出现网络中断、崩溃或者重启的情况 集群中已经不存在过半的服务器与该leader保持正常通信 zab协议进入崩溃恢复模式会做什么 当leader出现问题，zab协议进入崩溃恢复模式，并且选举出新的leader。当新的leader选举出来以后，如果集群中已经有过半机器完成了leader服务器的状态同（数据同步），退出崩溃恢复，进入 消息广播模式 当新的机器加入到集群中的时候，如果已经存在leader服务器，那么新加入的服务器就会自觉进入数据恢复模式，找到leader进行数据同步 问题假设一个事务在leader服务器被提交了，并且已经有过半的follower返回了ack。 在leader节点把commit消息发送给folower机器之前, leader服务器挂了怎么办? zab协议，一定需要保证已经被leader提交的事务也能够被所有follower提交zab协议需要保证，在崩溃恢复过程中跳过哪些已经被丢弃的事务 zookeeper 数据存储内存数据和磁盘数据，zookeeper会定时吧数据存储在磁盘上 DataDir: 存储数据快照 快照： 存储某一个时刻全量的内存数据内容 DataLogDir: 存储事务日志 查看事务日志的命令java -cp :~/zookeeper-3.4.10/lib/slf4j-api-1.6.1.jar:~/zookeeper-3.4.10/zookeeper-3.4.10.jar org.apache.zookeeper.server.LogFormatter log.200000001 zookeeper 有三种日志zookeeper.out //运行日志快照 存储某一时刻的全量数据事务日志 事务操作的日志记录","categories":[],"tags":[]},{"title":"分布式通信协议-HTTP","slug":"分布式通信协议-HTTP","date":"2018-08-30T15:34:31.000Z","updated":"2018-09-22T02:55:36.746Z","comments":true,"path":"2018/08/30/分布式通信协议-HTTP/","link":"","permalink":"https://lincy.online/2018/08/30/分布式通信协议-HTTP/","excerpt":"HTTP协议概述 客户端和服务端","text":"HTTP协议概述 客户端和服务端 资源html/文本、word、avi等等 媒体类型MIME类型。text/html、image/jpeg、application/json等等 URI和URLURI：服务器资源的名字。index.htmlURL:网络资源描述 http://lincy.online/2018/08/30/分布式通信协议-HTTP schema: http/https/ftp host: web服务器的IP地址或域名。 path: 资源访问路径。 query-string: 查询参数。 method，方法get/put/delete/post/patch/head 报文 状态码 1XX 提示信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器端的错误 缓存 HTTPShttps工作原理 第一步，使用对称加解密 第二步，密钥是公开的，所有的客户端都可以拿到 第三步 针对不同的客户端使用不同的密钥 问题：协商过程是没有加密的，所以还会出现被截断的问题 第四步：使用非对称加密（公钥、私钥） 客户端如何拿到公钥： 服务器端把公钥发送给每一个客户端 服务器端把公钥放到远程服务器，客户端可以请求到 让浏览器保存所有的公钥（不现实） 第五步 公钥被调包的问题按照上面的方案，永远存在。 第六步：使用第三方机构来解决 通过第三方机构，使用第三方机构的私钥对我们【需要传输的公钥】进行加密 问题：数字证书有可能颁发给了窃密者 第七步：数字证里面包含的内容： 公司信息、网站信息、数字证书的算法、公钥 http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html https握手过程： 客户端发起一个https请求a) 客户端支持的加密方式b) 客户端生成的随机数（第一个随机数）c) 协议版本号 服务端收到请求后，拿到随机数，返回a) 证书（颁发机构（CA）、证书内容本身的数字签名（使用第三方机构的私钥加密）、证书持有者的公钥、证书签名用到的hash算法）b) 生成一个随机数，返回给客户端（第二个随机数） 客户端拿到证书以后做验证a) 根据颁发机构找到本地的跟证书b) 根据CA得到根证书的公钥，通过公钥对数字签名解密，得到证书的内容摘要 Ac) 用证书提供的算法对证书内容进行摘要，得到摘要 Bd) 通过A和B的对比，也就是验证数字签名 验证通过以后，生成一个随机数（第三个随机数），通过证书内的公钥对这个随机数加密，发送给服务器端 （随机数1+2+3）通过对称加密得到一个密钥。（会话密钥） 通过会话密钥对内容进行对称加密传输 RESTful 在REST中，一切的内容都被认为是一种资源 每个资源都由URI唯一标识 使用统一的接口处理资源请求（POST/GET/PUT/DELETE/HEAD） 无状态","categories":[],"tags":[]},{"title":"分布式通信-序列化","slug":"分布式通信-序列化","date":"2018-08-30T14:06:59.000Z","updated":"2018-08-30T15:34:00.853Z","comments":true,"path":"2018/08/30/分布式通信-序列化/","link":"","permalink":"https://lincy.online/2018/08/30/分布式通信-序列化/","excerpt":"Java序列化机制 —— Serialize接口 数据结果大、传输效率低 不能跨语言","text":"Java序列化机制 —— Serialize接口 数据结果大、传输效率低 不能跨语言 如何实现Java序列化操作： 实现Serializable接口 ObjectInputStream： 读取字节数据转换成对象 ObjectOuputStream： 将对象转换成直接数据 serialVersionUID的作用：保证序列化的对象和反序列化后的对象是同一个，对类的签名。 transient 关键字：不参与序列化。父子类问题如果父类没有实现序列化，而子类实现列序列化。那么父类中的成员没办法做序列化操作 序列化的存储规则对同一个对象进行多次写入，打印出的第一次存储结果和第二次存储结果，只多了5个字节的引用关系, 并不会导致文件累加。 XML对象序列化 跨语言，容易理解 基于XML的SOAP协议和对应的WebService框架在很长一段时间成为主流的技术。 基于JSON的HTTP REST接口 相比XML更简单易用，基本上取代了复杂的Web Service接口，成为分布式框架中远程通信的首要选择。 仍然存在占用空间大、性能低的问题。 主流的序列化技术 JSON XML Protobuf 字节数小 速度快 Hessian 序列化速度比protobuf更快，但是字节数更大 ProtoStuff MsgPack thrift FST Avro","categories":[],"tags":[]},{"title":"分布式通信协议","slug":"分布式通信协议","date":"2018-08-29T18:26:33.000Z","updated":"2018-08-30T15:04:54.535Z","comments":true,"path":"2018/08/30/分布式通信协议/","link":"","permalink":"https://lincy.online/2018/08/30/分布式通信协议/","excerpt":"网络协议tcp/ip TCP五层模型 OSI七层 OSI模型多了表达层、会话层","text":"网络协议tcp/ip TCP五层模型 OSI七层 OSI模型多了表达层、会话层 tcp三次握手 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手协议三次握手耳熟能详，四次挥手估计就听得比较少了，所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。 udp协议tcp通信原理首先，对于TCP通信来说，每个TCP Socket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态。 接收缓冲区把数据缓存到内核，若应用进程一直没有调用Socket的read方法进行读取，那么该数据会一直被缓存在接收缓冲区内。不管进程是否读取Socket，对端发来的数据都会经过内核接收并缓存到Socket的内核接收缓冲区。read索要做的工作，就是把内核接收缓冲区中的数据复制到应用层用户的Buffer里。 进程调用Socket的send发送数据的时候，一般情况下是讲数据从应用层用户的Buffer里复制到Socket的内核发送缓冲区，然后send就会在上层返回。换句话说，send返回时，数据不一定会被发送到对端。 滑动窗口协议发送方和接收方都会维护一个数据帧的序列，这个序列被称作窗口。发送方的窗口大小由接收方确认，目的是控制发送速度，以免接收方的缓存不够大导致溢出，同时控制流量也可以避免网络拥塞。下面图中的4,5,6号数据帧已经被发送出去，但是未收到关联的ACK，7,8,9帧则是等待发送。可以看出发送端的窗口大小为6，这是由接受端告知的（事实上必须考虑拥塞窗口cwnd，这里暂且考虑cwnd&gt;rwnd）。此时如果发送端收到4号ACK，则窗口的左边缘向右收缩，窗口的右边缘则向右扩展，此时窗口就向前“滑动了”，即数据帧10也可以被发送 明白了Socket读写数据的底层原理，我们就很容易理解“阻塞模式”：对于读取Socket数据的过程而言，如果接收缓冲区为空，则调用Socket的read方法的线程会阻塞，知道有数据进入接收缓冲区；而对于写数据到Socket中的线程来说，如果待发送的数据长度大于发送缓冲区空余长度，则会阻塞在write方法上，等待发送缓冲区的报文被发送到网络上，然后继续发送下一段数据，循环上述过程直到数据都被写入到发送缓冲区为止 从前面分析的过程来看，传统的Socket阻塞模式直接导致每个Socket都必须绑定一个线程来操作数据，参与通信的任意一方如果处理数据的速度较慢，会直接拖累到另一方，导致另一方的线程不得不浪费大量的时间在I/O等待上，所以这就是Socket阻塞模式的“缺陷”。 但是这种模式在少量的TCP连接通信的情况下，双方都可以快速的传输数据，这个时候的性能是最高的。 BIO（同步阻塞）NIO（同步非阻塞）AIO（异步非阻塞） Multicst(组播) 单播 广播 组播 java api socket操作","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://lincy.online/tags/分布式/"}]},{"title":"分布式架构概述","slug":"分布式架构概述","date":"2018-08-29T17:00:40.000Z","updated":"2018-08-30T15:04:38.554Z","comments":true,"path":"2018/08/30/分布式架构概述/","link":"","permalink":"https://lincy.online/2018/08/30/分布式架构概述/","excerpt":"特点：高并发、海量数据什么是分布式 任务分解 节点通信","text":"特点：高并发、海量数据什么是分布式 任务分解 节点通信 分布式架构发展第一版 第二版单机负载越来越高，数据库和应用服务器分离 第三版应用服务器做集群 引入问题: session共享 session sticky session replication session 集中存储（db、缓存） cookie (保存在cookie，不保存在服务端) access_token(userid/token/timestamp) 请求转发第四版数据库高性能操作 引入问题： 数据库读写分离 数据库的数据同步 数据库路由（mycat） 第五版 引入问题： 搜索引擎的索引数据同步？实时增量同步？定时全量同步? 第六版用户无上限，解决方式： 缓存 限流 降级 第七版数据库的水平/垂直拆分 第八版应用拆分 SOA 微服务","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://lincy.online/tags/分布式/"}]},{"title":"HashMap源码解析","slug":"HashMap源码解析","date":"2018-07-12T12:08:26.000Z","updated":"2018-07-17T17:10:27.403Z","comments":true,"path":"2018/07/12/HashMap源码解析/","link":"","permalink":"https://lincy.online/2018/07/12/HashMap源码解析/","excerpt":"","text":"本文基于JDK1.8 HashMap 数据结构在JDK1.8中HashMap进行了优化，桶除了链表，还新增了红黑树的数据结构，加快查找速度 类声明 HashMap 构造函数 initialCapacity：初始容量。 loadFactor（默认值为0.75）：负载因子。负载因子表示哈希表在扩充容量之前可以达到多满的尺度，负载因子越大，填充程度越高。 public HashMap() public HashMap(int initialCapacity) public HashMap(int initialCapacity, float loadFactor) 看一下第三个构造函数： public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } shreshold指HashMap容量达到多少时，HashMap会扩容，根据以上描述，可以很简单的认为 shreshold = capacity * loadFactor。 在初始化HashMap时shreshold先被赋值为initial capacity。 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } put方法 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&#39;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 如果HashMap为空，则初始化 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } resize()方法初始化表大小或扩容 final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // capacity &gt; 0 的情况，对应需要扩容的情景 if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { // 如果原先容量已经到了最大值，则无法扩容，直接返回 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // shreshold翻倍 newThr = oldThr &lt;&lt; 1; } // capacity==0的情况，HashMap刚刚经过初始化还没有值的情景 else if (oldThr &gt; 0) // 构造函数（2）（3）初始化HashMap时threshold被设定为initialCapacity newCap = oldThr; else { // zero initial threshold signifies using defaults //threshold==0, 使用默认配置，对应无参构造函数（1）的情景 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) // 桶中只有一个元素 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 桶为红黑树 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order // 桶为数组 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; }","categories":[],"tags":[{"name":"JDK源码","slug":"JDK源码","permalink":"https://lincy.online/tags/JDK源码/"}]},{"title":"[转载]从实际案例聊聊Java应用的GC优化","slug":"转载-从实际案例聊聊Java应用的GC优化","date":"2018-04-20T23:55:37.000Z","updated":"2018-10-22T03:24:15.194Z","comments":true,"path":"2018/04/21/转载-从实际案例聊聊Java应用的GC优化/","link":"","permalink":"https://lincy.online/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/","excerpt":"美团技术团队： https://tech.meituan.com/jvm_optimize.html 当Java程序性能达不到既定目标，且其他优化手段都已经穷尽时，通常需要调整垃圾回收器来进一步提高性能，称为GC优化。但GC算法复杂，影响GC性能的参数众多，且参数调整又依赖于应用各自的特点，这些因素很大程度上增加了GC优化的难度。即便如此，GC调优也不是无章可循，仍然有一些通用的思考方法。本篇会介绍这些通用的GC优化策略和相关实践案例，主要包括如下内容： 优化前准备: 简单回顾JVM相关知识、介绍GC优化的一些通用策略。优化方法: 介绍调优的一般流程：明确优化目标→优化→跟踪优化结果。优化案例: 简述笔者所在团队遇到的GC问题以及优化方案。","text":"美团技术团队： https://tech.meituan.com/jvm_optimize.html 当Java程序性能达不到既定目标，且其他优化手段都已经穷尽时，通常需要调整垃圾回收器来进一步提高性能，称为GC优化。但GC算法复杂，影响GC性能的参数众多，且参数调整又依赖于应用各自的特点，这些因素很大程度上增加了GC优化的难度。即便如此，GC调优也不是无章可循，仍然有一些通用的思考方法。本篇会介绍这些通用的GC优化策略和相关实践案例，主要包括如下内容： 优化前准备: 简单回顾JVM相关知识、介绍GC优化的一些通用策略。优化方法: 介绍调优的一般流程：明确优化目标→优化→跟踪优化结果。优化案例: 简述笔者所在团队遇到的GC问题以及优化方案。 一、优化前的准备GC优化需知为了更好地理解本篇所介绍的内容，你需要了解如下内容。 GC相关基础知识，包括但不限于：a) GC工作原理。b) 理解新生代、老年代、晋升等术语含义。c) 可以看懂GC日志。 GC优化不能解决一切性能问题，它是最后的调优手段。 如果对第一点中提及的知识点不是很熟悉，可以先阅读小结-JVM基础回顾；如果已经很熟悉，可以跳过该节直接往下阅读。 JVM基础回顾JVM内存结构简单介绍一下JVM内存结构和常见的垃圾回收器。 当代主流虚拟机（Hotspot VM）的垃圾回收都采用“分代回收”的算法。“分代回收”是基于这样一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。 Hotspot VM将内存划分为不同的物理区，就是“分代”思想的体现。如图所示，JVM内存主要由新生代、老年代、永久代构成。 ① 新生代（Young Generation）：大多数对象在新生代中被创建，其中很多对象的生命周期很短。每次新生代的垃圾回收（又称Minor GC）后只有少量对象存活，所以选用复制算法，只需要少量的复制成本就可以完成回收。 新生代内又分三个区：一个Eden区，两个Survivor区（一般而言），大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到两个Survivor区（中的一个）。当这个Survivor区满时，此区的存活且不满足“晋升”条件的对象将被复制到另外一个Survivor区。对象每经历一次Minor GC，年龄加1，达到“晋升年龄阈值”后，被放到老年代，这个过程也称为“晋升”。显然，“晋升年龄阈值”的大小直接影响着对象在新生代中的停留时间，在Serial和ParNew GC两种回收器中，“晋升年龄阈值”通过参数MaxTenuringThreshold设定，默认值为15。 ② 老年代（Old Generation）：在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。 ③ 永久代（Perm Generation）：主要存放元数据，例如Class、Method的元信息，与垃圾回收要回收的Java对象关系不大。相对于新生代和年老代来说，该区域的划分对垃圾回收影响比较小。 常见垃圾回收器不同的垃圾回收器，适用于不同的场景。常用的垃圾回收器： 串行（Serial）回收器是单线程的一个回收器，简单、易实现、效率高。 并行（ParNew）回收器是Serial的多线程版，可以充分的利用CPU资源，减少回收的时间。 吞吐量优先（Parallel Scavenge）回收器，侧重于吞吐量的控制。 并发标记清除（CMS，Concurrent Mark Sweep）回收器是一种以获取最短回收停顿时间为目标的回收器，该回收器是基于“标记-清除”算法实现的。 GC日志每一种回收器的日志格式都是由其自身的实现决定的，换而言之，每种回收器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个回收器的日志都维持一定的共性。JavaGC日志 中简单介绍了这些共性。 参数基本策略各分区的大小对GC的性能影响很大。如何将各分区调整到合适的大小，分析活跃数据的大小是很好的切入点。 活跃数据的大小是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是Full GC后堆中老年代占用空间的大小。可以通过GC日志中Full GC之后老年代数据大小得出，比较准确的方法是在程序稳定后，多次获取GC数据，通过取平均值的方式计算活跃数据的大小。活跃数据和各分区之间的比例关系如下（见参考文献1）： 空间 倍数 总大小 3-4 倍活跃数据的大小 新生代 1-1.5 活跃数据的大小 老年代 2-3 倍活跃数据的大小 永久代 1.2-1.5 倍Full GC后的永久代空间占用 例如，根据GC日志获得老年代的活跃数据大小为300M，那么各分区大小可以设为： 总堆：1200MB = 300MB × 4新生代：450MB = 300MB × 1.5老年代： 750MB = 1200MB - 450MB* 这部分设置仅仅是堆大小的初始值，后面的优化中，可能会调整这些值，具体情况取决于应用程序的特性和需求。 二、优化步骤GC优化一般步骤可以概括为：确定目标、优化参数、验收结果。 确定目标明确应用程序的系统需求是性能优化的基础，系统的需求是指应用程序运行时某方面的要求，譬如： 高可用，可用性达到几个9。 低延迟，请求必须多少毫秒内完成响应。 高吞吐，每秒完成多少次事务。 明确系统需求之所以重要，是因为上述性能指标间可能冲突。比如通常情况下，缩小延迟的代价是降低吞吐量或者消耗更多的内存或者两者同时发生。 由于笔者所在团队主要关注高可用和低延迟两项指标，所以接下来分析，如何量化GC时间和频率对于响应时间和可用性的影响。通过这个量化指标，可以计算出当前GC情况对服务的影响，也能评估出GC优化后对响应时间的收益，这两点对于低延迟服务很重要。 举例：假设单位时间T内发生一次持续25ms的GC，接口平均响应时间为50ms，且请求均匀到达，根据下图所示： 那么有(50ms+25ms)/T比例的请求会受GC影响，其中GC前的50ms内到达的请求都会增加25ms，GC期间的25ms内到达的请求，会增加0-25ms不等，如果时间T内发生N次GC，受GC影响请求占比=(接口响应时间+GC时间)×N/T 。可见无论降低单次GC时间还是降低GC次数N都可以有效减少GC对响应时间的影响。 优化通过收集GC信息，结合系统需求，确定优化方案，例如选用合适的GC回收器、重新设置内存比例、调整JVM参数等。 进行调整后，将不同的优化方案分别应用到多台机器上，然后比较这些机器上GC的性能差异，有针对性的做出选择，再通过不断的试验和观察，找到最合适的参数。 验收优化结果将修改应用到所有服务器，判断优化结果是否符合预期，总结相关经验。 接下来，我们通过三个案例来实践以上的优化流程和基本原则（本文中三个案例使用的垃圾回收器均为ParNew+CMS，CMS失败时Serial Old替补)。 三、GC优化案例案例一 Major GC和Minor GC频繁确定目标服务情况：Minor GC每分钟100次 ，Major GC每4分钟一次，单次Minor GC耗时25ms，单次Major GC耗时200ms，接口响应时间50ms。 由于这个服务要求低延时高可用，结合上文中提到的GC对服务响应时间的影响，计算可知由于Minor GC的发生，12.5%的请求响应时间会增加，其中8.3%的请求响应时间会增加25ms，可见当前GC情况对响应时间影响较大。 （50ms+25ms）× 100次/60000ms = 12.5%，50ms × 100次/60000ms = 8.3% 。 优化目标：降低TP99、TP90时间。 优化首先优化Minor GC频繁问题。通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁Minor GC，因此可以通过增大新生代空间来降低Minor GC的频率。例如在相同的内存分配率的前提下，新生代中的Eden区增加一倍，Minor GC的次数就会减少一半。 这时很多人有这样的疑问，扩容Eden区虽然可以减少Minor GC的次数，但会增加单次Minor GC时间么？根据上面公式，如果单次Minor GC时间也增加，很难保证最后的优化效果。我们结合下面情况来分析，单次Minor GC时间主要受哪些因素影响？是否和新生代大小存在线性关系？首先，单次Minor GC时间由以下两部分组成：T1（扫描新生代）和 T2（复制存活对象到Survivor区）如下图。（注：这里为了简化问题，我们认为T1只扫描新生代判断对象是否存活的时间，其实该阶段还需要扫描部分老年代，后面案例中有详细描述。） 扩容前：新生代容量为R ，假设对象A的存活时间为750ms，Minor GC间隔500ms，那么本次Minor GC时间= T1（扫描新生代R）+T2（复制对象A到S）。 扩容后：新生代容量为2R ，对象A的生命周期为750ms，那么Minor GC间隔增加为1000ms，此时Minor GC对象A已不再存活，不需要把它复制到Survivor区，那么本次GC时间 = 2 × T1（扫描新生代R），没有T2复制时间。 可见，扩容后，Minor GC时增加了T1（扫描时间），但省去T2（复制对象）的时间，更重要的是对于虚拟机来说，复制对象的成本要远高于扫描成本，所以，单次Minor GC时间更多取决于GC后存活对象的数量，而非Eden区的大小。因此如果堆中短期对象很多，那么扩容新生代，单次Minor GC时间不会显著增加。下面需要确认下服务中对象的生命周期分布情况： 通过上图GC日志中两处红色框标记内容可知： new threshold = 2（动态年龄判断，对象的晋升年龄阈值为2），对象仅经历2次Minor GC后就晋升到老年代，这样老年代会迅速被填满，直接导致了频繁的Major GC。 Major GC后老年代使用空间为300M+，意味着此时绝大多数(86% = 2G/2.3G)的对象已经不再存活，也就是说生命周期长的对象占比很小。 由此可见，服务中存在大量短期临时对象，扩容新生代空间后，Minor GC频率降低，对象在新生代得到充分回收，只有生命周期长的对象才进入老年代。这样老年代增速变慢，Major GC频率自然也会降低。 优化结果通过扩容新生代为为原来的三倍，单次Minor GC时间增加小于5ms，频率下降了60%，服务响应时间TP90，TP99都下降了10ms+，服务可用性得到提升。 调整前： 调整后： 小结如何选择各分区大小应该依赖应用程序中对象生命周期的分布情况：如果应用存在大量的短期对象，应该选择较大的年轻代；如果存在相对较多的持久对象，老年代应该适当增大。 更多思考关于上文中提到晋升年龄阈值为2，很多同学有疑问，为什么设置了MaxTenuringThreshold=15，对象仍然仅经历2次Minor GC，就晋升到老年代？这里涉及到“动态年龄计算”的概念。 动态年龄计算：Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值。在本案例中，调优前：Survivor区 = 64M，desired survivor = 32M，此时Survivor区中age&lt;=2的对象累计大小为41M，41M大于32M，所以晋升年龄阈值被设置为2，下次Minor GC时将年龄超过2的对象被晋升到老年代。 JVM引入动态年龄计算，主要基于如下两点考虑： 如果固定按照MaxTenuringThreshold设定的阈值作为晋升条件：a）MaxTenuringThreshold设置的过大，原本应该晋升的对象一直停留在Survivor区，直到Survivor区溢出，一旦溢出发生，Eden+Svuvivor中对象将不再依据年龄全部提升到老年代，这样对象老化的机制就失效了。b）MaxTenuringThreshold设置的过小，“过早晋升”即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的Major GC。分代回收失去了意义，严重影响GC性能。 相同应用在不同时间的表现不同：特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面相同的问题。 总结来说，为了更好的适应不同程序的内存情况，虚拟机并不总是要求对象年龄必须达到Maxtenuringthreshhold再晋级老年代。 案例二 请求高峰期发生GC，导致服务可用性下降确定目标GC日志显示，高峰期CMS在重标记（Remark）阶段耗时1.39s。Remark阶段是Stop-The-World（以下简称为STW）的，即在执行垃圾回收时，Java应用程序中除了垃圾回收器线程之外其他所有线程都被挂起，意味着在此期间，用户正常工作的线程全部被暂停下来，这是低延时服务不能接受的。本次优化目标是降低Remark时间。 优化解决问题前，先回顾一下CMS的四个主要阶段，以及各个阶段的工作内容。下图展示了CMS各个阶段可以标记的对象，用不同颜色区分。 Init-mark初始标记(STW) ，该阶段进行可达性分析，标记GC ROOT能直接关联到的对象，所以很快。 Concurrent-mark并发标记，由前阶段标记过的绿色对象出发，所有可到达的对象都在本阶段中标记。 Remark重标记(STW) ，暂停所有用户线程，重新扫描堆中的对象，进行可达性分析，标记活着的对象。因为并发标记阶段是和用户线程并发执行的过程，所以该过程中可能有用户线程修改某些活跃对象的字段，指向了一个未标记过的对象，如下图中红色对象在并发标记开始时不可达，但是并行期间引用发生变化，变为对象可达，这个阶段需要重新标记出此类对象，防止在下一阶段被清理掉，这个过程也是需要STW的。特别需要注意一点，这个阶段是以新生代中对象为根来判断对象是否存活的。 并发清理，进行并发的垃圾清理。 可见，Remark阶段主要是通过扫描堆来判断对象是否存活。那么准确判断对象是否存活，需要扫描哪些对象？CMS对老年代做回收，Remark阶段仅扫描老年代是否可行？结论是不可行，原因如下： 如果仅扫描老年代中对象，即以老年代中对象为根，判断对象是否存在引用，上图中，对象A因为引用存在新生代中，它在Remark阶段就不会被修正标记为可达，GC时会被错误回收。新生代对象持有老年代中对象的引用，这种情况称为“跨代引用”。因它的存在，Remark阶段必须扫描整个堆来判断对象是否存活，包括图中灰色的不可达对象。 灰色对象已经不可达，但仍然需要扫描的原因：新生代GC和老年代的GC是各自分开独立进行的，只有Minor GC时才会使用根搜索算法，标记新生代对象是否可达，也就是说虽然一些对象已经不可达，但在Minor GC发生前不会被标记为不可达，CMS也无法辨认哪些对象存活，只能全堆扫描（新生代+老年代）。由此可见堆中对象的数目影响了Remark阶段耗时。分析GC日志可以得出同样的规律，Remark耗时&gt;500ms时，新生代使用率都在75%以上。这样降低Remark阶段耗时问题转换成如何减少新生代对象数量。 新生代中对象的特点是“朝生夕灭”，这样如果Remark前执行一次Minor GC，大部分对象就会被回收。CMS就采用了这样的方式，在Remark前增加了一个可中断的并发预清理（CMS-concurrent-abortable-preclean），该阶段主要工作仍然是并发标记对象是否存活，只是这个过程可被中断。此阶段在Eden区使用超过2M时启动，当然2M是默认的阈值，可以通过参数修改。如果此阶段执行时等到了Minor GC，那么上述灰色对象将被回收，Reamark阶段需要扫描的对象就少了。 除此之外CMS为了避免这个阶段没有等到Minor GC而陷入无限等待，提供了参数CMSMaxAbortablePrecleanTime ，默认为5s，含义是如果可中断的预清理执行超过5s，不管发没发生Minor GC，都会中止此阶段，进入Remark。根据GC日志红色标记2处显示，可中断的并发预清理执行了5.35s，超过了设置的5s被中断，期间没有等到Minor GC ，所以Remark时新生代中仍然有很多对象。 对于这种情况，CMS提供CMSScavengeBeforeRemark参数，用来保证Remark前强制进行一次Minor GC。 优化结果经过增加CMSScavengeBeforeRemark参数，单次执行时间&gt;200ms的GC停顿消失，从监控上观察，GCtime和业务波动保持一致，不再有明显的毛刺。 小结通过案例分析了解到，由于跨代引用的存在，CMS在Remark阶段必须扫描整个堆，同时为了避免扫描时新生代有很多对象，增加了可中断的预清理阶段用来等待Minor GC的发生。只是该阶段有时间限制，如果超时等不到Minor GC，Remark时新生代仍然有很多对象，我们的调优策略是，通过参数强制Remark前进行一次Minor GC，从而降低Remark阶段的时间。 更多思考案例中只涉及老年代GC，其实新生代GC存在同样的问题，即老年代可能持有新生代对象引用，所以Minor GC时也必须扫描老年代。 JVM是如何避免Minor GC时扫描全堆的？经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性JVM引入了卡表（card table）来实现这一目的。如下图所示： 卡表的具体策略是将老年代的空间分成大小为512B的若干张卡（card）。卡表本身是单字节数组，数组中的每个元素对应着一张卡，当发生老年代引用新生代时，虚拟机将该卡对应的卡表元素设置为适当的值。如上图所示，卡表3被标记为脏（卡表还有另外的作用，标识并发标记阶段哪些块被修改过），之后Minor GC时通过扫描卡表就可以很快的识别哪些卡中存在老年代指向新生代的引用。这样虚拟机通过空间换时间的方式，避免了全堆扫描。 总结来说，CMS的设计聚焦在获取最短的时延，为此它“不遗余力”地做了很多工作，包括尽量让应用程序和GC线程并发、增加可中断的并发预清理阶段、引入卡表等，虽然这些操作牺牲了一定吞吐量但获得了更短的回收停顿时间。 案例三 发生Stop-The-World的GC确定目标GC日志如下图（在GC日志中，Full GC是用来说明这次垃圾回收的停顿类型，代表STW类型的GC，并不特指老年代GC），根据GC日志可知本次Full GC耗时1.23s。这个在线服务同样要求低时延高可用。本次优化目标是降低单次STW回收停顿时间，提高可用性。 优化首先，什么时候可能会触发STW的Full GC呢？ Perm空间不足； CMS GC时出现promotion failed和concurrent mode failure（concurrent mode failure发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再被使用的对象，这时停止所有的线程，同时终止CMS，直接进行Serial Old GC）； 统计得到的Young GC晋升到老年代的平均大小大于老年代的剩余空间； 主动触发Full GC（执行jmap -histo:live [pid]）来避免碎片问题。 然后，我们来逐一分析一下： 排除原因2：如果是原因2中两种情况，日志中会有特殊标识，目前没有。 排除原因3：根据GC日志，当时老年代使用量仅为20%，也不存在大于2G的大对象产生。 排除原因4：因为当时没有相关命令执行。 锁定原因1：根据日志发现Full GC后，Perm区变大了，推断是由于永久代空间不足容量扩展导致的。 找到原因后解决方法有两种： 通过把-XX:PermSize参数和-XX:MaxPermSize设置成一样，强制虚拟机在启动的时候就把永久代的容量固定下来，避免运行时自动扩容。 CMS默认情况下不会回收Perm区，通过参数CMSPermGenSweepingEnabled、CMSClassUnloadingEnabled ，可以让CMS在Perm区容量不足时对其回收。 由于该服务没有生成大量动态类，回收Perm区收益不大，所以我们采用方案1，启动时将Perm区大小固定，避免进行动态扩容。 优化结果调整参数后，服务不再有Perm区扩容导致的STW GC发生。 小结对于性能要求很高的服务，建议将MaxPermSize和MinPermSize设置成一致（JDK8开始，Perm区完全消失，转而使用元空间。而元空间是直接存在内存中，不在JVM中），Xms和Xmx也设置为相同，这样可以减少内存自动扩容和收缩带来的性能损失。虚拟机启动的时候就会把参数中所设定的内存全部化为私有，即使扩容前有一部分内存不会被用户代码用到，这部分内存在虚拟机中被标识为虚拟内存，也不会交给其他进程使用。 四、总结结合上述GC优化案例做个总结： 首先再次声明，在进行GC优化之前，需要确认项目的架构和代码等已经没有优化空间。我们不能指望一个系统架构有缺陷或者代码层次优化没有穷尽的应用，通过GC优化令其性能达到一个质的飞跃。 其次，通过上述分析，可以看出虚拟机内部已有很多优化来保证应用的稳定运行，所以不要为了调优而调优，不当的调优可能适得其反。 最后，GC优化是一个系统而复杂的工作，没有万能的调优策略可以满足所有的性能指标。GC优化必须建立在我们深入理解各种垃圾回收器的基础上，才能有事半功倍的效果。 本文中案例均来北京业务安全中心（也称风控）对接服务的实践经验。同时感谢风控的小伙伴们，是他们专业负责的审阅，才让这篇文章更加完善。对于本文中涉及到的内容，欢迎大家指正和补充。 作者简介录录，2016年加入美团点评，主要负责北京业务安全中心对接服务的后台研发工作。","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"}]},{"title":"深入理解JVM-（5）Class文件的结构","slug":"深入理解JVM-（5）Class文件的结构","date":"2018-04-03T08:18:40.000Z","updated":"2018-07-17T17:10:27.415Z","comments":true,"path":"2018/04/03/深入理解JVM-（5）Class文件的结构/","link":"","permalink":"https://lincy.online/2018/04/03/深入理解JVM-（5）Class文件的结构/","excerpt":"Class文件结构","text":"Class文件结构 magic魔数，4个字节，表明这是一个Class文件，0xCAFEBABE 版本号minor_version，major_version各两个字节 Class文件版本号 常量池constant_pool_count，u2常量池容量计数（从1开始），第0项表达“不引用任何一个常量池项目”。如:0x0016(十进制的22)标识有21常量，索引值范围为1~21. constant_pool 字面量(Literal) 接近于Java语言的常量概念，如文本字符串、final的常量值 符号引用 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 常量池的项目类型 例子（下图）： 0x07从上图可知为：CONSTANT_Class_info类型常量。而COMSTANT_Class_info的结构如下图，tag就是0x07，name_index（代表这个类或接口的全限定名）（0x0002）指向常量池的第二项。 看第二项的tag标识0x01，从上面的常量池的类型图可以看出，此项为CONSTANT_UTF8_info。CONSTANT_Utf8_info的结构如下： 所以第二项的内容三部分如下: 第三部分的utf编码转换为字符串为org/fenixsoft/clazz/TestClass，就是第一个常量（CONSTANT_Class_info）的值。 以此类推，可以得到所有的常量的值。 可以使用javap工具输出TestClass.class的文件字节码内容（省略了常量池意外的信息）： 常量池的14种常量的结构： 访问标志在常量池结束后，紧接着2个字节代表访问标志，用于识别类或接口层次的访问信息。 access_flags一共有16个标志位可用，当前只定义了其中8个。 类索引、父类索引与接口索引集合 类索引、父类索引是一个u2类型的数据（只能继承一个父类），指向一个Constant_class_info常量，通过constant_class_info常量中的索引值找到定义在constant_utf8_info中的全限定名字符串。 接口索引集合是一组u2类型的数据（可以实现多个接口）。入口的第一项——一个u2类型的数据标识接口索引的数量。如果没有实现任何接口，则计数器为0。 字段表集合在所有字段表之前有一个u2类型的数据fields_count为字段计数器，表示这个类有多少字段。 字段表（field_info），描述接口或者类中声明的变量。 字段表结构 access_flags: 标志位，如下图 字段访问标志 name_index（简单名称）和descriptor_index（描述符）都是对常量池的引用。inc()方法和m字段的简单名称分别是inc和m。描述符比较复杂，用来描述字段的数据类型、方法的参数列表（包括数量、类型、顺序）和返回值。 描述符标识字符含义 举几个例子： int[]的描述符为[I。（[表示数组） java.lang.String[][]的描述符为：[[Ljava/lang/String; 方法void inc()的描述符为()V 方法java.lang.String toString()的描述符为()Ljava/lang/String; 方法int indexOf(char[]source,int sourceOffset,int sourceCount,char[]target,int targetOffset,int targetCount,int fromIndex)的描述符为([CII[CIII)I 还有一部分是属性表集合，attribute_info，将在下面介绍。 方法表集合基本上同字段表结合一样。在字段表集合里已经有涉及。 属性表集合虚拟机规范预定义的属性（Java SE 7） 虚拟机预定义的属性类型(1) 虚拟机预定义的属性类型(2) 属性表结构","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（4）内存分配与回收策略","slug":"深入理解JVM-（4）内存分配与回收策略","date":"2018-03-15T09:13:09.000Z","updated":"2018-10-22T22:24:50.404Z","comments":true,"path":"2018/03/15/深入理解JVM-（4）内存分配与回收策略/","link":"","permalink":"https://lincy.online/2018/03/15/深入理解JVM-（4）内存分配与回收策略/","excerpt":"前言如何查看GC日志： 对象优先分配在Eden","text":"前言如何查看GC日志： 对象优先分配在Eden 使用JDK7实验新生代的GC： public class CH03_05 { private static final int _1MB = 1024 * 1024; /** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC */ public static void testAllocation() { byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; // 出现一次Minor GC allocation4 = new byte[4 * _1MB]; } public static void main(String args[]) { testAllocation(); } } gc日志如下： [GC[DefNew: 7801K-&gt;524K(9216K), 0.0050620 secs] 7801K-&gt;6668K(19456K), 0.0050979 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 5034K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 55% used [0x00000000f9a00000, 0x00000000f9e67560, 0x00000000fa200000) from space 1024K, 51% used [0x00000000fa300000, 0x00000000fa3832f0, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2970K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 13% used [0x00000000fae00000, 0x00000000fb0e6a58, 0x00000000fb0e6c00, 0x00000000fc2c0000) allocation1、2、3在Eden区占用了6M的空间。在分配allocation4时，发现新生代无法容纳，发生一次Minor GC。而survivor区无法并无法容纳2M的大小，因此将allocation1、2、3移动到老年代。gc后，将allocation4分配eden区。 大对象直接进入老年代-XX:PretenureSizeThreshold=3145728 ：大于3M的对象直接进入老年代 长期存活的对象直接进入老年代 private static final int _1MB = 1024 * 1024; /** * VM参数：-verbose:gc -Xms40M -Xmx40M -Xmn20M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 * -XX:+PrintTenuringDistribution */ @SuppressWarnings(&quot;unused&quot;) public static void testTenuringThreshold() { byte[] allocation1, allocation2, allocation3; allocation1 = new byte[_1MB / 4]; // 什么时候进入老年代决定于XX:MaxTenuringThreshold设置 allocation2 = new byte[8 * _1MB]; allocation3 = new byte[8 * _1MB]; allocation3 = null; allocation3 = new byte[8 * _1MB]; } public static void main(String[] args) { testTenuringThreshold(); } MaxTenuringThreshold=1，第一回收，allocation1依然在新生代（新生代占用784K）；第二次回收，allocation1已经转移到老年代（新生代0K）: [GC[DefNew Desired survivor size 1048576 bytes, new threshold 1 (max 1) - age 1: 804672 bytes, 804672 total : 10432K-&gt;785K(18432K), 0.0059603 secs] 10432K-&gt;8977K(38912K), 0.0059928 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC[DefNew Desired survivor size 1048576 bytes, new threshold 1 (max 1) - age 1: 760 bytes, 760 total : 9643K-&gt;0K(18432K), 0.0023646 secs] 17835K-&gt;8975K(38912K), 0.0023892 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 18432K, used 8468K [0x00000000f8600000, 0x00000000f9a00000, 0x00000000f9a00000) eden space 16384K, 51% used [0x00000000f8600000, 0x00000000f8e45000, 0x00000000f9600000) from space 2048K, 0% used [0x00000000f9600000, 0x00000000f96002f8, 0x00000000f9800000) to space 2048K, 0% used [0x00000000f9800000, 0x00000000f9800000, 0x00000000f9a00000) tenured generation total 20480K, used 8975K [0x00000000f9a00000, 0x00000000fae00000, 0x00000000fae00000) the space 20480K, 43% used [0x00000000f9a00000, 0x00000000fa2c3ce8, 0x00000000fa2c3e00, 0x00000000fae00000) compacting perm gen total 21248K, used 3098K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb106b08, 0x00000000fb106c00, 0x00000000fc2c0000) 如果设置MaxTenuringThreshold=15(默认为15), 第二次gc新生代仍然有784K: [GC[DefNew Desired survivor size 1048576 bytes, new threshold 15 (max 15) - age 1: 804672 bytes, 804672 total : 10432K-&gt;785K(18432K), 0.0061502 secs] 10432K-&gt;8977K(38912K), 0.0061935 secs] [Times: user=0.02 sys=0.02, real=0.01 secs] [GC[DefNew Desired survivor size 1048576 bytes, new threshold 15 (max 15) - age 1: 968 bytes, 968 total - age 2: 802008 bytes, 802976 total : 9643K-&gt;784K(18432K), 0.0015832 secs] 17835K-&gt;8976K(38912K), 0.0016100 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 18432K, used 9252K [0x00000000f8600000, 0x00000000f9a00000, 0x00000000f9a00000) eden space 16384K, 51% used [0x00000000f8600000, 0x00000000f8e45000, 0x00000000f9600000) from space 2048K, 38% used [0x00000000f9600000, 0x00000000f96c40a0, 0x00000000f9800000) to space 2048K, 0% used [0x00000000f9800000, 0x00000000f9800000, 0x00000000f9a00000) tenured generation total 20480K, used 8192K [0x00000000f9a00000, 0x00000000fae00000, 0x00000000fae00000) the space 20480K, 40% used [0x00000000f9a00000, 0x00000000fa200010, 0x00000000fa200200, 0x00000000fae00000) compacting perm gen total 21248K, used 3098K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb106b08, 0x00000000fb106c00, 0x00000000fc2c0000) 空间分配担保发生MinorGC之前，检查老年代可用连续空间是否大于新生代的所有对象总空间。 是，那么MinorGC可以确保是安全的 否。 查看HandlePromotionFailure设置值是否允许担保失败。 允许。检查老年代最大连续空间是否大于历次晋升到老年代对象的平均大小： 大于，尝试进行一次MinorGC，尽管是有风险的。 小于，直接FullGC 不允许。FullGC。 JDK6 Update24之后，HandlePromotionFailure不再起作用，只要老年代最大连续空间大于新生代对象总大小或历次平均大小，就进行MinorGC","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（3）GC算法","slug":"深入理解JVM-（3）GC算法","date":"2018-03-02T13:02:17.000Z","updated":"2018-07-17T17:10:27.413Z","comments":true,"path":"2018/03/02/深入理解JVM-（3）GC算法/","link":"","permalink":"https://lincy.online/2018/03/02/深入理解JVM-（3）GC算法/","excerpt":"标记清除算法标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象","text":"标记清除算法标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 缺点： 效率低 产生大量不连续的内存碎片 复制算法将内存分为大小相等的两块，每次只使用其中的一块。当一块用完了，就将或者的对象复制到另外一块上面，然后把另一块一次清理掉 优点： 简单效率高 不产生内存碎片 缺点：浪费了一半的内存空间 新生代就是用这种算法来回收对象的，不过新生代的对象大多存活时间都很短（98%活不过下一次gc），所以不要按1：1的比例来划分内存空间，而是： 将内存分为一块较大的Eden空间和两块较小的Survior空间（默认是8：1，这样只浪费10%的空间），每次使用Eden和其中的一块Survior。 回收时，将Eden和Survior中还存活着的对象一次性拷贝到另一块Survior上，最后清理掉Eden和刚刚的Survior。 但是没办法保证每次都只有10%的对象存活，有时还需要以来其他内存（老年代）分配担保。如果一块Survior无法容纳一次新生代gc存活下来的对象，那么这些对象将直接进入老年代 标记-整理算法标记-整理算法适用于存活率较高的老年代。(不适用复制算法，存活率高要复制的内存多，且浪费的空间大) 标记过程和标记清除算法一样，后续步骤让所有存活的对象都向一端移动，然后清理掉边界以外的内存 分代收集算法根据各个年特点代采用合适的清除算法：新生代采用复制算法，老年代采用标记-清除算法。 垃圾收集器 连线表明它们可以搭配使用 Serial收集器最基本最悠久的收集器，单线程收集器，新生代采用复制算法。gc时，必须暂停其他所有的工作线程（Stop The World）。单个CPU环境下，效率较高，对于运行在Client模式下的虚拟机是个好选择。 ParNew收集器Serial收集器的多线程版本 Parallel Scavenge收集器 是一个新生代收集器，采用复制算法 关注点与其他收集器不同，CMS等收集器关注的是尽可能地缩短垃圾收集时用户线程的等待时间，而Parallel Scavenge收集器目的是达到一个可控制的吞吐量（throughput=运行用户代码时间/(运行用户代码时间+垃圾收集时间)）。 停顿时间短适合与用户交互的程序；而高吞吐量可以最高效率的利用cpu时间，适合后台运算而不需要太多交互的任务。 两个参数： -XX：MaxGCPauseMillis，最大垃圾收集停顿时间（尽力保证） -XX：GCTimeRatio，吞吐量大小 -XX：+UseAdaptiveSizePolice，开关参数，不需要手工指定新生代大小（-Xmn）、Eden和Survior的比例（-XX:SurviorRatio）、晋升老年代对象年龄（-XX：PretenureSizeThreshold）等细节参数，虚拟机会根据收集的系统性能信息，动态调整这些参数。如果对虚拟机不熟，可以打开这个开关，然后使用MaxGCPauseMillis或GCTimeRatio给虚拟机设立一个优化目标，具体细节参数调节由虚拟机完成。 Serial Old收集器Serial收集器的老年代版本 Parallel Old收集器Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。 CMS收集器（Concurrent Mark Sweep）以获取最短回收停顿时间为目标的收集器，重视服务的相应速度，符合B/S系统服务端的需求。基于标记-清除算法（Mark Sweep）。分为四个步骤： 初始标记 标记GC Roots能直接关联到的对象，速度很快（stop the world） 并发标记 进行GC Roots Tracing 重新标记 修正并发标记阶段期间，用户程序继续运行而导致标记产生变动的那一部分对象的标记记录（stop the world） 并发清除 整个过程耗时最长的并发标记和并发清除过程，收集线程可以和用户线程一起工作，总体上cms收集器的回收过程是与用户线程一起并发地执行的。 CMS收集器 CMS收集器仍然有三个显著的缺点： 对cpu资源非常敏感 默认回收线程数=（cpu数量+3）/4，当cpu数量&gt;=4时，收集线程占用的cpu资源&lt;25%；但是当cpu资源不足4时，比如2，那么回收线程将占用50%的cpu资源，导致用户线程速度降低50%。 无法处理浮动垃圾（Floating Garbage，并发清理阶段，用户线程产生的新垃圾），可能出现“concurrent mode failure”而导致另一次Full GC的产生。由于垃圾收集阶段用户线程仍然在运行，所以需要预留空间提供程序运作使用。因此默认设置下，CMS在老年代使用了68%的空间后就会被激活（-XX:CMSInitiatingOccuPancyFraction参数可以用来设置这个比例值）。如果应用老年代增长不是很快，可以提高出发百分比，以便降低内存回收次数获得更好性能。要是CMS运行期间预留的内存空间无法满足程序需求，就会出现一次“Concurrent Mode Failure”，这时候虚拟机会临时启用Serial Old收集器来重新进行老年代的收集，这样停顿时间就更长了。因此-XX：CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量“Concurrent Mode Failure”，降低性能。 标记-清除算法，产生大量空间碎片，往往出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间，从而触发Full GC。CMS提供了一个-XX：+UseCMSCompactAtFullCollection开关参数，用于在Full GC后二外进行一个碎片整理过程，但停顿时间变常了。因此还提供了另一个参数-XX：CMSFullGCsBeforeComapction，用于设置执行多少次Full GC后，跟着来一次压缩。 G1收集器基于标记-整理算法，不会产生空间碎片。可以非常精确控制停顿，可以明确指定在一个长度为M毫秒的时间片段内，消耗在GC的时间不超过N好眠。 G1收集器，避免了全区域的垃圾收集（前面介绍的都是全区域的垃圾收集），它将整个Java堆划分为多个大小固定的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个优先队列，每次根据允许的收集时间，优先回收垃圾最多的区域（Garbage First）。区域划分有优先级的区域回收，保证了G1收集器在有限的时间内可以获得最高的收集效率。 GC常用参数总结 CMS收集器","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（2）垃圾回收, 对象已死？","slug":"深入理解JVM-（2）垃圾回收","date":"2018-03-02T09:06:31.000Z","updated":"2018-07-17T17:10:27.410Z","comments":true,"path":"2018/03/02/深入理解JVM-（2）垃圾回收/","link":"","permalink":"https://lincy.online/2018/03/02/深入理解JVM-（2）垃圾回收/","excerpt":"引用计数法算法：引用计数为0即为死对象缺陷: 无法解决循环引用的问题，JDK不采用这种方法。","text":"引用计数法算法：引用计数为0即为死对象缺陷: 无法解决循环引用的问题，JDK不采用这种方法。 根搜索算法根对象——GC Roots： 虚拟机栈中引用的对象（栈帧中的本地变量表） 方法去中的静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（Native方法）的引用的对象 不能从GC Roots追溯到的对象，为可回收的对象。 引用 强引用 类似 “Object obj = new Object()”，只要强引用还在，就不会被回收 软引用 JDK中提供的SoftReference类——还有用，但并非必须的对象。在内存溢出之前，会把软引用对象列进回收范围，进行二次回收，如果还是没有足够的内存，才会抛出内存溢出异常。 弱引用 WeakReference——非必需对象，只能生存到下一次垃圾收集之前。无论当前内存是否足够，都会回收掉弱引用对象。 虚引用 PhantomReference——完全不会对对象的生存构成影响，也无法通过其获取对象实例，唯一的目的是对象被垃圾回收时收到一个系统通知。 生还是死根搜索算法中不可达的对象，并非“非死不可”，可以通过finalize()方法自救： finalize执行流程 不建议使用finalize(), 应使用try-finally, 更好更及时。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"深入理解JVM-（1）Java内存结构","slug":"深入理解JVM-（1）Java内存结构","date":"2018-03-02T07:50:26.000Z","updated":"2018-07-17T17:10:27.409Z","comments":true,"path":"2018/03/02/深入理解JVM-（1）Java内存结构/","link":"","permalink":"https://lincy.online/2018/03/02/深入理解JVM-（1）Java内存结构/","excerpt":"运行时数据区域","text":"运行时数据区域 程序计数器线程私有， 当前线程所执行的字节码的行号指示器，可以通过改变这个计数器的值来选取吓一跳需要执行的字节码指令。 虚拟机栈线程私有，生命周期与线程相同。描述Java方法执行的内存模型，每个方法被执行都会创建一个栈帧用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法从调用到执行完成的过程，对应一个栈帧再虚拟机栈中从入栈到出栈的过程。 如果请求的栈深度超过虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈动态扩展无法申请得到足够的内存，将会排除OutOfMemoryError。 本地方法栈跟虚拟机栈类似，本地方法栈服务于Native方法 Java堆被所有线程共享，目的是存放对象实例(对象实例不一定都分配在Java堆上，也可能在栈上——逃逸分析、栈上分配)。 GC的主要区域。通过-Xms和-Xmx控制扩展大小，无法扩展时，抛出OutOfMemoryError。 方法区线程共享，存储类信息、常量、静态变量、即时编译器编译后的代码等数据。习惯称为永久代。垃圾收集在这个区域较少出现，但数据也并非“永久”存在。 可能会抛出OutOfMemoryError。典型场景如Spring和Hibernate对类增强时，用到CGLib字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以载入内存。 运行时常量池属于方法区的一部分，存放编译器生成的各种字面量和符号引用。 直接内存堆外内存。NIO基于通道（channel）与缓冲区（buffer），使用Nativ函数直接分配堆外内存。因为避免了在Java堆和Navite堆中来回复制数据，所以可以提高性能。 对象的引用两种方式: 通过句柄 通过直接指针 直接指针速度优于句柄方式，因为少了一次寻址。Sun HotSpot（JDK默认）采用直接指针方式。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://lincy.online/tags/JVM/"},{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"}]},{"title":"New Year's Day","slug":"New-Year-s-Day","date":"2018-02-15T16:35:59.000Z","updated":"2018-02-16T06:25:45.952Z","comments":true,"path":"2018/02/16/New-Year-s-Day/","link":"","permalink":"https://lincy.online/2018/02/16/New-Year-s-Day/","excerpt":"","text":"2018I will be with you againI will begin again","categories":[{"name":"生活","slug":"生活","permalink":"https://lincy.online/categories/生活/"}],"tags":[]},{"title":"责任链模式","slug":"责任链模式","date":"2018-02-13T05:25:29.000Z","updated":"2018-02-13T15:10:50.721Z","comments":true,"path":"2018/02/13/责任链模式/","link":"","permalink":"https://lincy.online/2018/02/13/责任链模式/","excerpt":"","text":"/** * 职责接口 * @author LinChangyi * @date 2018/2/13 **/ public abstract class Handler { /** * 持有后继的职责对象 */ protected Handler successor; public void setSuccessor(Handler successor) { this.successor = successor; } /** * 处理请求的方法 * 可以根据需求传入参数 */ public abstract void handleRequest(); } /** * @author LinChangyi * @date 2018/2/13 **/ public class ConcreteHandler1 extends Handler{ @Override public void handleRequest() { //根据某些条件来判断是否属于自己的职责范围 //判断条件比如，从外部传入的参数，或者这里主动去获取的外部数据 //如从数据库中获取等，下面只是个示意 boolean someCondition = false; if(someCondition){ //属于自己的职责 System.out.println(&quot;ConcreteHandler1 handle request&quot;); } else { if(this.successor!=null){ this.successor.handleRequest(); } } } } /** * @author LinChangyi * @date 2018/2/13 **/ public class Client { public static void main(String[] args){ //组装责任链 Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); handler1.setSuccessor(handler2); //提交请求 handler1.handleRequest(); } }","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"SpringBoot启动过程分析","slug":"SpringBoot启动过程分析","date":"2018-02-09T03:49:43.000Z","updated":"2018-03-10T09:15:46.521Z","comments":true,"path":"2018/02/09/SpringBoot启动过程分析/","link":"","permalink":"https://lincy.online/2018/02/09/SpringBoot启动过程分析/","excerpt":"入口@SpringBootApplication public class SpringbootstarterApplication { public static void main(String[] args) { SpringApplication.run(SpringbootstarterApplication.class, args); } }","text":"入口@SpringBootApplication public class SpringbootstarterApplication { public static void main(String[] args) { SpringApplication.run(SpringbootstarterApplication.class, args); } } 初始化private void initialize(Object[] sources) { //sources为入口的传入的class if (sources != null &amp;&amp; sources.length &gt; 0) { this.sources.addAll(Arrays.asList(sources)); } //是否web应用 this.webEnvironment = deduceWebEnvironment(); //应用上下文初始化器 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //应用监听器监听器，使用观察者模式实现 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 加载的初始化器和监听器如下： 初始化器和监听器是如何创建的？可以看到初始化器和监听器的创建都是通过 getSpringFactoriesInstances 这个方法： private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // SpringFactoriesLoader读取spring.factories文件，找到类名 Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); //根据上面找到的类名，创建实例 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; } springboot的一个jar包底下的\\META-INF\\spring.factories配置的初始化器和监听器: spring.factories一部分配置 运行SpringApplition.java public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); FailureAnalyzers analyzers = null; configureHeadlessProperty(); //SpringApplicationRunListener，也是通getSpringFactoriesInstances方式加载。 //是SpringApplicationRunListener的集合，监测应用上下文环境的事件： //starting, environmentPrepared, contextPrepared, contextLoaded, finished SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //初始化一些配置 prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } return context; } catch (Throwable ex) { handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); } } …未完待续","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://lincy.online/tags/springboot/"}]},{"title":"丙州三调","slug":"行摄/丙州大桥","date":"2018-02-06T15:28:38.000Z","updated":"2018-02-06T15:47:49.331Z","comments":true,"path":"2018/02/06/行摄/丙州大桥/","link":"","permalink":"https://lincy.online/2018/02/06/行摄/丙州大桥/","excerpt":"丙州大桥，傍晚时分，瞎拍几张","text":"丙州大桥，傍晚时分，瞎拍几张","categories":[{"name":"生活","slug":"生活","permalink":"https://lincy.online/categories/生活/"}],"tags":[{"name":"行摄","slug":"行摄","permalink":"https://lincy.online/tags/行摄/"}]},{"title":"命令模式","slug":"命令模式","date":"2018-02-06T08:19:40.000Z","updated":"2018-02-06T12:06:26.301Z","comments":true,"path":"2018/02/06/命令模式/","link":"","permalink":"https://lincy.online/2018/02/06/命令模式/","excerpt":"命令模式","text":"命令模式 优点： command子类可以快速扩展 调用者和接收者间解耦，调用者只需要调用command的execute方法，不需要了解接收者 //通用Receiver类 public abstract class Receiver { public abstract void doSomething(); } //具体Receiver类 public class ConcreteReciver1 extends Receiver{ //每个接收者都必须处理一定的业务逻辑 public void doSomething(){ } } public class ConcreteReciver2 extends Receiver{ //每个接收者都必须处理一定的业务逻辑 public void doSomething(){ } } //抽象Command类 public abstract class Command { public abstract void execute(); } //具体的Command类 public class ConcreteCommand1 extends Command { //对哪个Receiver类进行命令处理 private Receiver receiver; //构造函数传递接收者 public ConcreteCommand1(Receiver _receiver){ this.receiver = _receiver; } //必须实现一个命令 public void execute() { //业务处理 this.receiver.doSomething(); } } public class ConcreteCommand2 extends Command { //哪个Receiver类进行命令处理 private Receiver receiver; //构造函数传递接收者 public ConcreteCommand2(Receiver _receiver){ this.receiver = _receiver; } //必须实现一个命令 public void execute() { //业务处理 this.receiver.doSomething(); } } //调用者Invoker类 public class Invoker { private Command command; public void setCommand(Command _command){ this.command = _command; } public void action() { this.command.execute(); } } //场景类 public class Client { public static void main(String[] args){ Invoker invoker = new Invoker(); Receiver receiver = new ConcreteReceiver1(); Command command = new ConcreteCommand1(receiver); invoker.setCommand(command); invoker.action(); } }","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"zookeeper学习笔记（2）Paxos Made Simple【翻译】","slug":"zookeeper学习笔记/zookeeper学习笔记（2）paxos协议","date":"2018-01-18T08:50:04.000Z","updated":"2018-10-21T00:13:29.666Z","comments":true,"path":"2018/01/18/zookeeper学习笔记/zookeeper学习笔记（2）paxos协议/","link":"","permalink":"https://lincy.online/2018/01/18/zookeeper学习笔记/zookeeper学习笔记（2）paxos协议/","excerpt":"原文 Paxos Made Simple摘自 Paxos Made Simple论文翻译","text":"原文 Paxos Made Simple摘自 Paxos Made Simple论文翻译 【这篇论文我翻一下来，首先感觉还是不好懂，很多地方结论的得出不够清楚，需要读者自己思考其中的原因。要理解Paxos算法，个人建议先搜索下介绍算法的中文文章，大致了解下Paxos算法要做什么，然后就再读下论文，应该会有所感悟。】 Paxos Made SimpleLeslie Lamport01 Nov 2001 说明【说明这部分是我自己加的，下面这几个词大量出现与论文的主体部分，提前了解它们的含义有助于后面对于算法原理和流程的理解。】 议案(proposal):由提议人提出，由审批人进行初审和复审，包括议案编号和议案内容。内容(value):议案的内容。编号(id):议案的编号，全局唯一。提议人(proposer):提出议案，接收审批人的初审和复审意见。审批人(acceptoer):接收议案，根据规则决定初审和复审结果，返回给提议人。执行人(learner):一旦议案成为决议，就要通知所有执行人。初审(accept):议案的第一轮审核，通过后可以进行复审。复审(chossen):议案的第二轮审核，通过后将成为决议。 摘要Paxos算法，当用简明英语表述时，灰常简单。【大神的第一篇论文用在虚构的希腊岛屿Paxos上的人们通过议会表决法律来解释Paxos算法，群众纷纷表示太难理解了。大神表示你们这群渣渣不懂我的幽默，既然如此，我就用简明英语再表述一遍，哼！】 1 介绍Paxos算法的目标是实现一个具有容错能力的分布式系统。人们觉得这一算法哪一理解，也许对许多读者来说，算法最初使用希腊语表述的。[5]事实上，这一算法是分布式算法中最简单直观的算法之一。【Google Chubby的作者Mike Burrows:there is only one consensus protocol, and that’s Paxos– all other approaches are just broken versions of Paxos.】这一算法的核心是论文[5]中提到的一致性算法“synod”。下一章我们将看到这一算法如何严格遵守我们制定的规则。最后一章会通过将一致性算法应用于构建分布式系统的确定状态机（这是分布式理论的文章最常常引用的论文的内容[4]）来对Paxos算法进行完整的解释。 2 一致性算法2.1 问题的提出假设我们有一组服务器，他们都可以提出议案。一致性算法要保证被提出的多个议案中最终只有一个议案可以通过审核成为决议。如果没有议案提出，就不会产生决议。如果一个议案成为决议，那么所有process都应当知道这个决议。那么，要保证一致性就要满足： 所有被提出的议案中只有一个议案可以成为决议只有一个议案成为决议，且服务器永远不知道一个议案成为了决议，除非这个议案真的成为了决议这一过程的运行时间并不重要，但要保证最终将会有某个议案成为决议，并且，一旦议案成为决议，所有服务器都能够知道这一决议。 我们用三类代理人代表一致性算法中的三个角色：提议人、审批人和执行人。在具体实现中，单个服务器可以扮演多种代理人，我们不需要关心他们之间的对应关系。【同一台服务器，可以即是提议人，又是审批人或执行人。】 假设代理间通过消息通信。这里我们使用传统的异步、非拜占庭模型【不考虑拜占庭问题，代理间通信可能丢失或重复，但不会被篡改】： 服务器运行效率不确定，可能停机或重启。因为当决议产生后所有服务器都有可能停机重启，所以服务器必须能够做到即使停机重启也可以记住某些信息，否则停机重启的问题将无法解决。消息传递时间任意，消息可以重复发送，允许丢失，但不允许修改。 2.2 选择决议只有一个审批人的状况是最简单的。提议人向审批人发送议案，审批人选择接收到的第一个议案作为决议。这个方案无法解决单机失效问题，如果审批人停机，整个系统将被阻塞。 因此，我们来尝试另一种选择决议的方式：让多个审核人共同参与决议的产生。提议人向一部分审核人发送议案，审核人可能会初审通过这一议案。当足够多的审核人初审通过这一议案时，议案就可以进行复审了。多少人算足够多？为了保证只有一个议案成为决议，足够多的人必须包括审核人的多数派，即半数以上的审批人。因为任何两个多数派集合中至少有一个成员是公共的，因此只要保证一个审批人同一时间最多只能初审通过一条议案【这里指的是审批人承认这一议案通过初审，当该议案进行复审时，也会通过复审的状态】，就可以保证最终只有一个议案可以成为决议。 (在大量论文中都涉及了多数派的研究，最早出现于[3]) 在不存在服务器停机或消息丢失的前提下，我们希望即使只发起了一个议案，这个议案仍可以成为决议。因此我们需要满足以下条件： P1.对于接收到的第一个议案，审核人必须初审通过。 但是这一条件会产生一个问题。不同提议人几乎同时提出不同的议案，导致每个审批人都初审通过了一个议案，但是没有一个议案同时被半数以上的审批人初审通过。即使只有两个议案，审批人有2n+1个，且他们分别被n个审批人初审通过，那么最后一个审批人的停机就可能导致无法产生决议。 条件P1以及决议的产生必须经过多数派审核这一条件表明审批人应当可以先后初审通过多条议案。我们通过为每一个议案分配一个编号来追踪不同的议案，这样一个议案就包括议案编号和议案内容两部分。为了防止混淆，我们要求不同议案的编号也必须不同。关于这点如何保证依赖于具体实现，我们这里只是假设他成立。【google的编号生成算法在附录，有兴趣的可以看下】当一项议案被审批人中的多数派初审通过后，这项议案的内容将进入复审阶段。 我们允许多个议案进入复审阶段，但是我们必须保证这些议案的内容是相同的。通过引入议案编号，我们可以保证以下条件： P2.如果一个编号为n内容为v的议案【下文用议案（n,v）替代】进入复审阶段，那么所有进入复审阶段的议案编号大于n的议案，他们的议案内容也为v。【条件P2以及后续P2的强化条件都在保证一件事：多个提议人可以提出多个议案，议案编号各不相同，但是这些议案的内容最终都会一样】 由于议案编号是有序的，条件P2严格保证了只有一个议案内容可以成为决议。 要进入复审阶段并最终成为决议，议案必须被至少一个审批人初审通过。因此要满足条件P2,我们只要满足以下条件： P2a.如果议案（n,v）进入复审阶段，那么所有通过初审的编号大于n的议案的议案内容为v。 我们仍需要满足条件P1以保证会有决议产生。因为通信是异步的，一个议案可能被任何尚未收到过议案的审批人初审通过，这违背了条件P2a。要保证P1和P2a同时有效，需要把P2a加强为以下条件： P2b.如果议案（n,v）进入复审阶段，那么任何提议人提出的编号大于n的议案，议案内容为v。 因为一个议案首先要由提议人提出才有可能被审批人初审通过，所以条件P2b保证了条件P2a也就保证条件P2. 在找到方法满足P2b前，我们先研究如何使这一条件成立。假设议案（m,v）进入复审阶段，如何使议案编号为n且n&gt;m的任意议案的议案内容为v 。我们使用对n使用数学归纳法证明，这样我们要证明议案n的内容为v，就要需要额外的假设条件：任意编号在m和n-1区间内的议案的内容为v。因为议案（m,v）已经进入复审阶段，那么必然有一个多数派的审批人集合C，集合中的每个审批人都对议案m初审通过。把这一结论与额外条件结合，议案m进入复审阶段表明： 每个集合C中的审批人都初审通过一个编号在m和n-1区间内的议案，并且所有编号在m和n-1区间内的议案内容为v。 【要理解这一部分，需要了解算法的具体执行过程。对于编号m到n-1的议案，议案的内容为v，提议人是怎么样决定议案内容的呢？提议人必然是通过向集合C中的某些成员发送初审请求并通过初步审核后，从回复信息中获知这一信息的。这就是上半句话的解释】 因为任意审批人多数派的集合S和集合C至少有一个成员相同，那么只要保证以下条件成立，议案n的内容就可以保证为v： P2c.对任意内容v和编号n，议案（n,v）如果被某个提议人发出，那么必然有一个审批人的多数派集合S，他们要么 （a） S中的任何审批人都没有收到过编号小于n的议案，或者 （b） 集合S中所有审批人初审通过的编号小于n的议案中编号最大的那个议案的议案内容为v。 我们可以证明满足条件P2c即可满足条件P2b。 要保证条件P2c，当一个提议人想要发出一个编号为n的议案时，他必须知道已经或将要通过多数派审批人初步审核的编号小于n的议案中编号最大的那个议案的内容。要知道已经通过初审的议案很简单，但是预测未来的初审结果很难。为了规避预测未来这一难题，审批人必须保证不会有允许这样的初审结果出现。也就是说，提议人要求审批人一旦初审通过编号为n的议案将不得再初审通过编号小于n的议案。因此发出议案的算法如下： 1. 一个提议人生成一个新的议案编号n并发给一半以上的任意审批人，要求他们回复： （a） 保证不再审核通过【包括初审和复审】编号小于n的议案，且 （b） 如果已经初审通过了议案，把编号小于n且编号最大的那个议案的编号和内容回复给我。 这一过程称为编号为n的议案的初审请求。 2. 如果提议人收到了半数以上的初审通过回复，那么他将发起一个议案，议案的编号为n，内容为v，【请注意，此时才决定议案内容，之前初步审核只是要确认议案编号是否可用】如果审批人的回复中包括议案，v就是这些议案中编号最大的那个议案的内容，如果审批人的回复中不包括议案，那么提议人可以自己设置一个议案内容。 提议人向多数派审批人发送已经通过初审的议案（初审的多数派和这次审核的多数派成员可以不同），我们称第二次审核的过程为复审。 以上就是提议人的算法，审批人呢？他接受两种审批请求：初审请求和复审请求。审批人可以拒绝任意请求而不会对系统造成损害，我们应当说清楚在什么情况下审批人可以回复一个请求。在不违背初审通过时的承诺【保证不再审核通过编号小于n的议案】的前提下，他既可以初审通过又可以复审通过一个议案。换句话说： P1a.一个审批人可以初审或复审通过一个议案（n,v），当且仅当他从未初审通过一个编号大于n的议案。【当审批人从未收到任何议案时，他可以初审通过收到的任何议案，这符合条件P1.所以】P1a包含了P1. 我们现在拥有完整的决议产生算法并且满足我们设定的条件——议案编号唯一。最终算法仍需要一些优化。 假设审批人收到了一个编号为n的初审请求，但是他已经初审通过了编号大于n的议案，因此已经保证过不对编号为n的议案做出回应。因为他不会初审通过这一议案，所以他没有必要对初审请求做出回应。因此我们让审批人忽略这一初审请求，同时，审批人也会忽略再次收到的已经初审通过的议案的初审请求。 这一优化要求审批人必须且只需记住他收到过的编号最高的议案以及他初审通过的编号最高的议案。因为P2c条件在某些角色停机的情况下仍要保证有效，审批人即使在停机重启后仍要记的这些信息。注意提议人可以随时放弃当前的议案或者忘掉之前提出过的议案，但是他必须保证议案的编号唯一且递增。 把提议人和审批人的算法结合在一起，我们得到下面两个阶段的算法： 阶段1 （a） 提议人生成议案编号n，向半数以上审批人发送编号为n的初审请求。 （b） 如果审批人收到的初审请求编号n大于他之前初审通过的议案编号，将回复两个信息：一个是保证不再对编号小于n的议案做出回应【包括初审和复审】，二是如果之前初审通过了议案，将其中编号最大的议案的编号和内容回复给提议人。 阶段2（a） 如果提议人收到了半数以上的审批人的初审通过回复，他将会以议案（n,v）发送复审请求。对于议案内容v，如果审批人的初审回复中包含议案，那么v就是这些议案中编号最大的那个议案的内容，如果初审回复中不包含议案，提议人可以自行决定议案内容v。 （b） 如果审批人收到了编号为n的议案的复审请求，只要他没有初审通过编号大于n的议案【从而做出过保证】，他会复审通过这一议案。 提议人可以在遵守算法规则的前提下提出多个议案。他可以在协议的任意阶段随时放弃某个议案。（算法不会因此出现问题，即使审核请求或回复在议案被抛弃后才接收到）如果其他提议人开始发起编号更高的议案，也许放弃当前编号较低的议案是个好主意。【不管编号更高的议案能否通过多数派的初审，都意味着当前编号的议案不会得到半数以上的通过回复，发送请求和等待回复将是浪费时间】因此，如果审批人因为保证过不再回复编号较小的议案而忽略某些议案时，他应当通知提议人：你的议案编号太小了，放弃当前议案，选一个更大的编号，重新发送申请。这是一个性能方面的优化，不会影响算法的正常运行。 2.3 产生决议后如何通知执行人要随时知道一个决议是否产生了，执行人必须能随时获悉是否有一个议案被半数以上审批人复审通过。首先想到的算法是，让审批人每次复审通过一条议案，就给所有执行人发送一条消息。这使得执行人可以实时了解当前审核情况，但是这要求每个审批人和每个执行人通信，通信规模是两者数量的乘积。 非拜占庭问题的假设使得执行人获得消息变得简单。我们可以选出一个执行人代表，所有审批人都与执行人代表进行通信，而当决议产生时，执行人代表再把决议通知其他执行人。这里需要一轮额外的通信以通知所有执行人当前决议。而且这一做法更不可靠，因为执行人代表也可能停机。但是他的通信量仅仅是两者数量之和。更进一步，我们可以让审批人和多个执行人代表通信，每个执行人代表都可以在决议产生后通知其他执行人。多个执行人代表可以使系统更加稳定但是通信的复杂度也会提高。 由于允许通信失败，执行人可能无法得知进入复审阶段议案的内容。执行人可以向所有审批人询问当前初审通过的议案，但是某个审批人停机就可能导致没有一个议案被半数以上审批人初审通过。在这一情况下，只有当新的议案进入复审阶段时，执行人才能知晓议案内容。如果执行人需要知道当前是否有进入复审阶段的议案的内容，他可以要求提议人根据上面的算法发起一个议案。【这个新议案的议案编号足够大，发起初审请求后能够得到半数以上审批人的回复，他们的回复中如果有议案，议案编号最大的那个议案内容就是目前进入复审阶段的议案内容。提议人可以继续发起复审请求，也可以放弃当前议案。最终产生的决议内容是不会发生变化的。】 2.4 保证算法的进行很容易就可以想到一个场景，两个提议人轮流发起编号递增的提议并通过初步审核，虽然按照算法规则，他们的提议内容是相同的，但是由于复审请求时，审批人已经初审通过了另一个编号更高的议案，导致自己的复审请求无法通过，因此永远无法产生决议。提议人p的议案n1通过初审，然后提议人q的议案n2通过初审，n2&gt;n1；提议人p的复审请求将被忽略，因为审批人已经保证过不再回复编号小于n2的议案。然后提议人p将议案编号提高为n3，n3&gt;n2，并通过初步审核，导致q的复审请求也被忽略。这样重复下去，永远无法产生决议。【活锁】 要保证算法进行下去，必须选出一个提议人代表，只有他可以发出议案。如果提议人代表可以和半数以上的审核人成功通信，并且他提出的议案编号比所有已经提出过的议案的编号都大，他就可以成功让议案变成决议。如果通过审核人的忽略回复得知已经存在某些编号更高的议案，提议人代表会放弃当前议案，增大议案编号然后重新进行步骤一的初步审核，最终，提议人代表能够选出一个足够大的编号用于产生决议。 如果分布式系统中足够多的部分正常工作（至少一个提议人、半数以上审批人、工作正常的通信网络），通过选举选出一个提议人代表就可以保证系统正常运行。Fischer,lynch和Patterson[1]的著名研究结果表明，可靠地选举算法要么是随机的，要么是实时的-比如使用超时机制。【另一篇文章中关于FLP理论与Paxos算法的讨论：其实仔细回忆Paxos论文会发现，Paxos中存在活锁，理论上的活锁会导致Paxos算法无法满足Termination属性，也就不算一个正确的一致性算法。Lamport在自己的论文中也提到“FLP结果表明，不存在完全满足一致性的异步算法…”，因此他建议通过Leader来代替Paxos中的Proposer，而Leader则通过随机或其他方式来选定（Paxos中假如随机过程会极大降低FLP发生的概率）。也就是说Paxos算法其实也不算理论上完全正确的，只是在工程实现中避免了一些理论上存在的问题。但这丝毫不影响Paxos的伟大性！】但是，不管选举成功还是失败，系统安全性都可以得到保障。 2.5 实现Paxos算法[5]建立在一组通过网络通信的服务器上。在此一致性算法中，每个服务器都可以是提议人、审批人或执行人。算法选举出一个提议人代表防止活锁出现、选出一个执行人代表降低通信复杂度。Paxos一致性算法中的审核请求和审核回复都以普通消息的形式发送（审核回复带有相应的议案编号防止出现消息发送失败、延迟或重复时导致提议人的混乱）。持久化存储保证即使停机后仍可以保存数据，用来保存审核人必须记住的信息。审核人在发送审核回复消息前，会先在持久化存储中存储这些消息。 最后要描述的是实现任意两个议案编号不相同的机制。不同的提议人从互不相交的集合中选择编号，因此两个提议人不会生成相同的编号。每个提议人都会存储他们发出过的最大的议案编号，当他们再次开始步骤一的初步审核申请时，会选择一个比之前议案编号更大的编号。 3 有限状态机的实现实现分布式系统的一个方案是由一组客户端向中心服务器发送指令。中心服务器作为确定状态自动机按一定顺序执行接收的指令。状态机根据当前状态和接收到的指令产生输出结果和新的状态。例如，分布式银行系统的客户端可能是出纳员，而状态机的状态可能是所有账户余额的集合。提现操作会向状态机发出指令，当且仅当账户余额不小于提现金额时，减少账户余额数量【新的状态】，并返回提现前后的余额【输出】。 单个中心服务器无法解决单机失效问题。因此我们使用一组中心服务器，每个服务器都是一个独立的状态机。因为状态机属于确定状态自动机，所以当输入命令的内容和顺序相同时，这些状态的状态变化和输出也是相同的。因此客户端的指令发送给任何服务器都是有效的。 要保证所有服务器执行相同的状态机指令序列，我们执行多轮paxos一致性算法，第i轮产生的决议作为指令序列中第i条状态机指令。每个服务器都将作为提议人、审核人和执行人参与到算法中。我们假设服务器组不发生变动，每一轮算法执行都是用同一组服务器。 通常，某个服务器会被选出作为提议人代表，在每一轮算法执行时，只有代表可以提出议案。客户端向代表发送指令，由提议人代表决定指令应该何时执行。如果代表决定某条指令应当成为指令队列中第135条指令，他会把这条指令作为议案内容发送给审核人，最终形成决议。一般情况下总是可以成功的。但也有失败的可能，如果出现通信失败、停机或者另一个服务器误以为自己也是提议人代表，并且希望另一条指令成为第135条指令。但是Paxos算法保证至多只有一条指令可以成为第135条指令。 产生这一结果的关键是，在Paxos一致性算法中，决议必须要经过复审才可以产生。回想一下，当议案通过初审时，提议人自己也不确定议案内容是什么，他必须根据审批人的回复来决定要么使用之前的议案内容、要么自己决定议案内容。 现在我将描述正常情况下Paxos状态机如何工作。稍后，再来讨论可能出现的风险。考虑上一个代表停机，新的代表刚刚选出的情况。（系统启动状态是一个特殊状态，此时还没有任何议案提出） 新的提议人代表，作为执行人，应当知道已经产生的指令队列中的大部分指令。假设他知道指令1-134号，138号和139号，即第1轮到134轮，138轮和139轮算法执行的结果。（我们稍后会看到这种指令空缺是如何产生的）然后他开始执行空缺的135-137轮算法以及139轮以后的算法的初审阶段。假设只有135轮和140轮的议案初审通过的回复中包含指令信息，其他轮的初审回复不包含指令信息【这里是指135轮和140轮之前已经进行过，在初审通过的返回信息中包含了之前已经进入复审阶段的议案，而进入复审阶段的议案是包含议案内容的，因此不需要等待客户端发送指令请求来决定议案内容，可以直接发起复审请求】。提议人代表之后会执行135轮和140轮的复审阶段，最终产生135号指令和140号指令。 提议人代表以及所有从提议人代表处了解到所有指令的服务器都可以执行1-135号指令。但是，138号-140号指令不能执行，因为136号和137号指令还没有产生。提议人可以用接下来收到的两条客户端指令请求作为136号和137号指令。但是为了立即弥补指令空缺，我们用‘no-op’指令作为136号和137号指令的议案内容，这一指令不会对状态机状态产生影响。一旦这两条no-op指令被选出为决议，指令138号-140号就可以执行了。 第1号-140号指令都已经产生。提议人代表也已经完成了所有编号大于140的指令的初审阶段，提议人代表可以自由决定复审阶段应当使用的议案内容。他把接下来收到的第一个客户端指令请求作为141号指令进行复审。接着把收到的下一条客户端指令作为142号，以此类推。 提议人代表不需要等待141号指令产生就可以发起142号指令的复审请求。有可能提议人发出的所有141号指令复审请求都发送失败，可能142号指令已经产生了，执行人还不知道141号指令的内容是什么。当执行人没有收到关于141号指令的复审请求回复时，他会再次发送请求。如果一切正常，141号指令就会成功产生。然而，这次仍有可能失败，导致指令队列中出现空缺。综上，如果一个提议人可以一次产生长度为α的指令队列，那么当指令1到指令i产生后，他可以继续产生指令i+1到i+α。最坏的情况是产生一个α-1大小的指令空缺。【i+1轮到i+α-1轮的算法执行都没有成功，i+α轮执行成功】 新产生的提议人代表要执行无限多次初审请求【初审请求为了确定议案的编号，不需要知道议案的内容，也就是说在收到初审通过的回复前，提议人也不知道指令内容是什么，由于整个系统中只有一个提议人发送请求，初审请求一般是一次通过的】，在上面的场景中，提议人要执行135轮-137轮以及139轮之后算法的初审阶段。通过在审核回复中添加额外的信息【当前算法执行轮数】，提议人就可以在不同算法执行轮中使用相同的议案编号。在初审阶段，仅当某个议案进入复审阶段时，审批人在回复给其他提议人的初审通过消息中会附带该议案的议案编号和议案内容。因此，审批人对于每一轮算法执行过程中的消息回复都可以非常精简。【仅包括算法执行轮数和已经进入复审的议案内容】即使执行无穷多次初审阶段也不会造成任何问题。 由于提议人代表停机并选择新的提议人是非常罕见的情况，产生状态机指令序列的效率，也就是在指令/决议上达成一致的效率仅仅取决于算法执行的复审阶段。可以证明，在允许失效的情况下【停机、消息发送失败】，Paxos算法比其他任何算法都更加高效。因此，Paxos算法绝对是一致性算法的最佳选择。 以上讨论假设提议人代表在系统中一直在线，除了当前代表停机和选出新代表间的短暂时间。在特殊情况下，新代表的选举也可能失败。如果没有提议人代表在线，就无法产生新的指令。如果多个服务器都认为自己是代表，那么他们会在算法执行的每一轮都提出议案，导致活锁，同样使得指令无法产生。然而算法的安全性是可以保证的，两个服务器也许会提出不同的议案，但是他们的议案内容必然是相同的。选出单个的提议人代表只是为了避免活锁的出现。 如果服务器组可以变动，必须有办法确定哪些服务器参与了某一轮算法的执行。最简单的方法是通过改变状态机状态来实现。当前服务器组作为状态信息的一部分，当服务器发生变化时，可以通过状态机指令修改状态来记录。在执行完第i条指令后，通过标明将要参与第i+α轮算法执行的服务器组，就可以保证执行人代表可以提前发布α条指令的初审请求。这样就实现了一个简单地arbitrarily sophisticated reconfiguration algorithm。 参考文献 [1] Michael J. Fischer, Nancy Lynch, and Michael S. Paterson. Impossibility of distributed consensus with one faulty process. Journal of the ACM, 32(2):374–382, April 1985. [2] Idit Keidar and Sergio Rajsbaum. On the cost of fault-tolerant consensus when there are no faults—a tutorial. TechnicalReport MIT-LCS-TR-821, Laboratory for Computer Science, Massachusetts Institute Technology, Cambridge, MA, 02139, May 2001. also published in SIGACT News 32(2) (June 2001). [3] Leslie Lamport. The implementation of reliable distributed multiprocess systems. Computer Networks, 2:95–114, 1978. [4] Leslie Lamport. Time, clocks, and the ordering of events in a distributed system. Communications of the ACM, 21(7):558–565, July 1978. [5] Leslie Lamport. The part-time parliament. ACM Transactions on Com- puter Systems, 16(2):133–169, May 1998. 附录 议案编号生成算法 在Google的Chubby论文中给出了这样一种方法： 假设有n个proposer，每个编号为ir(0&lt;=ir&lt;n)，proposol编号的任何值s都应该大于他已知的最大值，并且满足：s %n = ir =&gt; s = m*n + ir proposer已知的最大值来自两部分：proposer自己对编号自增后的值和接收到acceptor的reject后所得到的值 以3个proposer P1、P2、P3为例，开始m=0,编号分别为0，1，2 P1提交的时候发现了P2已经提交，P2编号为1 &gt; P1的0，因此P1重新计算编号：new P1 = 1*3+0 = 4 P3以编号2提交，发现小于P1的4，因此P3重新编号：new P3 = 1*3+2 = 5 作者：哇噜噜大王没有巴 链接：https://www.jianshu.com/p/6d01a8d2df9f 來源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://lincy.online/tags/zookeeper/"}]},{"title":"zookeeper学习笔记（1）2PC和3PC","slug":"zookeeper学习笔记/zookeeper学习笔记（1）2PC和3PC","date":"2018-01-18T03:02:33.000Z","updated":"2018-02-12T11:23:30.374Z","comments":true,"path":"2018/01/18/zookeeper学习笔记/zookeeper学习笔记（1）2PC和3PC/","link":"","permalink":"https://lincy.online/2018/01/18/zookeeper学习笔记/zookeeper学习笔记（1）2PC和3PC/","excerpt":"","text":"分布式系统的挑战事务ACID 原子性 一致性 隔离性 未授权读取，允许脏读 授权读取，允许不可重复读 可重复读取，允许幻读 串行化 持久性 CAP理论分布式系统不可能同时满足C（一致性），A（可用性），P（分区容错性） BASE理论对CAP中一致性和可用性权衡的结果，无法做到强一致性 Basically Avalible，基本可用 Soft State，软状态 相对于硬状态，存在中间状态 Eventually consistent，最终一致性 一致性协议2PC与3PC角色：参与者，协调者 2PC 阶段一 提交事务请求（也称为投票阶段） 事务询问 协调者向参与者发送事务内容，询问是否可以执行事务，等待响应 执行事务 执行事务，记录undo和redo信息到事务日志中 参与者向协调者反馈事务询问的相应 如果成功执行事务，反馈yes 如果执行失败，反馈no 阶段二 执行事务请求 包含两种可能： 得到的反馈都是yes，则执行事务提交： 发送提交请求：协调者向所有参与者发送commit请求 事务提交：参与者收到commit请求，执行commit操作 反馈commit结果：完成事务提交之后，向协调者发送ack消息 完成事务：协调者收到所有参与则的ack后，完成事务 任意一个参与者反馈了no，或者协调者等待反馈超时，那么就中断事务： 向所有参与者发送rollback回滚请求 参与者收到rollback请求，根据undo信息回滚 反馈回滚结果：参与者回滚之后，向协调者发送ack消息 协调者收到所有参与者反馈的ack消息后，完成事务中断 优点简单，实现方便 缺点 同步阻塞 二阶段执行阶段，所有参与者都处于阻塞阶段，等待其他参与者的响应（阶段一） 单点问题 协调者 脑裂，数据不一致 阶段二协调者崩溃，导致只有部分参与者收到commit请求，数据不一致 太过保守 参与者发生故障，协调者只能通过超时机制感知 3PC阶段一：CanCommit 事务询问：协调者向参与者发送CanCommit请求 反馈yes或者no：参与者向协调反馈是否可以执行事务 阶段二：PreCommit包含两种可能： 执行事务提交，参与者反馈的都是yes 发送预提交请求 协调者向所有参与者发出preCommit请求，进入Prepared阶段 事务预提交 参与者接收到preCommit请求，执行事务操作，记录undo和redo信息到事务日志 参与者反馈事务执行的响应 如果参与者成功执行了操作，向协调者发送ack响应，同时等待协调者的最终指令：commit或者abort 中断事务，任意参与者反馈了no，或者等待超时 发送中断请求 协调者发送abort请求 中断事务 收到协调者的abort请求，或者等待协调者请求超时，参与者中断事务 阶段三：DoCommit也包含两种可能： 执行提交 发送提交请求 协调者收到所有参与者的ack，从“预提交”状态转换到“提交”状态，向参与者发送doCommit请求 事务提交 参与者收到doCommit请求，执行事务提交操作 反馈事务提交结果 参与者向协调者发送ack消息 完成事务 协调者收到所有的ack，完成事务 中断事务，任意一个参与者反聩了no，或者协调者接收反馈超时 发送中断请求 协调者发送abort请求 事务回滚 参与者收到abort请求后，根据undo信息回滚 反馈回滚结果 参与者回滚后，发送ack消息 中断事务 协调者收到所有ack后，中断事务 注意：进入阶段三，协调者crash或者网络出现故障，参与者无法收到协调者的abort或者doCommit请求，会在等待超时后进行事务提交（这点在2PC协议中，参与者会一直阻塞下去） 优点降低了2PC参与者的阻塞范围 缺点参与者收到preCommit后，如果协调者crash或者网络出现分区，此时协调者和参与者无法通信，此时参与者仍然将提交事务，会导致不一致性","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://lincy.online/tags/笔记/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://lincy.online/tags/zookeeper/"}]},{"title":"服务器性能指标","slug":"性能指标","date":"2018-01-17T08:24:50.000Z","updated":"2018-02-13T15:13:08.050Z","comments":true,"path":"2018/01/17/性能指标/","link":"","permalink":"https://lincy.online/2018/01/17/性能指标/","excerpt":"","text":"吞吐率（throughout） web服务器单位时间内处理的请求数，单位req/s 吞吐量 一次性能测试过程中网络传输的数据量的总和 事务，tps（Transaction per second） 就是用户某一步或几步操作的集合。不过，我们要保证它有一个完整意义。比如用户对某一个页面的一次请求，用户对某系统的一次登录，淘宝用户对商品的一次确认支付过程。这些我们都可以看作一个事务。那么如何衡量服务器对事务的处理能力。又引出一个概念—-TPS 每秒钟系统能够处理事务或交易的数量，它是衡量系统处理能力的重要指标。 点击率是tps的一种特定情况，一次鼠标点击，客户端可能向服务器发送多个请求。","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[]},{"title":"vim正则替换技巧","slug":"vim正则替换技巧","date":"2017-05-09T06:51:34.000Z","updated":"2018-03-10T09:15:46.525Z","comments":true,"path":"2017/05/09/vim正则替换技巧/","link":"","permalink":"https://lincy.online/2017/05/09/vim正则替换技巧/","excerpt":"","text":"通过以下命令：:.,+6s/ r&#39;\\(.*\\)&#39;/ re.compile(&#39;\\1&#39;)/将就可以批量将python中 r&#39;...&#39;的 字符串批量替换成 re.compile(&#39;...&#39;) 其中使用\\(和\\)包含起来，后面可以使用\\1,\\2指代","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"vim","slug":"vim","permalink":"https://lincy.online/tags/vim/"}]},{"title":"python装饰器","slug":"python装饰器","date":"2017-03-20T02:19:09.000Z","updated":"2018-07-17T17:10:27.407Z","comments":true,"path":"2017/03/20/python装饰器/","link":"","permalink":"https://lincy.online/2017/03/20/python装饰器/","excerpt":"","text":"import functools # 不带参数的装饰器 def log(func): @functools.wraps(func) def wrapper(*args, **kw): print(&#39;call %s&#39; % func.__name__) return func(*args, **kw) return wrapper # 带参数的装饰器 def log2(name): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print(&#39;%s call %s&#39; % (name, func.__name__)) return func(*args, **kw) return wrapper return decorator # 兼容带参数和不带参数 def log3(p): def build_wrapper(func, name=None): @functools.wraps(func) def wrapper(*args, **kw): print(&#39;%s call %s&#39; % (name if name else &#39;somebody&#39;, func.__name__)) return func(*args, **kw) return wrapper if callable(p): # 不带参数 return build_wrapper(p) else: # 带参数 def decorator(func): return build_wrapper(func, p) return decorator @log def test(): print(&#39;test!&#39;) # 输出： # call test # test! @log2(&#39;Tom&#39;) def test2(): print(&#39;test2&#39;) # 输出： # Tom call test2 # test2 @log3 def test3(): print(&#39;test3&#39;) # 输出： # somebody call test3 # test3 @log3(&#39;Jim&#39;) def test4(): print(&#39;test4&#39;) # 输出： # Jim call test4 # test4 if __name__ == &#39;__main__&#39;: test() test2() test3() test4()","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"https://lincy.online/tags/python/"}]},{"title":"观察者模式","slug":"观察者模式","date":"2017-03-05T08:42:54.000Z","updated":"2018-03-10T09:15:46.537Z","comments":true,"path":"2017/03/05/观察者模式/","link":"","permalink":"https://lincy.online/2017/03/05/观察者模式/","excerpt":"","text":"public interface Observer { /** * 观察者更新方法 * 拉模式：传入整个Subject对象，让观察者自行操作 * 推模式：Subject知道Observer所需要的数据，只传入相应参数 */ void update(Subject subject); } public class ConcreteObserver implements Observer{ @Override public void update(Subject subject) { System.out.println(&quot;观察者被调用了&quot;); } } public class Subject { /** * 观察者 */ private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); public void addObserver(Observer observer){ this.observers.add(observer); } public void removeObserver(Observer observer){ this.observers.remove(observer); } public void notifyObservers(){ for (Observer observer: observers){ observer.update(this); } } } 优点： 动态注册，动态联动 广播 需要注意循环广播的发生","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"代理模式","slug":"代理模式","date":"2017-02-27T09:25:20.000Z","updated":"2018-03-01T15:26:05.486Z","comments":true,"path":"2017/02/27/代理模式/","link":"","permalink":"https://lincy.online/2017/02/27/代理模式/","excerpt":"静态代理 代理模式","text":"静态代理 代理模式 public interface Subject { void request(); } public interface Subject { void request(); } public class Proxy implements Subject{ private RealSubject subject; public Proxy(RealSubject subject) { this.subject = subject; } @Override public void request() { //在调用目标对象方法之前，执行一些功能处理 subject.request(); //在调用目标对象方法之后，执行一些功能处理 } } 动态代理（Java动态代理）public class DynamicProxy implements InvocationHandler{ private Subject subject; public Subject getInstance(Subject subject) { this.subject = subject; return (Subject) Proxy.newProxyInstance(subject.getClass().getClassLoader(), subject.getClass().getInterfaces(), this); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //在调用目标对象方法之前，执行一些功能处理 return method.invoke(proxy, args); //在调用目标对象方法之后，执行一些功能处理 } } public class Client { public static void main(String[] args){ Subject subject = new RealSubject(); new DynamicProxy().getInstance(subject).request(); } }","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lincy.online/tags/设计模式/"}]},{"title":"RabbitMQ学习笔记","slug":"RabbitMQ学习笔记","date":"2016-10-22T07:03:26.000Z","updated":"2018-10-22T12:52:27.659Z","comments":true,"path":"2016/10/22/RabbitMQ学习笔记/","link":"","permalink":"https://lincy.online/2016/10/22/RabbitMQ学习笔记/","excerpt":"基本概念","text":"基本概念 ProducerConsumerBroker消息中间件的服务节点 QueueExchange生产者将消息发送到Exchange，由交换器将消息路由到一个或多个队列。 RoutingKey路由键，指定路由规则。生产者将消息发给交换器的时候，一般会指定一个RoutingKey，用来指定这个消息的路由规则，而这个Routing Key需要与交换器类型和绑定键（BindingKey）联合使用才能最终生效。 Binding绑定。RabbitMQ中通过绑定将交换器与队列关联起来，在绑定的时候一般会指定一个绑定键（BindingKey），这样RabbitMQ就知道如何正确地将消息路由到队列了。 生产者将消息发送给交换器时，需要一个RoutingKey，当BindingKey和RoutingKey 相匹配时，消息会被路由到对应的队列中。 交换器类型fanout它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。 directdirect类型的交换器路由规则也很简单，它会把消息路由到那些BindingKey和RoutingKey完全匹配的队列中。 topictopic类型的交换器在匹配规则上进行了扩展，它与direct类型的交换器相似，也是将消息路由到BindingKey和RoutingKey相匹配的队列中，但这里的匹配规则有些不同，它约定： RoutingKey 为一个点号“.”分隔的字符串（被点号“.”分隔开的每一段独立的字符串称为一个单词），如“com.rabbitmq.client”、“java.util.concurrent”、“com.hidden.client”； BindingKey和RoutingKey一样也是点号“.”分隔的字符串； BindingKey中可以存在两种特殊字符串“”和“#”，用于做模糊匹配，其中“ ”用于匹配一个单词，“ # ”用于匹配多个单词（可以是零个）。 以图2-8中的配置为例：· 路由键为“com.rabbitmq.client”的消息会同时路由到Queuel和Queue2；· 路由键为“com.hidden.client”的消息只会路由到Queue2中；· 路由键为“com.hidden.demo”的消息只会路由到Queue2中；· 路由键为“java.rabbitmq.demo”的消息只会路由到Queue1中；· 路由键为“java.util.concurrent”的消息将会被丢弃或者返回给生产者（需要设置mandatory参数），因为它没有匹配任何路由键。 headersheaders类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。在绑定队列和交换器时制定一组键值对，当发送消息到交换器时，RabbitMQ会获取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers类型的交换器性能会很差，而且也不实用，基本上不会看到它的存在。 Connection 和 Channel 无论是生产者还是消费者，都需要和RabbitMQBroker建立连接，这个连接就是一条TCP连接，也就是Connection。一旦TCP连接建立起来，客户端紧接着可以创建一个AMQP信道（Channel），每个信道都会被指派一个唯一的ID。信道是建立在Connection之上的虚拟连接，RabbitMQ处理的每条AMQP指令都是通过信道完成的。（采用类似NIO的做法，选择TCP连接复用，不仅可以减少性能开销，同时也便于管理。） RabbitMQ 开发消费模式RabbitMQ的消费模式分两种：推（Push）模式和拉（Pull）模式。推模式采用Basic.Consume进行消费，而拉模式则是调用Basic.Get进行消费。 推模式import com.rabbitmq.client.Consumer; import com.rabbitmq.client.DefaultConsumer; boolean autoAck=false; channel. basicQos(64); //接收消息一般通过实现Consumer 接口或者继承 DefaultConsumer类来实现。 //当调用与Consumer相关的API方法时，不同的订阅采用不同的消费者标签（consumerTag）来区分彼此，在同一个channel中的消费者也需要通过唯一的消费者标签以作区分 channel. basicConsume(queueName, autoAck,&quot;myConsumerTag&quot;, new DefaultConsumer(channel){ @override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String routingkey =envelope. getRoutingKey(); String contentType=properties. getContentType(); long deliveryTag=envelope. getDeliveryTag(); //(process the message components here...) channel. basicAck(deliveryTag, false); } }); string basicConsume( String queue,boolean autoAck,String consumerTag, boolean noLocal, boolean exclusive,Map&lt;String,Object&gt;arguments,Consumer callback ) throws IOException; basicConsume 参数： queue：队列的名称； autonck：设置是否自动确认。建议设成false，即不自动确认； consumerTag：消费者标签，用来区分多个消费者； noLocal：设置为true则表示不能将同一个Connection中生产者发送的消息传送给这个Connection中的消费者； exclusive：设置是否排他； arguments；设置消费者的其他参数； callback：设置消费者的回调函数。用来处理RabbitMQ推送过来的消息，比如 Defaultconsumer，使用时需要客户端重写（override）其中的方法。 拉模式通过channel.basicGet方法可以单条地获取消息，其返回值是GetRespone。Channel类的basicGet方法没有其他重载方法，只有：GetResponse basicGet(String queue,boolean autoAck)throws IOException; 消费者的确认与拒绝确认 当autoAck等于false时，RabbitMQ会等待消费者显式地回复确认信号后才从内存（或者磁盘）中移去消息（实质上是先打上删除标记，之后再删除） 当autoAck等于true时，RabbitMQ会自动把发送出去的消息置为确认，然后从内存（或者磁盘）中删除，而不管消费者是否真正地消费到了这些消息。 当autoAck参数置为false，对于RabbitMQ服务端而言，队列中的消息分成了两个部分： 一部分是等待投递给消费者的消息； 一部分是已经投递给消费者，但是还没有收到消费者确认信号的消息。 如果RabbitMQ一直没有收到消费者的确认信号，并且消费此消息的消费者已经断开连接，则RabbitMQ会安排该消息重新进入队列，等待投递给下一个消费者，当然也有可能还是原来的那个消费者。 拒绝单条拒绝 void basicReject(long deliveryTag,boolean requeue)throws IOException; deliveryTag可以看作消息的编号，它是一个64位的长整型值，最大值是9223372036854775807。 requeue参数设置为true，则RabbitMQ会重新将这条消息存入队列，以便可以发送给下一个订阅的消费者； 如果 requeue参数设置为false，则RabbitMQ立即会把消息从队列中移除，而不会把它发送给新的消费者。 批量拒绝void basicNack(long deliveryTag,boolean multiple,boolean requeue)throws IOException; multiple参数： false：表示拒绝编号为deliveryTag的这一条消息，这时候basicNack和basicReject方法一样； true：拒绝 deliveryTag编号之前所有未被当前消费者确认的消息。 将channel.basicReject或者channel.basicNack中的requeue设置为false，可以启用“死信队列”的功能。 关闭连接//显式地关闭 Channe1是个好习惯，但这不是必须的，在Connection关闭的时候，Channe1也会自动关闭。 channel. close(); conn. close(); AMQP协议中的Connection和Channe1采用同样的方式来管理网络失败、内部错误和显式地关闭连接。Connection和Channel所具备的生命周期如下所述。 open：开启状态，代表当前对象可以使用。 Closing：正在关闭状态。当前对象被显式地通知调用关闭方法（shutdown），这样就产生了一个关闭请求让其内部对象进行相应的操作，并等待这些关闭操作的完成。 Closed：已经关闭状态。当前对象已经接收到所有的内部对象已完成关闭动作的通知，并且其也关闭了自身。 Connection和Channel最终都是会成为Closed的状态，不论是程序正常调用的关闭方法，或者是客户端的异常，再或者是发生了网络异常。 在Connection和channe1中，与关闭相关的方法有addshutdownListener (ShutdownListener listener)和removeShutdownListener(ShutdownListner listener)。当Connection或者Channel的状态转变为closed的时候会调用shutdownListener。而且如果将一个ShutdownListener 注册到一个已经处于closed状态的对象（这里特指Connection和Channe1对象）时，会立刻调用shutdownListener。 connection.addShutdownListener(new ShutdownListener(){ public void shutdownCompleted(ShutdownSignalException cause) { //ShutdownsignalException 提供了多个方法来分析关闭的原因 if(cause. isHardError()) Connection conn=(Connection) cause. getReference(); if(! cause. isInitiatedByApplication()){ Method reason=cause. getReason(); ... } else{ Channel ch=(Channe1) cause. getReference(); ... } } );","categories":[{"name":"技术","slug":"技术","permalink":"https://lincy.online/categories/技术/"}],"tags":[]},{"title":"Spring IOC 笔记","slug":"Spring-IOC-体系结构","date":"2016-10-04T16:13:15.000Z","updated":"2018-10-04T20:12:48.429Z","comments":true,"path":"2016/10/05/Spring-IOC-体系结构/","link":"","permalink":"https://lincy.online/2016/10/05/Spring-IOC-体系结构/","excerpt":"","text":"主要接口BeanFactorySpring Bean的创建是典型的工厂模式，这一系列的Bean工厂，也即IOC容器为开发者管理对象间的依赖关系提供了很多便利和基础服务，在Spring中有许多的IOC容器的实现供用户选择和使用，其相互关系如下： 其中BeanFactory作为最顶层的一个接口类，它定义了IOC容器的基本功能规范，BeanFactory有三个子类：ListableBeanFactory、HierarchicalBeanFactory 和AutowireCapableBeanFactory。但是从上图中我们可以发现最终的默认实现类是DefaultListableBeanFactory，他实现了所有的接口。那为何要定义这么多层次的接口呢？查阅这些接口的源码和说明发现，每个接口都有他使用的场合，它主要是为了区分在Spring 内部在操作过程中对象的传递和转化过程中，对对象的数据访问所做的限制。例如ListableBeanFactory 接口表示这些Bean 是可列表的，而HierarchicalBeanFactory表示的是这些Bean 是有继承关系的，也就是每个Bean有可能有父Bean。 AutowireCapableBeanFactory 接口定义Bean的自动装配规则。这四个接口共同定义了Bean的集合、Bean之间的关系、以及Bean行为. 最基本的IOC容器接口BeanFactory public interface BeanFactory{ //对FactoryBean的转义定义，因为如果使用bean的名字检索FactoryBean得到的对象是工厂生成的对象， //如果需要得到工厂本身，需要转义 String FACTORY_BEAN_PREFIX=&quot;&amp;&quot;; //根据bean的名字，获取在IOC容器中得到bean 实例 Object getBean（String name）throws BeansException; //根据bean的名字和Class类型来得到bean 实例，增加了类型安全验证机制。 Object getBean（String name，Class requiredlyee）throws BeansException; //提供对bean的检索，看看是否在IOC容器有这个名字的bean boolean containsBean（String name）; //根据bean名字得到bean实例，并同时判断这个bean是不是单例 boolean issingleton（String name）throws NoSuchBeanDefinitionException; //得到bean实例的Class类型 Class getType（String name）throws NoSuchBeanDefinitionException; //得到bean的别名，如果根据别名检索，那么其原名也会被检索出来 String[]getAliases（String name）; } 在BeanFactory里只对IOC容器的基本行为作了定义，根本不关心你的bean是如何定义怎样加载的。正如我们只关心工厂里得到什么的产品对象，至于工厂是怎么生产这些对象的，这个基本的接口不关心。而要知道工厂是如何产生对象的，我们需要看具体的IOC容器实现，Spring提供了许多IOC容器的实现。比如XmlBeanFactory，ClasspathXmlApplicationContext等。其中XmlBeanFactory就是针对最基本的IOC容器的实现，这个IOC容器可以读取XML文件定义的BeanDefinition（XML文件中对bean的描述），如果说XmlBeanFactory是容器中的屌丝，ApplicationContext应该算容器中的高帅富.ApplicationContext是Spring提供的一个高级的IOC容器，它除了能够提供IOC容器的基本功能外，还为用户提供了以下的附加服务。从ApplicationContext接口的实现，我们看出其特点： 支持信息源，可以实现国际化。（实现MessageSource接口） 访问资源。（实现ResourcePatternResolver 接口，这个后面要讲） 支持应用事件。（实现ApplicationEventPublisher接口） BeanDefinitionSpringIOc容器管理了我们定义的各种Bean对象及其相互的关系，Bean对象在Spring实现中是以BeanDefinition来描述的，其继承体系如下： Bean的解析过程非常复杂，功能被分的很细，因为这里需要被扩展的地方很多，必须保证有足够的灵活性，以应对可能的变化。Bean 的解析主要就是对Spring 配置文件的解析。这个解析过程主要通过下图中的类完成： IOC容器的初始化IOC容器的初始化包括BeanDefinition的 Resource定位、载入和注册这三个基本的过程。我们以ApplicationContext 为例讲解，ApplicationContext系列容器也许是我们最熟悉的，因为web项目中使用的XmlWebApplicationContext 就属于这个继承体系，还有ClasspathXmlApplicationContext等，其继承体系如下图所示： ApplicationContext 允许上下文嵌套，通过保持父上下文可以维持一个上下文体系。对于bean的查找可以在这个上下文体系中发生，首先检查当前上下文，其次是父上下文，逐级向上，这样为不同的Spring应用提供了一个共享的bean定义环境。 下面我们分别简单地演示一下两种ioc容器的创建过程 XmlBeanFacotry的整个流程通过XmlBeanFactory的源码，我们可以发现： public class XmlBeanFactory extends DefaultListableBeanFactory{ private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this); public XmlBeanFactory(Resource resource) throws BeansException{ this(resource, nul1); } public XmlBeanFactory(Resource resource, BeanFactory parent BeanFactory) throws BeansException{ super(parentBeanFactory); this. reader. loadBeanDefinitions(resource); } } 调用全过程还原，定位、载入、注册: //根据Xml配置文件创建Resource资源对象，该对象中包含了BeanDefinition的信息 ClassPathResource resource =new ClassPathResource（&quot;application-context.xml&quot;）; //创建 DefaultListableBeanFactory DefaultListableBeanFactory factory =new DefaultListab leBeanFactory（）; //创建XmlBeanDefinitionReader读取器，用于载入BeanDefinition。之所以需要BeanFactory作为参数，是因为会将读取的信息回调配置给 factory XmlBeanDefinitionReader reader =new XmlBeanDefinitionReader（factory）; //XmlBeanDefinitionReader执行载入Beanpefinition的方法，最后会完成Bean的载入和注册。完成后Bean就成功的放置到IoC容器当中，以后我们就可以从中取得Bean来使用 reader.loadBeanDefinitions（resource）; 通过前面的源码，this.reader=new XmlBeanDefinitionReader（this）; 中其中this传的是factory对象。 FileSystemXmlApplicationContext 的IOC容器流程ApplicationContext=new FileSystemxmlApplicationContext(xmlPath); /** *Create a new FileSystemxmlApplicationContext,loading the definitions * from the given XML files and automatically refreshing the context. *@param configlocations array of file paths *@throws BeansException if context creation failed */ public FileSystemXmlApplicationContext(String... configlocations)throws BeansException{ this(configlocations,true,null); } 构造方法 public FilesystemXmlApplicationContext(String[] configLocations,boolean refresh,ApplicationContextparent)throws BeansException{ super(parent); setConfigLocations(configLocations); if(refresh){ refresh(); } } 设置资源加载器和资源定位 通过分析FileSystemxmlApplicationContext的源代码可以知道，在创建FileSystemXmlApplicationContext容器时，构造方法做以下两项重要工作： - 首先，调用父类容器的构造方法（super（parent）方法）为容器设置好Bean 资源加载器。 - 然后，再调用父类`Abstract RefreshableConfigApplicationContext的setConfigLocations（configLocations）`方法设置Bean定义资源文件的定位路径。 通过追踪FileSystemxmlApplicationContext的继承体系，发现其父类的父类AbstractApplicationContext中初始化IOC容器所做的主要源码如下： public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext，DisposableBean{ //静态初始化块，在整个容器创建过程中只执行一次 static{ //为了避免应用程序在Weblogic8.1关闭时出现类加载异常加载问题，加载IoC容 //器关闭事件（ContextClosedEvent）类 ContextClosedEvent.class.getName（）； } public AbstractApplicationcontext（）{ this.resourcePatternResolyer.=getResourcePatternResolver（）； } //5ileSystemxmlApplicationContext 调用父构造方法调用的就是该方法 public AbstractApplicationContext（Applicat ionContextparent）{ this（）； setParent（parent）； } //获取一个Spring Source的加载器用于读入Spring Bean定义资源文件 protected ResourcePatternResolver getResourcePatternResolver（）{ //AbstractApplicationContext继承DefaultResourceLoader，因此也是一个资源加载器 //Spring 资源加载器，其getResource（String location）方法用于载入资源 return new PathMatchingResourcePatternResolver（this）； } ... } AbstractApplicationContext 构造方法中调用PathMatchingResourcePatternResolver的构造方法创建Spring资源加载器： public PathMatchingResourcePatternResolver（ResourceLoader resourceloader）{ Assert.notNull（resourceLoader，&quot;ResourceLoader must not be null&quot;）； //设置Spring的资源加载器 this.resourceLoader=resourceLoader； } 在设置容器的资源加载器之后，接下来ileSystemXmlApplicationContet 执行 setConfigLocations方法通过调用其父类AbstractRefreshableConfigApplicationContext的方法进行对Bean 定义资源文件的定位，该方法的源码如下： //处理单个资源文件路径为一个字符串的情况 public void setConfiglocation（String location）{ //String CONFIG_LOCATION_DELIMITERS=&quot;，；/t/n&quot;； //即多个资源文件路径之间用”，；/t/n”分隔，解析成数组形式 setConfiglocations（Stringutils.tokenizelostringArra.（location，CONF IG_LOCATION_DELIMITERS））； } //解析Bean定义资源文件的路径，处理多个资源文件字符串数组 public void setConfigLocations（String[] locations）{ if（locations ！=null）{ Assert.nolullElements（locations，&quot;Config locations must not be null&quot;）； this.configlocations =new String[locations.1ength]； for（inti=0；i&lt;locations.length；i++）{ //resolvePath为同一个类中将字符串解析为路径的方法 this.configlocations[i]=resolvdpath（locations[i]）.trim（）； } else{ this.configlocations=null； } } } 通过这两个方法的源码我们可以看出，我们既可以使用一个字符串来配置多个Spring Bean 定义资源文件，也可以使用字符串数组，即下面两种方式都是可以的：A. ClasspathResource res =new ClasspathResource（“a.xml，b.xml，……”）；多个资源文件路径之间可以是用”，；/t/n”等分隔。B. ClasspathResource res =new ClasspathResource（newString[]{“a.xml”，”b.xml”，……}）；至此，Spring IOC容器在初始化时将配置的Bean定义资源文件定位为Spring 封装的Resource。 AbstractApplicationContext的 refresh 函数载入Bean定义过程： Spring IOC容器对Bean 定义资源的载入是从refresh（）函数开始的，refresh（）是一个模板方法，refresh（）方法的作用是：在创建IOC容器前，如果己经有容器存在，则需要把己有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IOC容器。refresh的作用类似于对IOC容器的重启，在新建立好的容器中对容器进行初始化，对Bean定义资源进行载入FileSystemXmlApplicationContext 通过调用其父类AbstractApplicationContext的 refresh（）函数启动整个IoC容器对Bean定义的载入过程： public void refresh（） throws BeansException，IllegalstateException{ synchronized（this.startueshut downMonitor）{ //调用容器准备刷新的方法，获取容器的当时时间，同时给容器设置同步标识 prepareRefresh（）； //告诉子类启动refreshBeanFactory（）方法，Bean定义资源文件的载入从 //子类的refreshBeanFactory（）方法启动 ConfigurablelistableBeanFactory beanFactorx=obtainFreshBeanFactorx（）； //为BeanFactory配置容器特性，例如类加载器、事件处理器等 prepareBeanFactory（beanFactorx）； try{ //为容器的某些子类指定特殊的BeanPost事件处理器 postProcessBeanFactory（beanFactorx）； //调用所有注册的BeanFactoryPostProcessor的Bean invokeBeanFactoryPostProcessors（beanFactory）； //为BeanFactory注册 BeanPost事件处理器. //BeanPostProces sor是Bean后置处理器，用于监听容器触发的事件 registerBeanPostprocessors（beanFactory）； //初始化信息源，和国际化相关. initMessagesource（）； //初始化容器事件传播器。 initAplicationEventMulticaster（）； //调用子类的某些特殊Bean初始化方法 onRefresh（）； //为事件传播器注册事件监听器。 registerListeners（）； //初始化所有剩余的单例Bean. finishBeanFactoryInitialization（beanFactory）； //初始化容器的生命周期事件处理器，并发布容器的生命周期事件 finishRefresh（）； } catch （BeansException ex）{ //销毁以创建的单态Bean destroyBeans（）； //取消refresh 操作，重置容器的同步标识. cancelRefresh（ex）； throw ex； } } refresh（）方法主要为IOC容器Bean的生命周期管理提供条件，Spring IOC容器载入Bean定义资源文件从其子类容器的refreshBeanFactory（）方法启动，所以整个refresh（）中ConfigurableListableBeanFactory beanFactory =obtainFreshBeanFactory（）；这句以后代码的都是注册容器的信息源和生命周期事件，载入过程就是从这句代码启动。 refresh（）方法的作用是：在创建IOC容器前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IOC容器。 refresh的作用类似于对IOC容器的重启，在新建立好的容器中对容器进行初始化，对Bean定义资源进行载入AbstractApplicationContext的 obtainFreshBeanFactory（）方法调用子类容器的refreshBeanFactory（）方法，启动容器载入Bean定义资源文件的过程，代码如下： protected ConfigurableListableBeanFactory obtainFreshBeanFactory（）{ //父类定义了抽象的refreshBeanEactory（）方法，具体实现调用子类容器的refreshBeanFactory（）方法 refreshBeanFactory（）； Configurablel istableBeanFactory beanFactory=getBeanFactory（）； if（logger.isDebugEnabled（））{ logger.debug（&quot;Bean factory for&quot;+getDisplaylame（）+&quot;：&quot;+beanEactorx）； } return beanFactory； } AbstractApplicationContext 子类的 refreshBeanFactorx）方法：AbstractApplicationContext 类中只抽象定义了refreshBeanFactory（）方法，容器真正调用的是其子类AbstractRefreshableApplicationContext实现的refreshBeanFactory（）方法，方法的源码如下： protected final void refreshBeanFactory（）throws BeansException{ if（hasBeanFactory（））{//如果己经有容器，销毁容器中的bean，关闭容器 destroyBeans（）； closeBeanFactory（）； } try{ //创建 IOC容器 DefaultListableBeanFactory beanEactory =createbeanFactorx（）； beanFactory.setSerializationId（getId（））； //对IOC容器进行定制化，如设置启动参数，开启注解的自动装配等 sustomizeBeanFactorx（beanFactorx）； //调用载入Bean定义的方法，在当前类中只定义了抽象的loadBeanDefinitions方法，具体的实现调用子类容器 loadBeanDefinitions（beanFactory）； synchronized（this.beanFactoryMonitor）{ this.beanFactory=beanFactory； } }catch（IOException ex）{ throw new ApplicationContextException（&quot;I/0 error parsing bean definition source for&quot;+getDisplayName（），ex）; } } 在这个方法中，先判断BeanFactory是否存在，如果存在则先销毁beans 并关闭beanFactory，接着创建DefaultListableBeanFactory，并调用loadBeanDefinitions（beanFactory）装载bean定义。 AbstractRefreshableApplicationContext 子类的 loadBeanDefinitions方法： AbstractRefreshableApplicationContext 中只定义了抽象的loadBeanDefinitions方法，容器真正调用的是其子类AbstractXmlApplicationContext对该方法的实现，AbstractXmlApplicationContext的主要源码如下： loadBeanDefinitions方法同样是抽象方法，是由其子类实现的，也即在AbstractXmlApplicationContext中。 public abstract class AbstractXmlApplicationContext extends AbstractRefreshableConfigApplicationContext{ .… //实现父类抽象的载入Bean 定义方法 @Override protected void loadBeanDefinitions（pefaultListableBeanFactory beanFactory）throws BeansException，IOException{ //创建Xm1BeanDefinitionReader，即创建Bean 读取器，并通过回调设置到容器中去，容器使用该读取器读取Bean 定义资源 XmlBeanDefinitionReader beanDefinitionReader =new XmlBeanDefinitionReader（beanFactory）； //为Bean 读取器设置Spring 资源加载器，AbstractXmlApplicationContext的 //祖先父类AbstractApplicationContext继承DefaultResourcelLoader，因此，容器本身也是一个资源加载器 beanDefinitionReader.setEnvironment（this.getEnvironment（））；beanDefinitionReader.setResourceLoader（this）； //为Bean读取器设置SAxxm1解析器 beanDefinitionReader.setEntityResolver（new ResourceEntityResolver（this））； //当Bean读取器读取Bean定义的Xml资源文件时，启用Xml的校验机制 init BeanDefinitionReader（beanDefinitionReader）； //Bean 读取器真正实现加载的方法 loadBeanDefinitions（beanDefinitionReader）； } //Xml Bean 读取器加载Bean定义资源 protected void loadBeanDefinitions（XmlBeanDefinitionReader reader） throws BeansException，IOException { //获取Bean定义资源的定位 Resource[]configResources=getConfigResources（）； if（sonfigResources.！=null）{ //Xml Bean 读取器调用其父类AbstractBeanDefinitionReader读取定位 //的Bean 定义资源 reader.loadBeanDefinitions（configResources）； } //如果子类中获取的Bean定义资源定位为空，则获取FilesystemxmlApplicationContext构造方法中 setConfigLocations方法设置的资源 String[]configlocations =getConfiglocations（）； if（configlocations！=null）{ //Xml Bean读取器调用其父类AbstractBeanDefinitionReader读取定位 reader.loadBeanDefinitions(configLocations); } }","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lincy.online/tags/Spring/"}]}]}
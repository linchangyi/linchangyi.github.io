<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lincy&#39;s Blog</title>
  
  <subtitle>归去来兮，Just Do IT.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lincy.online/"/>
  <updated>2019-08-18T00:25:18.516Z</updated>
  <id>https://lincy.online/</id>
  
  <author>
    <name>Lincy</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Titanic - Machine Learning from Disaster</title>
    <link href="https://lincy.online/2019/06/22/titanic_advanced/"/>
    <id>https://lincy.online/2019/06/22/titanic_advanced/</id>
    <published>2019-06-22T10:00:04.000Z</published>
    <updated>2019-08-18T00:25:18.516Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Titanic-Machine-Learning-from-Disaster"><a href="#Titanic-Machine-Learning-from-Disaster" class="headerlink" title="Titanic: Machine Learning from Disaster"></a>Titanic: Machine Learning from Disaster</h1><h2 id="Libraries"><a href="#Libraries" class="headerlink" title="Libraries"></a>Libraries</h2><a id="more"></a><pre><code class="python">import numpy as npimport pandas as pd</code></pre><pre><code class="python">import matplotlib.pyplot as pltimport seaborn as sns</code></pre><pre><code class="python">sns.set(style=&quot;darkgrid&quot;)</code></pre><pre><code class="python">from sklearn.ensemble import RandomForestClassifierfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScalerfrom sklearn.metrics import roc_curve, aucfrom sklearn.model_selection import StratifiedKFold</code></pre><pre><code class="python">import stringimport warnings</code></pre><pre><code class="python">warnings.filterwarnings(&#39;ignore&#39;)</code></pre><pre><code class="python">SEED = 42</code></pre><pre><code class="python">def pandas_df_to_markdown_table(df):    from IPython.display import Markdown, display    fmt = [&#39;---&#39; for i in range(len(df.columns))]    df_fmt = pd.DataFrame([fmt], columns=df.columns)    df_formatted = pd.concat([df_fmt, df])    display(Markdown(df_formatted.to_csv(sep=&quot;|&quot;, index=False)))</code></pre><ul><li><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2></li></ul><ul><li>训练数据 891 条，测试数据 418 条</li><li>训练数据 12 个特征，测试数据 11 个特征</li><li>训练数据 多了一个 ‘Survived’ 特征</li></ul><pre><code class="python">def concat_df(train_data, test_data):    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)</code></pre><pre><code class="python">def divide_df(all_data):    return all_data.loc[:890], all_data[891:].drop([&#39;Survived&#39;], axis=1)</code></pre><pre><code class="python">df_train = pd.read_csv(&#39;./data/train.csv&#39;)df_test = pd.read_csv(&#39;./data/test.csv&#39;)df_all: pd.DataFrame = concat_df(df_train, df_test)</code></pre><pre><code class="python">df_train.name = &#39;Training Set&#39;df_test.name = &#39;Test Set&#39;df_all.name = &#39;All Set&#39;</code></pre><pre><code class="python">print(&#39;Number of Training Examples = {}&#39;.format(df_train.shape[0]))print(&#39;Number of Test Examples = {}\n&#39;.format(df_test.shape[0]))print(&#39;Training X Shape = {}&#39;.format(df_train.shape))print(&#39;Training y Shape = {}\n&#39;.format(df_train[&#39;Survived&#39;].shape[0]))print(&#39;Test X Shape = {}&#39;.format(df_test.shape))print(&#39;Test y Shape = {}\n&#39;.format(df_test.shape[0]))print(df_train.columns)print(df_test.columns)</code></pre><pre><code>Number of Training Examples = 891Number of Test Examples = 418Training X Shape = (891, 12)Training y Shape = 891Test X Shape = (418, 11)Test y Shape = 418Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],      dtype=&#39;object&#39;)Index([&#39;PassengerId&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;,       &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],      dtype=&#39;object&#39;)</code></pre><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><ul><li>PassengerId 是数据的主键，对预测没有任何影响</li><li>Survived 值为 0 or 1<ul><li>1 幸存</li><li>2 丧生</li></ul></li><li>Pclass 类别标示，乘客等级<ul><li><ol><li>高级</li></ol></li><li><ol start="2"><li>中级</li></ol></li><li><ol start="3"><li>普通</li></ol></li></ul></li><li>Name，Sex，Age</li><li>SibSp 乘客的兄弟姐妹数量</li><li>Parch 乘客的父母和子女的数量</li><li>Ticket 船票的号码</li><li>fare 船票费用</li><li>Cabin 船舱号码</li><li>Embarked 登船的码头<ul><li>C = Cherbourg</li><li>Q = Queenstown</li><li>S = Southampton</li></ul></li></ul><pre><code class="python">print(df_train.info())pandas_df_to_markdown_table(df_train.sample(3))</code></pre><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns):PassengerId    891 non-null int64Survived       891 non-null int64Pclass         891 non-null int64Name           891 non-null objectSex            891 non-null objectAge            714 non-null float64SibSp          891 non-null int64Parch          891 non-null int64Ticket         891 non-null objectFare           891 non-null float64Cabin          204 non-null objectEmbarked       889 non-null objectdtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KBNone</code></pre><table><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr></thead><tbody><tr><td>95</td><td>0</td><td>3</td><td>Coxon, Mr. Daniel</td><td>male</td><td>59.0</td><td>0</td><td>0</td><td>364500</td><td>7.25</td><td></td><td>S</td></tr><tr><td>434</td><td>0</td><td>3</td><td>Kallio, Mr. Nikolai Erland</td><td>male</td><td>17.0</td><td>0</td><td>0</td><td>STON/O 2. 3101274</td><td>7.125</td><td></td><td>S</td></tr><tr><td>371</td><td>1</td><td>1</td><td>Harder, Mr. George Achilles</td><td>male</td><td>25.0</td><td>1</td><td>0</td><td>11765</td><td>55.4417</td><td>E50</td><td>C</td></tr></tbody></table><pre><code class="python">print(df_test.info())</code></pre><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 418 entries, 891 to 1308Data columns (total 44 columns):Age                        418 non-null int64Deck                       418 non-null int64Embarked                   418 non-null int64Fare                       418 non-null int64Name                       418 non-null objectParch                      418 non-null int64PassengerId                418 non-null int64Pclass                     418 non-null int64Sex                        418 non-null int64SibSp                      418 non-null int64Survived                   0 non-null float64Ticket                     418 non-null objectFamily_Size                418 non-null int64Family_Size_Grouped        418 non-null int64Ticket_Frequency           418 non-null int64Title                      418 non-null int64Is_Married                 418 non-null int64Family                     418 non-null objectFamily_Survival_Rate       418 non-null float64Family_Survival_Rate_NA    418 non-null int64Ticket_Survival_Rate       418 non-null float64Ticket_Survival_Rate_NA    418 non-null int64Survival_Rate              418 non-null float64Survival_Rate_NA           418 non-null float64Pclass_1                   418 non-null float64Pclass_2                   418 non-null float64Pclass_3                   418 non-null float64Sex_1                      418 non-null float64Sex_2                      418 non-null float64Deck_1                     418 non-null float64Deck_2                     418 non-null float64Deck_3                     418 non-null float64Deck_4                     418 non-null float64Embarked_1                 418 non-null float64Embarked_2                 418 non-null float64Embarked_3                 418 non-null float64Title_1                    418 non-null float64Title_2                    418 non-null float64Title_3                    418 non-null float64Title_4                    418 non-null float64Family_Size_Grouped_1      418 non-null float64Family_Size_Grouped_2      418 non-null float64Family_Size_Grouped_3      418 non-null float64Family_Size_Grouped_4      418 non-null float64dtypes: float64(25), int64(16), object(3)memory usage: 143.8+ KBNone</code></pre><pre><code class="python"></code></pre><pre><code class="python">pandas_df_to_markdown_table(df_test.sample(3))</code></pre><table><thead><tr><th>Age</th><th>Deck</th><th>Embarked</th><th>Fare</th><th>Name</th><th>Parch</th><th>PassengerId</th><th>Pclass</th><th>Sex</th><th>SibSp</th><th>Survived</th><th>Ticket</th><th>Family_Size</th><th>Family_Size_Grouped</th><th>Ticket_Frequency</th><th>Title</th><th>Is_Married</th><th>Family</th><th>Family_Survival_Rate</th><th>Family_Survival_Rate_NA</th><th>Ticket_Survival_Rate</th><th>Ticket_Survival_Rate_NA</th><th>Survival_Rate</th><th>Survival_Rate_NA</th><th>Pclass_1</th><th>Pclass_2</th><th>Pclass_3</th><th>Sex_1</th><th>Sex_2</th><th>Deck_1</th><th>Deck_2</th><th>Deck_3</th><th>Deck_4</th><th>Embarked_1</th><th>Embarked_2</th><th>Embarked_3</th><th>Title_1</th><th>Title_2</th><th>Title_3</th><th>Title_4</th><th>Family_Size_Grouped_1</th><th>Family_Size_Grouped_2</th><th>Family_Size_Grouped_3</th><th>Family_Size_Grouped_4</th></tr></thead><tbody><tr><td>25</td><td>3</td><td>2</td><td>7</td><td>“Hocking, Miss. Ellen Nellie”””””</td><td>1</td><td>944</td><td>2</td><td>0</td><td>2</td><td></td><td>29105</td><td>4</td><td>3</td><td>2</td><td>2</td><td>0</td><td>Hocking</td><td>0.5</td><td>1</td><td>1.0</td><td>1</td><td>0.75</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><td>49</td><td>0</td><td>1</td><td>12</td><td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td><td>0</td><td>1303</td><td>1</td><td>0</td><td>1</td><td></td><td>19928</td><td>2</td><td>3</td><td>3</td><td>2</td><td>1</td><td>Minahan</td><td>0.5</td><td>1</td><td>0.5</td><td>1</td><td>0.5</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><td>74</td><td>3</td><td>1</td><td>5</td><td>Lingane, Mr. John</td><td>0</td><td>1085</td><td>2</td><td>1</td><td>0</td><td></td><td>235509</td><td>1</td><td>0</td><td>1</td><td>3</td><td>0</td><td>Lingane</td><td>0.3838383838383838</td><td>0</td><td>0.3838383838383838</td><td>0</td><td>0.3838383838383838</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table><h2 id="处理缺失的特征值"><a href="#处理缺失的特征值" class="headerlink" title="处理缺失的特征值"></a>处理缺失的特征值</h2><ul><li>训练数据 Age，Cabin，Embarked  有缺失的记录</li><li>测试数据 Age，Cabin，Fare 有缺失的记录</li></ul><p>Age，Embarked，Fare 空值记录相对较少，可以用一些统计数据替代，比如平均值，中位数等。而 Cabin 有80%的记录都是</p><pre><code class="python">def display_missing(df):    for col in df.columns.tolist():        print(&#39;{} column missing values: {}&#39;.format(col, df[col].isnull().sum()))    print(&#39;\n&#39;)</code></pre><pre><code class="python">dfs = [df_train, df_test]for df in dfs:    print(&#39;{}&#39;.format(df.name))    display_missing(df)</code></pre><pre><code>Training SetPassengerId column missing values: 0Survived column missing values: 0Pclass column missing values: 0Name column missing values: 0Sex column missing values: 0Age column missing values: 177SibSp column missing values: 0Parch column missing values: 0Ticket column missing values: 0Fare column missing values: 0Cabin column missing values: 687Embarked column missing values: 2</code></pre><p>​<br>​    Test Set<br>​    PassengerId column missing values: 0<br>​    Pclass column missing values: 0<br>​    Name column missing values: 0<br>​    Sex column missing values: 0<br>​    Age column missing values: 86<br>​    SibSp column missing values: 0<br>​    Parch column missing values: 0<br>​    Ticket column missing values: 0<br>​    Fare column missing values: 1<br>​    Cabin column missing values: 327<br>​    Embarked column missing values: 0</p><p>​    </p><h3 id="Age"><a href="#Age" class="headerlink" title="Age"></a>Age</h3><p>对于缺失的Age特征，我们很容易地想到可以用中位数来替代。但是仔细想想还有更好的方式，比如已知了Pclass（乘客等级），这个数据跟年龄很有相关性，我们可以根据Pclass来更好的填充Age。计算 Age 和 各个属性的相关性。</p><pre><code class="python">df_all_corr = df_all.corr().abs().unstack().sort_values(kind=&quot;quicksort&quot;, ascending=False).reset_index()df_all_corr.rename(columns={&quot;level_0&quot;: &quot;Feature 1&quot;, &quot;level_1&quot;: &quot;Feature 2&quot;, 0: &#39;Correlation Coefficient&#39;}, inplace=True)pandas_df_to_markdown_table(df_all_corr[df_all_corr[&#39;Feature 1&#39;] == &#39;Age&#39;])</code></pre><table><thead><tr><th>Feature 1</th><th>Feature 2</th><th>Correlation Coefficient</th></tr></thead><tbody><tr><td>Age</td><td>Age</td><td>1.0</td></tr><tr><td>Age</td><td>Pclass</td><td>0.40810623423644476</td></tr><tr><td>Age</td><td>SibSp</td><td>0.24369899766477038</td></tr><tr><td>Age</td><td>Fare</td><td>0.1787398559996414</td></tr><tr><td>Age</td><td>Parch</td><td>0.15091709036354348</td></tr><tr><td>Age</td><td>Survived</td><td>0.07722109457217737</td></tr><tr><td>Age</td><td>PassengerId</td><td>0.028814450421119325</td></tr></tbody></table><p>除了乘客等级和年龄有相关性，性别在各自c里的年龄表现也有所区分。</p><pre><code class="python">age_by_pclass_sex = df_all.groupby([&#39;Sex&#39;, &#39;Pclass&#39;]).median()[&#39;Age&#39;]for pclass in range(1, 4):    for sex in [&#39;female&#39;, &#39;male&#39;]:        print(&#39;Median age of Pclass {} {}s: {}&#39;.format(pclass, sex, age_by_pclass_sex[sex][pclass]))print(&#39;Median age of all passengers: {}&#39;.format(df_all[&#39;Age&#39;].median()))</code></pre><pre><code>Median age of Pclass 1 females: 36.0Median age of Pclass 1 males: 42.0Median age of Pclass 2 females: 28.0Median age of Pclass 2 males: 29.5Median age of Pclass 3 females: 22.0Median age of Pclass 3 males: 25.0Median age of all passengers: 28.0</code></pre><pre><code class="python"># 根据各乘客等级性别填充年龄df_all[&#39;Age&#39;] = df_all.groupby([&#39;Sex&#39;, &#39;Pclass&#39;])[&#39;Age&#39;].apply(lambda x: x.fillna(x.median()))</code></pre><h3 id="Embarked"><a href="#Embarked" class="headerlink" title="Embarked"></a>Embarked</h3><p>Embarked 有两条缺失数据，都是女性，上流，船票是相同</p><pre><code class="python">pandas_df_to_markdown_table(df_all[df_all[&#39;Embarked&#39;].isnull()])</code></pre><table><thead><tr><th>Age</th><th>Cabin</th><th>Embarked</th><th>Fare</th><th>Name</th><th>Parch</th><th>PassengerId</th><th>Pclass</th><th>Sex</th><th>SibSp</th><th>Survived</th><th>Ticket</th></tr></thead><tbody><tr><td>38.0</td><td>B28</td><td></td><td>80.0</td><td>Icard, Miss. Amelie</td><td>0</td><td>62</td><td>1</td><td>female</td><td>0</td><td>1.0</td><td>113572</td></tr><tr><td>62.0</td><td>B28</td><td></td><td>80.0</td><td>Stone, Mrs. George Nelson (Martha Evelyn)</td><td>0</td><td>830</td><td>1</td><td>female</td><td>0</td><td>1.0</td><td>113572</td></tr></tbody></table><p>通过Google搜索，知道Stone, Mrs. George Nelson (Martha Evelyn)女士是在 S (Southampton) 登船</p><pre><code class="python">df_all[&#39;Embarked&#39;] = df_all[&#39;Embarked&#39;].fillna(&#39;S&#39;)</code></pre><h3 id="Fare"><a href="#Fare" class="headerlink" title="Fare"></a>Fare</h3><p>Fare 只有一条数据是空的</p><pre><code class="python">pandas_df_to_markdown_table(df_all[df_all[&#39;Fare&#39;].isnull()])</code></pre><table><thead><tr><th>Age</th><th>Cabin</th><th>Embarked</th><th>Fare</th><th>Name</th><th>Parch</th><th>PassengerId</th><th>Pclass</th><th>Sex</th><th>SibSp</th><th>Survived</th><th>Ticket</th></tr></thead><tbody><tr><td>60.5</td><td></td><td>S</td><td></td><td>Storey, Mr. Thomas</td><td>0</td><td>1044</td><td>3</td><td>male</td><td>0</td><td></td><td>3701</td></tr></tbody></table><pre><code class="python">med_fare = df_all.groupby([&#39;Pclass&#39;, &#39;Parch&#39;, &#39;SibSp&#39;]).Fare.median()[3][0][0]df_all[&#39;Fare&#39;] = df_all[&#39;Fare&#39;].fillna(med_fare)</code></pre><h3 id="Cabin"><a href="#Cabin" class="headerlink" title="Cabin"></a>Cabin</h3><p>Cabin 缺失最多却不能忽视，因为船舱的位置极有可能影响乘客逃生。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733" alt="船舱示意图" title>                </div>                <div class="image-caption">船舱示意图</div>            </figure><pre><code class="python"># 添加数据列甲板，M标示缺失df_all[&#39;Deck&#39;] = df_all[&#39;Cabin&#39;].apply(lambda s: s[0] if pd.notnull(s) else &#39;M&#39;)df_all_decks = df_all.groupby([&#39;Deck&#39;, &#39;Pclass&#39;]).count(). \    drop(columns=[&#39;Survived&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;, &#39;Cabin&#39;, &#39;PassengerId&#39;, &#39;Ticket&#39;]). \    rename(columns={&#39;Name&#39;: &#39;Count&#39;}).transpose()pandas_df_to_markdown_table(df_all_decks)</code></pre><p>A|B|C|D|D|E|E|E|F|F|G|M|M|M|T<br>1|1|1|1|2|1|2|3|2|3|3|1|2|3|1<br>—|—|—|—|—|—|—|—|—|—|—|—|—|—|—<br>22|65|94|40|6|34|4|3|13|8|5|67|254|693|1</p><pre><code class="python">def get_pclass_dist(df):    # Creating a dictionary for every passenger class count in every deck    deck_counts = {&#39;A&#39;: {}, &#39;B&#39;: {}, &#39;C&#39;: {}, &#39;D&#39;: {}, &#39;E&#39;: {}, &#39;F&#39;: {}, &#39;G&#39;: {}, &#39;M&#39;: {}, &#39;T&#39;: {}}    decks = df.columns.levels[0]    for deck in decks:        for pclass in range(1, 4):            try:                count = df[deck][pclass][0]                deck_counts[deck][pclass] = count            except KeyError:                deck_counts[deck][pclass] = 0    df_decks = pd.DataFrame(deck_counts)    deck_percentages = {}    # Creating a dictionary for every passenger class percentage in every deck    for col in df_decks.columns:        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]    return deck_counts, deck_percentagesdef display_pclass_dist(percentages):    df_percentages = pd.DataFrame(percentages).transpose()    deck_names = (&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;M&#39;, &#39;T&#39;)    bar_count = np.arange(len(deck_names))    bar_width = 0.85    pclass1 = df_percentages[0]    pclass2 = df_percentages[1]    pclass3 = df_percentages[2]    plt.figure(figsize=(20, 10))    plt.bar(bar_count, pclass1, color=&#39;#b5ffb9&#39;, edgecolor=&#39;white&#39;, width=bar_width, label=&#39;Passenger Class 1&#39;)    plt.bar(bar_count, pclass2, bottom=pclass1, color=&#39;#f9bc86&#39;, edgecolor=&#39;white&#39;, width=bar_width,            label=&#39;Passenger Class 2&#39;)    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color=&#39;#a3acff&#39;, edgecolor=&#39;white&#39;, width=bar_width,            label=&#39;Passenger Class 3&#39;)    plt.xlabel(&#39;Deck&#39;, size=15, labelpad=20)    plt.ylabel(&#39;Passenger Class Percentage&#39;, size=15, labelpad=20)    plt.xticks(bar_count, deck_names)    plt.tick_params(axis=&#39;x&#39;, labelsize=15)    plt.tick_params(axis=&#39;y&#39;, labelsize=15)    plt.legend(loc=&#39;upper left&#39;, bbox_to_anchor=(1, 1), prop={&#39;size&#39;: 15})    plt.title(&#39;Passenger Class Distribution in Decks&#39;, size=18, y=1.05)    plt.show()all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)display_pclass_dist(all_deck_per)</code></pre><p><img src="/2019/06/22/titanic_advanced/output_38_0.png" alt="png"></p><pre><code class="python">pandas_df_to_markdown_table(df_all[df_all[&#39;Deck&#39;] == &#39;T&#39;])</code></pre><table><thead><tr><th>Age</th><th>Cabin</th><th>Embarked</th><th>Fare</th><th>Name</th><th>Parch</th><th>PassengerId</th><th>Pclass</th><th>Sex</th><th>SibSp</th><th>Survived</th><th>Ticket</th><th>Deck</th></tr></thead><tbody><tr><td>45.0</td><td>T</td><td>S</td><td>35.5</td><td>Blackwell, Mr. Stephen Weart</td><td>0</td><td>340</td><td>1</td><td>male</td><td>0</td><td>0.0</td><td>113784</td><td>T</td></tr></tbody></table><pre><code class="python"># T甲板只有一个乘客，且这个乘客是高级船舱的，是异常数据，将这个乘客归到A甲板idx = df_all[df_all[&#39;Deck&#39;] == &#39;T&#39;].indexdf_all.loc[idx, &#39;Deck&#39;] = &#39;A&#39;</code></pre><pre><code class="python">df_all_decks_survived = df_all.groupby([&#39;Deck&#39;, &#39;Survived&#39;]).count() \    .drop(columns=[&#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;, &#39;Pclass&#39;, &#39;Cabin&#39;, &#39;PassengerId&#39;, &#39;Ticket&#39;]) \    .rename(columns={&#39;Name&#39;: &#39;Count&#39;}).transpose()df_all_decks_surviveddef get_survived_dist(df):    # Creating a dictionary for every survival count in every deck    surv_counts = {&#39;A&#39;: {}, &#39;B&#39;: {}, &#39;C&#39;: {}, &#39;D&#39;: {}, &#39;E&#39;: {}, &#39;F&#39;: {}, &#39;G&#39;: {}, &#39;M&#39;: {}}    decks = df.columns.levels[0]    for deck in decks:        for survive in range(0, 2):            surv_counts[deck][survive] = df[deck][survive][0]    df_surv = pd.DataFrame(surv_counts)    surv_percentages = {}    for col in df_surv.columns:        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]    return surv_counts, surv_percentagesdef display_surv_dist(percentages):    df_survived_percentages = pd.DataFrame(percentages).transpose()    deck_names = (&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;M&#39;)    bar_count = np.arange(len(deck_names))    bar_width = 0.85    not_survived = df_survived_percentages[0]    survived = df_survived_percentages[1]    plt.figure(figsize=(20, 10))    plt.bar(bar_count, not_survived, color=&#39;#b5ffb9&#39;, edgecolor=&#39;white&#39;, width=bar_width, label=&quot;Not Survived&quot;)    plt.bar(bar_count, survived, bottom=not_survived, color=&#39;#f9bc86&#39;, edgecolor=&#39;white&#39;, width=bar_width,            label=&quot;Survived&quot;)    plt.xlabel(&#39;Deck&#39;, size=15, labelpad=20)    plt.ylabel(&#39;Survival Percentage&#39;, size=15, labelpad=20)    plt.xticks(bar_count, deck_names)    plt.tick_params(axis=&#39;x&#39;, labelsize=15)    plt.tick_params(axis=&#39;y&#39;, labelsize=15)    plt.legend(loc=&#39;upper left&#39;, bbox_to_anchor=(1, 1), prop={&#39;size&#39;: 15})    plt.title(&#39;Survival Percentage in Decks&#39;, size=18, y=1.05)    plt.show()all_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)display_surv_dist(all_surv_per)</code></pre><p><img src="/2019/06/22/titanic_advanced/output_41_0.png" alt="png"></p><p>如同所预料的，每个甲板（船舱）都有不同的生存几率，这个信息不能被简单的丢弃。<br>B，C，D，E 有最高的生还率，这些船舱主要由高等级乘客组成。结论就是高等级的乘客比中级乘客和普通乘客有更高的生还率。<br>我认为，M甲板（缺失船舱数据）生存率最低因为无法死者很有可能无法获得确切的信息。<br>甲板这个属性是高数量类别特征（Deck feature has high-cardinality  ），可以根据相似度进行分类：</p><ul><li>A，B，C 归类为ABC，因为他们都是高级乘客</li><li>D，E 归类为DE 因为他们有相似的乘客分布</li><li>F，G 归类为FG，原因同上</li><li>M 自成一类，因为他蕴含了不同的信息</li></ul><pre><code class="python">df_all[&#39;Deck&#39;] = df_all[&#39;Deck&#39;].replace([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;], &#39;ABC&#39;)df_all[&#39;Deck&#39;] = df_all[&#39;Deck&#39;].replace([&#39;D&#39;, &#39;E&#39;], &#39;DE&#39;)df_all[&#39;Deck&#39;] = df_all[&#39;Deck&#39;].replace([&#39;F&#39;, &#39;G&#39;], &#39;FG&#39;)df_all[&#39;Deck&#39;].value_counts()</code></pre><pre><code>M      1014ABC     182DE       87FG       26Name: Deck, dtype: int64</code></pre><p>cabin 属性可以丢弃了</p><pre><code class="python">df_all.drop([&#39;Cabin&#39;], inplace=True, axis=1)df_train, df_test = divide_df(df_all)dfs = [df_train, df_test]for df in dfs:    display_missing(df)</code></pre><pre><code>Age column missing values: 0Embarked column missing values: 0Fare column missing values: 0Name column missing values: 0Parch column missing values: 0PassengerId column missing values: 0Pclass column missing values: 0Sex column missing values: 0SibSp column missing values: 0Survived column missing values: 0Ticket column missing values: 0Deck column missing values: 0</code></pre><p>​<br>​    Age column missing values: 0<br>​    Embarked column missing values: 0<br>​    Fare column missing values: 0<br>​    Name column missing values: 0<br>​    Parch column missing values: 0<br>​    PassengerId column missing values: 0<br>​    Pclass column missing values: 0<br>​    Sex column missing values: 0<br>​    SibSp column missing values: 0<br>​    Ticket column missing values: 0<br>​    Deck column missing values: 0</p><p>​    </p><pre><code class="python">survived = df_train[&#39;Survived&#39;].value_counts()[1]not_survived = df_train[&#39;Survived&#39;].value_counts()[0]survived_per = survived / df_train.shape[0] * 100not_survived_per = not_survived / df_train.shape[0] * 100print(&#39;{} of {} passengers survived and it is the {:.2f}% of the training set.&#39;.format(survived, df_train.shape[0],                                                                                       survived_per))print(&#39;{} of {} passengers didnt survive and it is the {:.2f}% of the training set.&#39;.format(not_survived,                                                                                            df_train.shape[0],                                                                                            not_survived_per))plt.figure(figsize=(10, 8))sns.countplot(df_train[&#39;Survived&#39;])plt.xlabel(&#39;Survival&#39;, size=15, labelpad=15)plt.ylabel(&#39;Passenger Count&#39;, size=15, labelpad=15)plt.xticks((0, 1), [&#39;Not Survived ({0:.2f}%)&#39;.format(not_survived_per), &#39;Survived ({0:.2f}%)&#39;.format(survived_per)])plt.tick_params(axis=&#39;x&#39;, labelsize=13)plt.tick_params(axis=&#39;y&#39;, labelsize=13)plt.title(&#39;Training Set Survival Distribution&#39;, size=15, y=1.05)plt.show()</code></pre><pre><code>342 of 891 passengers survived and it is the 38.38% of the training set.549 of 891 passengers didnt survive and it is the 61.62% of the training set.</code></pre><p><img src="/2019/06/22/titanic_advanced/output_46_1.png" alt="png"></p><h3 id="数据相关性"><a href="#数据相关性" class="headerlink" title="数据相关性"></a>数据相关性</h3><pre><code class="python">df_train_corr = df_train.drop([&#39;PassengerId&#39;], axis=1).corr().abs().unstack().sort_values(kind=&quot;quicksort&quot;,                                                                                          ascending=False).reset_index()df_train_corr.rename(columns={&quot;level_0&quot;: &quot;Feature 1&quot;, &quot;level_1&quot;: &quot;Feature 2&quot;, 0: &#39;Correlation Coefficient&#39;},                     inplace=True)df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr[&#39;Correlation Coefficient&#39;] == 1.0].index)df_test_corr = df_test.corr().abs().unstack().sort_values(kind=&quot;quicksort&quot;, ascending=False).reset_index()df_test_corr.rename(columns={&quot;level_0&quot;: &quot;Feature 1&quot;, &quot;level_1&quot;: &quot;Feature 2&quot;, 0: &#39;Correlation Coefficient&#39;},                    inplace=True)df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr[&#39;Correlation Coefficient&#39;] == 1.0].index)# Training set high correlationscorr = df_train_corr_nd[&#39;Correlation Coefficient&#39;] &gt; 0.1pandas_df_to_markdown_table(df_train_corr_nd[corr])</code></pre><table><thead><tr><th>Feature 1</th><th>Feature 2</th><th>Correlation Coefficient</th></tr></thead><tbody><tr><td>Pclass</td><td>Fare</td><td>0.5494996199439061</td></tr><tr><td>Pclass</td><td>Age</td><td>0.41766723369886644</td></tr><tr><td>SibSp</td><td>Parch</td><td>0.41483769862015263</td></tr><tr><td>Survived</td><td>Pclass</td><td>0.33848103596101586</td></tr><tr><td>Survived</td><td>Fare</td><td>0.2573065223849618</td></tr><tr><td>SibSp</td><td>Age</td><td>0.24974662870955514</td></tr><tr><td>Parch</td><td>Fare</td><td>0.21622494477076254</td></tr><tr><td>Age</td><td>Parch</td><td>0.17673256218946698</td></tr><tr><td>SibSp</td><td>Fare</td><td>0.15965104324216103</td></tr><tr><td>Age</td><td>Fare</td><td>0.12406104601800909</td></tr></tbody></table><pre><code class="python"># Test set high correlationscorr = df_test_corr_nd[&#39;Correlation Coefficient&#39;] &gt; 0.1pandas_df_to_markdown_table(df_test_corr_nd[corr])</code></pre><table><thead><tr><th>Feature 1</th><th>Feature 2</th><th>Correlation Coefficient</th></tr></thead><tbody><tr><td>Fare</td><td>Pclass</td><td>0.5774887948232105</td></tr><tr><td>Age</td><td>Pclass</td><td>0.5267887447504006</td></tr><tr><td>Age</td><td>Fare</td><td>0.3453471879464391</td></tr><tr><td>SibSp</td><td>Parch</td><td>0.30689461547590147</td></tr><tr><td>Fare</td><td>Parch</td><td>0.2304099972191158</td></tr><tr><td>SibSp</td><td>Fare</td><td>0.17203193101051656</td></tr></tbody></table><pre><code class="python">fig, axs = plt.subplots(nrows=2, figsize=(20, 20))sns.heatmap(df_train.drop([&#39;PassengerId&#39;], axis=1).corr(), ax=axs[0], annot=True, square=True, cmap=&#39;coolwarm&#39;,            annot_kws={&#39;size&#39;: 14})sns.heatmap(df_test.drop([&#39;PassengerId&#39;], axis=1).corr(), ax=axs[1], annot=True, square=True, cmap=&#39;coolwarm&#39;,            annot_kws={&#39;size&#39;: 14})for i in range(2):    axs[i].tick_params(axis=&#39;x&#39;, labelsize=14)    axs[i].tick_params(axis=&#39;y&#39;, labelsize=14)axs[0].set_title(&#39;Training Set Correlations&#39;, size=15)axs[1].set_title(&#39;Test Set Correlations&#39;, size=15)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_50_0.png" alt="png"></p><h3 id="各个特征的生存分布"><a href="#各个特征的生存分布" class="headerlink" title="各个特征的生存分布"></a>各个特征的生存分布</h3><h4 id="连续型特征"><a href="#连续型特征" class="headerlink" title="连续型特征"></a>连续型特征</h4><ul><li>两个特征都有明显的分割点和尖峰，这有利于决策树算法</li><li>低于十五岁的乘客有更高的生存率</li><li>船费特征中，生存率在分布末段更高</li></ul><pre><code class="python">cont_features = [&#39;Age&#39;, &#39;Fare&#39;]surv = df_train[&#39;Survived&#39;] == 1fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))plt.subplots_adjust(right=1.5)for i, feature in enumerate(cont_features):    # Distribution of survival in feature    sns.distplot(df_train[~surv][feature], label=&#39;Not Survived&#39;, hist=True, color=&#39;#e74c3c&#39;, ax=axs[0][i])    sns.distplot(df_train[surv][feature], label=&#39;Survived&#39;, hist=True, color=&#39;#2ecc71&#39;, ax=axs[0][i])    # Distribution of feature in dataset    sns.distplot(df_train[feature], label=&#39;Training Set&#39;, hist=False, color=&#39;#e74c3c&#39;, ax=axs[1][i])    sns.distplot(df_test[feature], label=&#39;Test Set&#39;, hist=False, color=&#39;#2ecc71&#39;, ax=axs[1][i])    axs[0][i].set_xlabel(&#39;&#39;)    axs[1][i].set_xlabel(&#39;&#39;)    for j in range(2):        axs[i][j].tick_params(axis=&#39;x&#39;, labelsize=20)        axs[i][j].tick_params(axis=&#39;y&#39;, labelsize=20)    axs[0][i].legend(loc=&#39;upper right&#39;, prop={&#39;size&#39;: 20})    axs[1][i].legend(loc=&#39;upper right&#39;, prop={&#39;size&#39;: 20})    axs[0][i].set_title(&#39;Distribution of Survival in {}&#39;.format(feature), size=20, y=1.05)axs[1][0].set_title(&#39;Distribution of {} Feature&#39;.format(&#39;Age&#39;), size=20, y=1.05)axs[1][1].set_title(&#39;Distribution of {} Feature&#39;.format(&#39;Fare&#39;), size=20, y=1.05)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_53_0.png" alt="png"></p><h3 id="离散型特征"><a href="#离散型特征" class="headerlink" title="离散型特征"></a>离散型特征</h3><ul><li>每一个离散型特征都有一个类别有比较低的死亡率，这有助于判断是否生还</li><li>从S登船的乘客生还率比较低，而从C登船的乘客有超过一半都生还了，这可能和Pclass有关</li><li>Parch和SibSp 表明只有一个家庭成员的乘客有更高的生还率</li><li>最佳的分类特征是Pclass和Sex，因为他们是最同质的分类（没搞懂）</li></ul><pre><code class="python">cat_features = [&#39;Embarked&#39;, &#39;Parch&#39;, &#39;Pclass&#39;, &#39;Sex&#39;, &#39;SibSp&#39;, &#39;Deck&#39;]fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))plt.subplots_adjust(right=1.5, top=1.25)for i, feature in enumerate(cat_features, 1):    plt.subplot(2, 3, i)    sns.countplot(x=feature, hue=&#39;Survived&#39;, data=df_train)    plt.xlabel(&#39;{}&#39;.format(feature), size=20, labelpad=15)    plt.ylabel(&#39;Passenger Count&#39;, size=20, labelpad=15)    plt.tick_params(axis=&#39;x&#39;, labelsize=20)    plt.tick_params(axis=&#39;y&#39;, labelsize=20)    plt.legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper center&#39;, prop={&#39;size&#39;: 18})    plt.title(&#39;Count of Survival in {} Feature&#39;.format(feature), size=20, y=1.05)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_55_0.png" alt="png"></p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><ul><li>大部分的特征都互相关联。这种关联可以用来创造新的特征</li><li>连续型特征分布的分割点和尖峰很明显，不幸的是只有两个连续型特征。这些信息能够被决策树算法很好的捕捉到，但神经网络可能不行。</li><li>离散型特征中各个分类有着明显不同的生还率。这些类别可以用来进行 One-hot encoding（独热编码）。某些还可以用来结合其他类别，构造新的特征。</li><li>新加了Deck特征，去除了Cabin特征</li></ul><pre><code class="python">df_all = concat_df(df_train, df_test)pandas_df_to_markdown_table(df_all.head())</code></pre><table><thead><tr><th>Age</th><th>Deck</th><th>Embarked</th><th>Fare</th><th>Name</th><th>Parch</th><th>PassengerId</th><th>Pclass</th><th>Sex</th><th>SibSp</th><th>Survived</th><th>Ticket</th></tr></thead><tbody><tr><td>22.0</td><td>M</td><td>S</td><td>7.25</td><td>Braund, Mr. Owen Harris</td><td>0</td><td>1</td><td>3</td><td>male</td><td>1</td><td>0.0</td><td>A/5 21171</td></tr><tr><td>38.0</td><td>ABC</td><td>C</td><td>71.2833</td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>0</td><td>2</td><td>1</td><td>female</td><td>1</td><td>1.0</td><td>PC 17599</td></tr><tr><td>26.0</td><td>M</td><td>S</td><td>7.925</td><td>Heikkinen, Miss. Laina</td><td>0</td><td>3</td><td>3</td><td>female</td><td>0</td><td>1.0</td><td>STON/O2. 3101282</td></tr><tr><td>35.0</td><td>ABC</td><td>S</td><td>53.1</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>0</td><td>4</td><td>1</td><td>female</td><td>1</td><td>1.0</td><td>113803</td></tr><tr><td>35.0</td><td>M</td><td>S</td><td>8.05</td><td>Allen, Mr. William Henry</td><td>0</td><td>5</td><td>3</td><td>male</td><td>0</td><td>0.0</td><td>373450</td></tr></tbody></table><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="连续型特征-1"><a href="#连续型特征-1" class="headerlink" title="连续型特征"></a>连续型特征</h3><h4 id="Fare-1"><a href="#Fare-1" class="headerlink" title="Fare"></a>Fare</h4><ul><li>Fare 特征是正偏态分布， 并且生存率在分布右端特别高</li><li>Fare 柱状图中分为13组，即使有些数量不是很多，但是也能提供可观的信息增益</li><li>分布图左端的死亡率高于右端，这是在分布图中看不到的信息</li><li>区间 (15.742, 23.25] 的组有异常高的生存率</li></ul><pre><code class="python">df_all[&#39;Fare&#39;] = pd.qcut(df_all[&#39;Fare&#39;], 13)fig, axs = plt.subplots(figsize=(22, 9))sns.countplot(x=&#39;Fare&#39;, hue=&#39;Survived&#39;, data=df_all)plt.xlabel(&#39;Fare&#39;, size=15, labelpad=20)plt.ylabel(&#39;Passenger Count&#39;, size=15, labelpad=20)plt.tick_params(axis=&#39;x&#39;, labelsize=10)plt.tick_params(axis=&#39;y&#39;, labelsize=15)plt.legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper right&#39;, prop={&#39;size&#39;: 15})plt.title(&#39;Count of Survival in {} Feature&#39;.format(&#39;Fare&#39;), size=15, y=1.05)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_61_0.png" alt="png"></p><h4 id="家庭成员数量"><a href="#家庭成员数量" class="headerlink" title="家庭成员数量"></a>家庭成员数量</h4><ul><li>Family_Size = SibSp + Parch +1</li><li>Family_Size = 1 标记为 Alone</li><li>Family_Size = 2,3,4 标记为 Small</li><li>Family_Size = 5,6 标记为 Medium</li><li>Family_Size = 7,8,11 标记为 Large</li></ul><pre><code class="python">df_all[&#39;Family_Size&#39;] = df_all[&#39;SibSp&#39;] + df_all[&#39;Parch&#39;] + 1fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)plt.subplots_adjust(right=1.5)sns.barplot(x=df_all[&#39;Family_Size&#39;].value_counts().index, y=df_all[&#39;Family_Size&#39;].value_counts().values, ax=axs[0][0])sns.countplot(x=&#39;Family_Size&#39;, hue=&#39;Survived&#39;, data=df_all, ax=axs[0][1])axs[0][0].set_title(&#39;Family Size Feature Value Counts&#39;, size=20, y=1.05)axs[0][1].set_title(&#39;Survival Counts in Family Size &#39;, size=20, y=1.05)family_map = {1: &#39;Alone&#39;, 2: &#39;Small&#39;, 3: &#39;Small&#39;, 4: &#39;Small&#39;, 5: &#39;Medium&#39;, 6: &#39;Medium&#39;, 7: &#39;Large&#39;, 8: &#39;Large&#39;,              11: &#39;Large&#39;}df_all[&#39;Family_Size_Grouped&#39;] = df_all[&#39;Family_Size&#39;].map(family_map)sns.barplot(x=df_all[&#39;Family_Size_Grouped&#39;].value_counts().index, y=df_all[&#39;Family_Size_Grouped&#39;].value_counts().values,            ax=axs[1][0])sns.countplot(x=&#39;Family_Size_Grouped&#39;, hue=&#39;Survived&#39;, data=df_all, ax=axs[1][1])axs[1][0].set_title(&#39;Family Size Feature Value Counts After Grouping&#39;, size=20, y=1.05)axs[1][1].set_title(&#39;Survival Counts in Family Size After Grouping&#39;, size=20, y=1.05)for i in range(2):    axs[i][1].legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper right&#39;, prop={&#39;size&#39;: 20})    for j in range(2):        axs[i][j].tick_params(axis=&#39;x&#39;, labelsize=20)        axs[i][j].tick_params(axis=&#39;y&#39;, labelsize=20)        axs[i][j].set_xlabel(&#39;&#39;)        axs[i][j].set_ylabel(&#39;&#39;)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_63_0.png" alt="png"></p><h4 id="船票频率"><a href="#船票频率" class="headerlink" title="船票频率"></a>船票频率</h4><ul><li>这个和Family_Size是不一样的， 除了同一个家庭会使用相同的票，结伴出行的朋友也会使用相同的票</li><li>可不可以将tickets 按船票的前缀分组？如果船票的特征有什么有用的信息，那么这些信息已经被Pclass 和 Embarked 包含了</li><li>船票频率分布和Family_size分布很像</li><li>船票频率不需要像Family_size那样分组，因为相似性太高了。这样的特征不会提供任何有用的信息</li></ul><pre><code class="python">df_all[&#39;Ticket_Frequency&#39;] = df_all.groupby(&#39;Ticket&#39;)[&#39;Ticket&#39;].transform(&#39;count&#39;)fig, axs = plt.subplots(figsize=(12, 9))sns.countplot(x=&#39;Ticket_Frequency&#39;, hue=&#39;Survived&#39;, data=df_all)plt.xlabel(&#39;Ticket Frequency&#39;, size=15, labelpad=20)plt.ylabel(&#39;Passenger Count&#39;, size=15, labelpad=20)plt.tick_params(axis=&#39;x&#39;, labelsize=15)plt.tick_params(axis=&#39;y&#39;, labelsize=15)plt.legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper right&#39;, prop={&#39;size&#39;: 15})plt.title(&#39;Count of Survival in {} Feature&#39;.format(&#39;Ticket Frequency&#39;), size=15, y=1.05)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_65_0.png" alt="png"></p><h4 id="称谓和婚姻状况"><a href="#称谓和婚姻状况" class="headerlink" title="称谓和婚姻状况"></a>称谓和婚姻状况</h4><ul><li>Title 是 从 Name 属性的前缀截取而来</li><li>Is_Married 根据 Title 中是否包含 Mrs 得来。</li></ul><pre><code class="python">df_all[&#39;Title&#39;] = df_all[&#39;Name&#39;].str.split(&#39;, &#39;, expand=True)[1].str.split(&#39;.&#39;, expand=True)[0]df_all[&#39;Is_Married&#39;] = 0df_all[&#39;Is_Married&#39;].loc[df_all[&#39;Title&#39;] == &#39;Mrs&#39;] = 1fig, axs = plt.subplots(nrows=2, figsize=(20, 20))sns.barplot(x=df_all[&#39;Title&#39;].value_counts().index, y=df_all[&#39;Title&#39;].value_counts().values, ax=axs[0])axs[0].tick_params(axis=&#39;x&#39;, labelsize=10)axs[1].tick_params(axis=&#39;x&#39;, labelsize=15)for i in range(2):    axs[i].tick_params(axis=&#39;y&#39;, labelsize=15)axs[0].set_title(&#39;Title Feature Value Counts&#39;, size=20, y=1.05)df_all[&#39;Title&#39;] = df_all[&#39;Title&#39;].replace([&#39;Miss&#39;, &#39;Mrs&#39;, &#39;Ms&#39;, &#39;Mlle&#39;, &#39;Lady&#39;, &#39;Mme&#39;, &#39;the Countess&#39;, &#39;Dona&#39;],                                          &#39;Miss/Mrs/Ms&#39;)df_all[&#39;Title&#39;] = df_all[&#39;Title&#39;].replace([&#39;Dr&#39;, &#39;Col&#39;, &#39;Major&#39;, &#39;Jonkheer&#39;, &#39;Capt&#39;, &#39;Sir&#39;, &#39;Don&#39;, &#39;Rev&#39;],                                          &#39;Dr/Military/Noble/Clergy&#39;)sns.barplot(x=df_all[&#39;Title&#39;].value_counts().index, y=df_all[&#39;Title&#39;].value_counts().values, ax=axs[1])axs[1].set_title(&#39;Title Feature Value Counts After Grouping&#39;, size=20, y=1.05)plt.show()</code></pre><p><img src="/2019/06/22/titanic_advanced/output_67_0.png" alt="png"></p><h4 id="生还率"><a href="#生还率" class="headerlink" title="生还率"></a>生还率</h4><ul><li>Family_Survival_Rate: 家庭生还率</li><li>Ticket_Survival_Rate: 同票生还率</li><li>Survival_Rate =(Family_Survival_Rate + Ticket_Survival_Rate )/ 2</li></ul><pre><code class="python">def extract_surname(data):    # 提取乘客姓氏，用来对家庭分组    families = []    for i in range(len(data)):        name = data.iloc[i]        if &#39;(&#39; in name:            name_no_bracket = name.split(&#39;(&#39;)[0]        else:            name_no_bracket = name        family = name_no_bracket.split(&#39;,&#39;)[0]        title = name_no_bracket.split(&#39;,&#39;)[1].strip().split(&#39; &#39;)[0]        for c in string.punctuation:            family = family.replace(c, &#39;&#39;).strip()        families.append(family)    return families</code></pre><pre><code class="python">df_all[&#39;Family&#39;] = extract_surname(df_all[&#39;Name&#39;])df_train = df_all.loc[:890]df_test = df_all.loc[891:]dfs = [df_train, df_test]</code></pre><pre><code class="python"># Creating a list of families and tickets that are occuring in both training and test setnon_unique_families = [x for x in df_train[&#39;Family&#39;].unique() if x in df_test[&#39;Family&#39;].unique()]non_unique_tickets = [x for x in df_train[&#39;Ticket&#39;].unique() if x in df_test[&#39;Ticket&#39;].unique()]</code></pre><pre><code class="python">df_family_survival_rate = df_train.groupby(&#39;Family&#39;)[&#39;Survived&#39;, &#39;Family&#39;, &#39;Family_Size&#39;].median()df_ticket_survival_rate = df_train.groupby(&#39;Ticket&#39;)[&#39;Survived&#39;, &#39;Ticket&#39;, &#39;Ticket_Frequency&#39;].median()</code></pre><pre><code class="python">family_rates = {}ticket_rates = {}</code></pre><pre><code class="python">for i in range(len(df_family_survival_rate)):    # Checking a family exists in both training and test set, and has members more than 1    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] &gt; 1:        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]</code></pre><pre><code class="python">for i in range(len(df_ticket_survival_rate)):    # Checking a ticket exists in both training and test set, and has members more than 1    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] &gt; 1:        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]</code></pre><pre><code class="python">mean_survival_rate = np.mean(df_train[&#39;Survived&#39;])</code></pre><pre><code class="python">train_family_survival_rate = []train_family_survival_rate_NA = []test_family_survival_rate = []test_family_survival_rate_NA = []</code></pre><pre><code class="python">for i in range(len(df_train)):    if df_train[&#39;Family&#39;][i] in family_rates:        train_family_survival_rate.append(family_rates[df_train[&#39;Family&#39;][i]])        train_family_survival_rate_NA.append(1)    else:        train_family_survival_rate.append(mean_survival_rate)        train_family_survival_rate_NA.append(0)</code></pre><pre><code class="python">for i in range(len(df_test)):    if df_test[&#39;Family&#39;].iloc[i] in family_rates:        test_family_survival_rate.append(family_rates[df_test[&#39;Family&#39;].iloc[i]])        test_family_survival_rate_NA.append(1)    else:        test_family_survival_rate.append(mean_survival_rate)        test_family_survival_rate_NA.append(0)</code></pre><pre><code class="python">df_train[&#39;Family_Survival_Rate&#39;] = train_family_survival_ratedf_train[&#39;Family_Survival_Rate_NA&#39;] = train_family_survival_rate_NAdf_test[&#39;Family_Survival_Rate&#39;] = test_family_survival_ratedf_test[&#39;Family_Survival_Rate_NA&#39;] = test_family_survival_rate_NA</code></pre><pre><code class="python">train_ticket_survival_rate = []train_ticket_survival_rate_NA = []test_ticket_survival_rate = []test_ticket_survival_rate_NA = []</code></pre><pre><code class="python">for i in range(len(df_train)):    if df_train[&#39;Ticket&#39;][i] in ticket_rates:        train_ticket_survival_rate.append(ticket_rates[df_train[&#39;Ticket&#39;][i]])        train_ticket_survival_rate_NA.append(1)    else:        train_ticket_survival_rate.append(mean_survival_rate)        train_ticket_survival_rate_NA.append(0)</code></pre><pre><code class="python">for i in range(len(df_test)):    if df_test[&#39;Ticket&#39;].iloc[i] in ticket_rates:        test_ticket_survival_rate.append(ticket_rates[df_test[&#39;Ticket&#39;].iloc[i]])        test_ticket_survival_rate_NA.append(1)    else:        test_ticket_survival_rate.append(mean_survival_rate)        test_ticket_survival_rate_NA.append(0)</code></pre><pre><code class="python">df_train[&#39;Ticket_Survival_Rate&#39;] = train_ticket_survival_ratedf_train[&#39;Ticket_Survival_Rate_NA&#39;] = train_ticket_survival_rate_NAdf_test[&#39;Ticket_Survival_Rate&#39;] = test_ticket_survival_ratedf_test[&#39;Ticket_Survival_Rate_NA&#39;] = test_ticket_survival_rate_NA</code></pre><pre><code class="python">for df in [df_train, df_test]:    df[&#39;Survival_Rate&#39;] = (df[&#39;Ticket_Survival_Rate&#39;] + df[&#39;Family_Survival_Rate&#39;]) / 2    df[&#39;Survival_Rate_NA&#39;] = (df[&#39;Ticket_Survival_Rate_NA&#39;] + df[&#39;Family_Survival_Rate_NA&#39;]) / 2</code></pre><h4 id="Frature-Transformation"><a href="#Frature-Transformation" class="headerlink" title="Frature Transformation"></a>Frature Transformation</h4><h5 id="标签编码（Label-Encoding）"><a href="#标签编码（Label-Encoding）" class="headerlink" title="标签编码（Label Encoding）"></a>标签编码（Label Encoding）</h5><p>将类型编码为0,1,…,n</p><pre><code class="python">non_numeric_features = [&#39;Embarked&#39;, &#39;Sex&#39;, &#39;Deck&#39;, &#39;Title&#39;, &#39;Family_Size_Grouped&#39;, &#39;Age&#39;, &#39;Fare&#39;]for df in dfs:    for feature in non_numeric_features:        df[feature] = LabelEncoder().fit_transform(df[feature])</code></pre><h5 id="独热编码（One-Hot-Encoding）"><a href="#独热编码（One-Hot-Encoding）" class="headerlink" title="独热编码（One-Hot Encoding）"></a>独热编码（One-Hot Encoding）</h5><pre><code class="python">cat_features = [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Deck&#39;, &#39;Embarked&#39;, &#39;Title&#39;, &#39;Family_Size_Grouped&#39;]encoded_features = []for df in dfs:    for feature in cat_features:        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()        n = df[feature].nunique()        cols = [&#39;{}_{}&#39;.format(feature, n) for n in range(1, n + 1)]        encoded_df = pd.DataFrame(encoded_feat, columns=cols)        encoded_df.index = df.index        encoded_features.append(encoded_df)df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)</code></pre><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><pre><code class="python">df_all = concat_df(df_train, df_test)drop_cols = [&#39;Deck&#39;, &#39;Embarked&#39;, &#39;Family&#39;, &#39;Family_Size&#39;, &#39;Family_Size_Grouped&#39;, &#39;Survived&#39;,             &#39;Name&#39;, &#39;Parch&#39;, &#39;PassengerId&#39;, &#39;Pclass&#39;, &#39;Sex&#39;, &#39;SibSp&#39;, &#39;Ticket&#39;, &#39;Title&#39;,             &#39;Ticket_Survival_Rate&#39;, &#39;Family_Survival_Rate&#39;, &#39;Ticket_Survival_Rate_NA&#39;, &#39;Family_Survival_Rate_NA&#39;]df_all.drop(columns=drop_cols, inplace=True)pandas_df_to_markdown_table(df_all.head())</code></pre><table><thead><tr><th>Age</th><th>Deck_1</th><th>Deck_2</th><th>Deck_3</th><th>Deck_4</th><th>Embarked_1</th><th>Embarked_2</th><th>Embarked_3</th><th>Family_Size_Grouped_1</th><th>Family_Size_Grouped_2</th><th>Family_Size_Grouped_3</th><th>Family_Size_Grouped_4</th><th>Fare</th><th>Is_Married</th><th>Pclass_1</th><th>Pclass_2</th><th>Pclass_3</th><th>Sex_1</th><th>Sex_2</th><th>Survival_Rate</th><th>Survival_Rate_NA</th><th>Ticket_Frequency</th><th>Title_1</th><th>Title_2</th><th>Title_3</th><th>Title_4</th></tr></thead><tbody><tr><td>28</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.3838383838383838</td><td>0.0</td><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><td>52</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>11</td><td>1</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>2</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>34</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3</td><td>0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.3838383838383838</td><td>0.0</td><td>1</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>48</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>10</td><td>1</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.3838383838383838</td><td>0.0</td><td>2</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>48</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3</td><td>0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.3838383838383838</td><td>0.0</td><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr></tbody></table><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><pre><code class="python">X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))y_train = df_train[&#39;Survived&#39;].valuesX_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))</code></pre><pre><code class="python">print(&#39;X_train shape: {}&#39;.format(X_train.shape))print(&#39;y_train shape: {}&#39;.format(y_train.shape))print(&#39;X_test shape: {}&#39;.format(X_test.shape))</code></pre><pre><code>X_train shape: (891, 26)y_train shape: (891,)X_test shape: (418, 26)</code></pre><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><pre><code class="python">single_best_model = RandomForestClassifier(criterion=&#39;gini&#39;,                                           n_estimators=1100,                                           max_depth=5,                                           min_samples_split=4,                                           min_samples_leaf=5,                                           max_features=&#39;auto&#39;,                                           oob_score=True,                                           random_state=SEED,                                           n_jobs=-1,                                           verbose=1)</code></pre><pre><code class="python">leaderboard_model = RandomForestClassifier(criterion=&#39;gini&#39;,                                           n_estimators=1750,                                           max_depth=7,                                           min_samples_split=6,                                           min_samples_leaf=6,                                           max_features=&#39;auto&#39;,                                           oob_score=True,                                           random_state=SEED,                                           n_jobs=-1,                                           verbose=1)</code></pre><pre><code class="python">N = 5oob = 0probs = pd.DataFrame(np.zeros((len(X_test), N * 2)),                     columns=[&#39;Fold_{}_Prob_{}&#39;.format(i, j) for i in range(1, N + 1) for j in range(2)])importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=[&#39;Fold_{}&#39;.format(i) for i in range(1, N + 1)],                           index=df_all.columns)fprs, tprs, scores = [], [], []skf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):    print(&#39;Fold {}\n&#39;.format(fold))    # Fitting the model    leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])    # Computing Train AUC score    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx],                                                 leaderboard_model.predict_proba(X_train[trn_idx])[:, 1])    trn_auc_score = auc(trn_fpr, trn_tpr)    # Computing Validation AUC score    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx],                                                 leaderboard_model.predict_proba(X_train[val_idx])[:, 1])    val_auc_score = auc(val_fpr, val_tpr)    scores.append((trn_auc_score, val_auc_score))    fprs.append(val_fpr)    tprs.append(val_tpr)    # X_test probabilities    probs.loc[:, &#39;Fold_{}_Prob_0&#39;.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 0]    probs.loc[:, &#39;Fold_{}_Prob_1&#39;.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 1]    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_    oob += leaderboard_model.oob_score_ / N    print(&#39;Fold {} OOB Score: {}\n&#39;.format(fold, leaderboard_model.oob_score_))print(&#39;Average OOB Score: {}&#39;.format(oob))</code></pre><pre><code>Fold 1[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.3s[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.1s[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finishedFold 1 OOB Score: 0.8581460674157303Fold 2[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.3s[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.0s[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.6s[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.3s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.8s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finishedFold 2 OOB Score: 0.851123595505618Fold 3[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.2s[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.0s[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finishedFold 3 OOB Score: 0.8330995792426368Fold 4[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.2s[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.1s[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finishedFold 4 OOB Score: 0.8401122019635343Fold 5[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.3s[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.1s[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finishedFold 5 OOB Score: 0.8431372549019608Average OOB Score: 0.8451237398058962</code></pre><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><h4 id="Feature-Importance"><a href="#Feature-Importance" class="headerlink" title="Feature Importance"></a>Feature Importance</h4><pre><code class="python">importances[&#39;Mean_Importance&#39;] = importances.mean(axis=1)importances.sort_values(by=&#39;Mean_Importance&#39;, inplace=True, ascending=False)plt.figure(figsize=(15, 20))sns.barplot(x=&#39;Mean_Importance&#39;, y=importances.index, data=importances)plt.xlabel(&#39;&#39;)plt.tick_params(axis=&#39;x&#39;, labelsize=15)plt.tick_params(axis=&#39;y&#39;, labelsize=15)plt.title(&#39;Random Forest Classifier Mean Feature Importance Between Folds&#39;, size=15)</code></pre><pre><code>Text(0.5, 1.0, &#39;Random Forest Classifier Mean Feature Importance Between Folds&#39;)</code></pre><p><img src="/2019/06/22/titanic_advanced/output_102_1.png" alt="png"></p><pre><code class="python">plt.show()</code></pre><h4 id="Roc-Curve"><a href="#Roc-Curve" class="headerlink" title="Roc Curve"></a>Roc Curve</h4><pre><code class="python">def plot_roc_curve(fprs, tprs):    tprs_interp = []    aucs = []    mean_fpr = np.linspace(0, 1, 100)    f, ax = plt.subplots(figsize=(15, 15))    # Plotting ROC for each fold and computing AUC scores    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))        tprs_interp[-1][0] = 0.0        roc_auc = auc(fpr, tpr)        aucs.append(roc_auc)        ax.plot(fpr, tpr, lw=1, alpha=0.3, label=&#39;ROC Fold {} (AUC = {:.3f})&#39;.format(i, roc_auc))    # Plotting ROC for random guessing    plt.plot([0, 1], [0, 1], linestyle=&#39;--&#39;, lw=2, color=&#39;r&#39;, alpha=0.8, label=&#39;Random Guessing&#39;)    mean_tpr = np.mean(tprs_interp, axis=0)    mean_tpr[-1] = 1.0    mean_auc = auc(mean_fpr, mean_tpr)    std_auc = np.std(aucs)    # Plotting the mean ROC    ax.plot(mean_fpr, mean_tpr, color=&#39;b&#39;, label=&#39;Mean ROC (AUC = {:.3f} $\pm$ {:.3f})&#39;.format(mean_auc, std_auc), lw=2,            alpha=0.8)    # Plotting the standard deviation around the mean ROC Curve    std_tpr = np.std(tprs_interp, axis=0)    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color=&#39;grey&#39;, alpha=.2, label=&#39;$\pm$ 1 std. dev.&#39;)    ax.set_xlabel(&#39;False Positive Rate&#39;, size=15, labelpad=20)    ax.set_ylabel(&#39;True Positive Rate&#39;, size=15, labelpad=20)    ax.tick_params(axis=&#39;x&#39;, labelsize=15)    ax.tick_params(axis=&#39;y&#39;, labelsize=15)    ax.set_xlim([-0.05, 1.05])    ax.set_ylim([-0.05, 1.05])    ax.set_title(&#39;ROC Curves of Folds&#39;, size=20, y=1.02)    ax.legend(loc=&#39;lower right&#39;, prop={&#39;size&#39;: 13})    plt.show()</code></pre><pre><code class="python">plot_roc_curve(fprs, tprs)</code></pre><p><img src="/2019/06/22/titanic_advanced/output_106_0.png" alt="png"></p><h2 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h2><pre><code class="python">class_survived = [col for col in probs.columns if col.endswith(&#39;Prob_1&#39;)]probs[&#39;1&#39;] = probs[class_survived].sum(axis=1) / Nprobs[&#39;0&#39;] = probs.drop(columns=class_survived).sum(axis=1) / Nprobs[&#39;pred&#39;] = 0pos = probs[probs[&#39;1&#39;] &gt;= 0.5].indexprobs.loc[pos, &#39;pred&#39;] = 1</code></pre><pre><code class="python">y_pred = probs[&#39;pred&#39;].astype(int)</code></pre><pre><code class="python">submission_df = pd.DataFrame(columns=[&#39;PassengerId&#39;, &#39;Survived&#39;])submission_df[&#39;PassengerId&#39;] = df_test[&#39;PassengerId&#39;]submission_df[&#39;Survived&#39;] = y_pred.valuessubmission_df.to_csv(&#39;submissions.csv&#39;, header=True, index=False)pandas_df_to_markdown_table(submission_df.head(10))</code></pre><table><thead><tr><th>PassengerId</th><th>Survived</th></tr></thead><tbody><tr><td>892</td><td>0</td></tr><tr><td>893</td><td>1</td></tr><tr><td>894</td><td>0</td></tr><tr><td>895</td><td>0</td></tr><tr><td>896</td><td>1</td></tr><tr><td>897</td><td>0</td></tr><tr><td>898</td><td>1</td></tr><tr><td>899</td><td>0</td></tr><tr><td>900</td><td>1</td></tr><tr><td>901</td><td>0</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Titanic-Machine-Learning-from-Disaster&quot;&gt;&lt;a href=&quot;#Titanic-Machine-Learning-from-Disaster&quot; class=&quot;headerlink&quot; title=&quot;Titanic: Machine Learning from Disaster&quot;&gt;&lt;/a&gt;Titanic: Machine Learning from Disaster&lt;/h1&gt;&lt;h2 id=&quot;Libraries&quot;&gt;&lt;a href=&quot;#Libraries&quot; class=&quot;headerlink&quot; title=&quot;Libraries&quot;&gt;&lt;/a&gt;Libraries&lt;/h2&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://lincy.online/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>[转载]领域驱动设计在互联网业务开发中的实践</title>
    <link href="https://lincy.online/2018/10/22/%E8%BD%AC%E8%BD%BD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%9C%A8%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"/>
    <id>https://lincy.online/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/</id>
    <published>2018-10-22T03:25:36.000Z</published>
    <updated>2018-11-18T14:18:39.673Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>美团技术团队： <a href="https://tech.meituan.com" target="_blank" rel="noopener">https://tech.meituan.com</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>至少30年以前，一些软件设计人员就已经意识到领域建模和设计的重要性，并形成一种思潮，Eric Evans将其定义为领域驱动设计（Domain-Driven Design，简称DDD）。在互联网开发“小步快跑，迭代试错”的大环境下，DDD似乎是一种比较“古老而缓慢”的思想。然而，由于互联网公司也逐渐深入实体经济，业务日益复杂，我们在开发中也越来越多地遇到传统行业软件开发中所面临的问题。本文就先来讲一下这些问题，然后再尝试在实践中用DDD的思想来解决这些问题。</p><a id="more"></a><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="过度耦合"><a href="#过度耦合" class="headerlink" title="过度耦合"></a>过度耦合</h2><p>业务初期，我们的功能大都非常简单，普通的CRUD就能满足，此时系统是清晰的。随着迭代的不断演化，业务逻辑变得越来越复杂，我们的系统也越来越冗杂。模块彼此关联，谁都很难说清模块的具体功能意图是啥。修改一个功能时，往往光回溯该功能需要的修改点就需要很长时间，更别提修改带来的不可预知的影响面。</p><p>下图是一个常见的系统耦合病例。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-26-28.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>订单服务接口中提供了查询、创建订单相关的接口，也提供了订单评价、支付、保险的接口。同时我们的表也是一个订单大表，包含了非常多字段。在我们维护代码时，牵一发而动全身，很可能只是想改下评价相关的功能，却影响到了创单核心路径。虽然我们可以通过测试保证功能完备性，但当我们在订单领域有大量需求同时并行开发时，改动重叠、恶性循环、疲于奔命修改各种问题。</p><p>上述问题，归根到底在于系统架构不清晰，划分出来的模块内聚度低、高耦合。</p><p>有一种解决方案，按照演进式设计的理论，让系统的设计随着系统实现的增长而增长。我们不需要作提前设计，就让系统伴随业务成长而演进。这当然是可行的，敏捷实践中的重构、测试驱动设计及持续集成可以对付各种混乱问题。重构——保持行为不变的代码改善清除了不协调的局部设计，测试驱动设计确保对系统的更改不会导致系统丢失或破坏现有功能，持续集成则为团队提供了同一代码库。</p><p>在这三种实践中，重构是克服演进式设计中大杂烩问题的主力，通过在单独的类及方法级别上做一系列小步重构来完成。我们可以很容易重构出一个独立的类来放某些通用的逻辑，但是你会发现你很难给它一个业务上的含义，只能给予一个技术维度描绘的含义。这会带来什么问题呢？新同学并不总是知道对通用逻辑的改动或获取来自该类。显然，制定项目规范并不是好的idea。我们又闻到了代码即将腐败的味道。</p><p>事实上，你可能意识到问题之所在。在解决现实问题时，我们会将问题映射到脑海中的概念模型，在模型中解决问题，再将解决方案转换为实际的代码。上述问题在于我们解决了设计到代码之间的重构，但提炼出来的设计模型，并不具有实际的业务含义，这就导致在开发新需求时，其他同学并不能很自然地将业务问题映射到该设计模型。设计似乎变成了重构者的自娱自乐，代码继续腐败，重新重构……无休止的循环。</p><p>用DDD则可以很好地解决领域模型到设计模型的同步、演化，最后再将反映了领域的设计模型转为实际的代码。</p><p>注：模型是我们解决实际问题所抽象出来的概念模型，领域模型则表达与业务相关的事实；设计模型则描述了所要构建的系统。</p><h2 id="贫血症和失忆症"><a href="#贫血症和失忆症" class="headerlink" title="贫血症和失忆症"></a>贫血症和失忆症</h2><blockquote><p><strong>贫血领域对象</strong></p><p>贫血领域对象（Anemic Domain Object）是指仅用作数据载体，而没有行为和动作的领域对象。</p></blockquote><p>在我们习惯了J2EE的开发模式后，Action/Service/DAO这种分层模式，会很自然地写出过程式代码，而学到的很多关于OO理论的也毫无用武之地。使用这种开发方式，对象只是数据的载体，没有行为。以数据为中心，以数据库ER设计作驱动。分层架构在这种开发模式下，可以理解为是对数据移动、处理和实现的过程。</p><p>以笔者最近开发的系统抽奖平台为例：</p><ul><li><p>场景需求</p><p>奖池里配置了很多奖项，我们需要按运营预先配置的概率抽中一个奖项。<br>实现非常简单，生成一个随机数，匹配符合该随机数生成概率的奖项即可。</p></li><li><p>贫血模型实现方案</p><p>先设计奖池和奖项的库表配置。</p></li></ul><p><img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-26-58.png" alt></p><ul><li>设计AwardPool和Award两个对象，只有简单的get和set属性的方法</li></ul><pre><code>class AwardPool {    int awardPoolId;    List&lt;Award&gt; awards;    public List&lt;Award&gt; getAwards() {        return awards;    }    public void setAwards(List&lt;Award&gt; awards) {        this.awards = awards;    }    ......}class Award {   int awardId;   int probability;//概率   ......}</code></pre><ul><li><p>Service代码实现</p><p>设计一个LotteryService，在其中的drawLottery()方法写服务逻辑</p></li></ul><pre><code>AwardPool awardPool = awardPoolDao.getAwardPool(poolId);//sql查询，将数据映射到AwardPool对象for (Award award : awardPool.getAwards()) {   //寻找到符合award.getProbability()概率的award}</code></pre><ul><li>按照我们通常思路实现，可以发现：在业务领域里非常重要的抽奖，我的业务逻辑都是写在Service中的，Award充其量只是个数据载体，没有任何行为。<strong>简单的业务系统采用这种贫血模型和过程化设计是没有问题的，</strong>但在业务逻辑复杂了，业务逻辑、状态会散落到在大量方法中，原本的代码意图会渐渐不明确，我们将这种情况称为由贫血症引起的失忆症。</li></ul><p>更好的是采用领域模型的开发方式，将数据和行为封装在一起，并与现实世界中的业务对象相映射。各类具备明确的职责划分，将领域逻辑分散到领域对象中。继续举我们上述抽奖的例子，使用概率选择对应的奖品就应当放到AwardPool类中。</p><h1 id="为什么选择DDD"><a href="#为什么选择DDD" class="headerlink" title="为什么选择DDD"></a>为什么选择DDD</h1><h2 id="软件系统复杂性应对"><a href="#软件系统复杂性应对" class="headerlink" title="软件系统复杂性应对"></a>软件系统复杂性应对</h2><p>解决<strong>复杂和大规模软件</strong>的武器可以被粗略地归为三类：抽象、分治和知识。</p><p><strong>分治</strong> 把问题空间分割为规模更小且易于处理的若干子问题。分割后的问题需要足够小，以便一个人单枪匹马就能够解决他们；其次，必须考虑如何将分割后的各个部分装配为整体。分割得越合理越易于理解，在装配成整体时，所需跟踪的细节也就越少。即更容易设计各部分的协作方式。评判什么是分治得好，即高内聚低耦合。</p><p><strong>抽象</strong> 使用抽象能够精简问题空间，而且问题越小越容易理解。举个例子，从北京到上海出差，可以先理解为使用交通工具前往，但不需要一开始就想清楚到底是高铁还是飞机，以及乘坐他们需要注意什么。</p><p><strong>知识</strong> 顾名思义，DDD可以认为是知识的一种。</p><p>DDD提供了这样的知识手段，让我们知道如何抽象出限界上下文以及如何去分治。</p><h2 id="与微服务架构相得益彰"><a href="#与微服务架构相得益彰" class="headerlink" title="与微服务架构相得益彰"></a>与微服务架构相得益彰</h2><p>微服务架构众所周知，此处不做赘述。我们创建微服务时，需要创建一个高内聚、低耦合的微服务。而DDD中的限界上下文则完美匹配微服务要求，可以将该限界上下文理解为一个微服务进程。</p><p>上述是从更直观的角度来描述两者的相似处。</p><p>在系统复杂之后，我们都需要用分治来拆解问题。一般有两种方式，技术维度和业务维度。技术维度是类似MVC这样，业务维度则是指按业务领域来划分系统。</p><p>微服务架构更强调从业务维度去做分治来应对系统复杂度，而DDD也是同样的着重业务视角。<br>如果<strong>两者在追求的目标（业务维度）达到了上下文的统一</strong>，那么在具体做法上有什么联系和不同呢？</p><p>我们将架构设计活动精简为以下三个层面：</p><ul><li>业务架构——根据业务需求设计业务模块及其关系</li><li>系统架构——设计系统和子系统的模块</li><li>技术架构——决定采用的技术及框架</li></ul><p>以上三种活动在实际开发中是有先后顺序的，但不一定孰先孰后。在我们解决常规套路问题时，我们会很自然地往熟悉的分层架构套（先确定系统架构），或者用PHP开发很快（先确定技术架构），在业务不复杂时，这样是合理的。</p><p>跳过业务架构设计出来的架构关注点不在业务响应上，可能就是个大泥球，在面临需求迭代或响应市场变化时就很痛苦。</p><p><strong>DDD的核心诉求就是将业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分解耦，可以自由地选择合适的技术架构，去中心化地治理技术和数据。</strong></p><p>可以参见下图来更好地理解双方之间的协作关系：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-27-20.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h1 id="如何实践DDD"><a href="#如何实践DDD" class="headerlink" title="如何实践DDD"></a>如何实践DDD</h1><p>我们将通过上文提到的抽奖平台，来详细介绍我们如何通过DDD来解构一个中型的基于微服务架构的系统，从而做到系统的高内聚、低耦合。</p><p>首先看下抽奖系统的大致需求：<br>运营——可以配置一个抽奖活动，该活动面向一个特定的用户群体，并针对一个用户群体发放一批不同类型的奖品（优惠券，激活码，实物奖品等）。<br>用户-通过活动页面参与不同类型的抽奖活动。</p><p>设计领域模型的一般步骤如下：</p><ol><li>根据需求划分出初步的领域和限界上下文，以及上下文之间的关系；</li><li>进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象；</li><li>对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根；</li><li>为聚合根设计仓储，并思考实体或值对象的创建方式；</li><li>在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。</li></ol><h2 id="战略建模"><a href="#战略建模" class="headerlink" title="战略建模"></a>战略建模</h2><p>战略和战术设计是站在DDD的角度进行划分。战略设计侧重于高层次、宏观上去划分和集成限界上下文，而战术设计则关注更具体使用建模工具来细化上下文。</p><h3 id="领域"><a href="#领域" class="headerlink" title="领域"></a>领域</h3><p>现实世界中，领域包含了问题域和解系统。一般认为软件是对现实世界的部分模拟。在DDD中，解系统可以映射为一个个限界上下文，限界上下文就是软件对于问题域的一个特定的、有限的解决方案。</p><h3 id="限界上下文"><a href="#限界上下文" class="headerlink" title="限界上下文"></a>限界上下文</h3><blockquote><p><strong>限界上下文</strong></p><p>一个由显示边界限定的特定职责。领域模型便存在于这个边界之内。在边界内，每一个模型概念，包括它的属性和操作，都具有特殊的含义。</p></blockquote><p>一个给定的业务领域会包含多个限界上下文，想与一个限界上下文沟通，则需要通过显示边界进行通信。系统通过确定的限界上下文来进行解耦，而每一个上下文内部紧密组织，职责明确，具有较高的内聚性。</p><p>一个很形象的隐喻：细胞质所以能够存在，是因为细胞膜限定了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。</p><h3 id="划分限界上下文"><a href="#划分限界上下文" class="headerlink" title="划分限界上下文"></a>划分限界上下文</h3><p>划分限界上下文，不管是Eric Evans还是Vaughn Vernon，在他们的大作里都没有怎么提及。</p><p>显然我们不应该按技术架构或者开发任务来创建限界上下文，应该按照语义的边界来考虑。</p><p><strong>我们的实践是，考虑产品所讲的通用语言，从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求里提取一些动词，观察动词和对象之间的关系；我们将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的界限上下文。形成之后，我们可以尝试用语言来描述下界限上下文的职责，看它是否清晰、准确、简洁和完整。简言之，限界上下文应该从需求出发，按领域划分。</strong></p><p>前文提到，我们的用户划分为运营和用户。其中，运营对抽奖活动的配置十分复杂但相对低频。用户对这些抽奖活动配置的使用是高频次且无感知的。根据这样的业务特点，我们首先将抽奖平台划分为C端抽奖和M端抽奖管理平台两个子域，让两者完全解耦。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-27-38.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>在确认了M端领域和C端的限界上下文后，我们再对各自上下文内部进行限界上下文的划分。下面我们用C端进行举例。</p><p>产品的需求概述如下：</p><pre><code>1. 抽奖活动有活动限制，例如用户的抽奖次数限制，抽奖的开始和结束的时间等；2. 一个抽奖活动包含多个奖品，可以针对一个或多个用户群体；3. 奖品有自身的奖品配置，例如库存量，被抽中的概率等，最多被一个用户抽中的次数等等；4. 用户群体有多种区别方式，如按照用户所在城市区分，按照新老客区分等；5. 活动具有风控配置，能够限制用户参与抽奖的频率。</code></pre><p>根据产品的需求，我们提取了一些关键性的概念作为子域，形成我们的限界上下文。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-27-51.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>首先，抽奖上下文作为整个领域的核心，承担着用户抽奖的核心业务，抽奖中包含了奖品和用户群体的概念。</p><ul><li>在设计初期，我们曾经考虑划分出抽奖和发奖两个领域，前者负责选奖，后者负责将选中的奖品发放出去。但在实际开发过程中，我们发现这两部分的逻辑紧密连接，难以拆分。并且单纯的发奖逻辑足够简单，仅仅是调用第三方服务进行发奖，不足以独立出来成为一个领域。</li></ul><p>对于活动的限制，我们定义了活动准入的通用语言，将活动开始/结束时间，活动可参与次数等限制条件都收拢到活动准入上下文中。</p><p>对于抽奖的奖品库存量，由于库存的行为与奖品本身相对解耦，库存关注点更多是库存内容的核销，且库存本身具备通用性，可以被奖品之外的内容使用，因此我们定义了独立的库存上下文。</p><p>由于C端存在一些刷单行为，我们根据产品需求定义了风控上下文，用于对活动进行风控。<br>最后，活动准入、风控、抽奖等领域都涉及到一些次数的限制，因此我们定义了计数上下文。</p><p>可以看到，通过DDD的限界上下文划分，我们界定出抽奖、活动准入、风控、计数、库存等五个上下文，每个上下文在系统中都高度内聚。</p><h3 id="上下文映射图"><a href="#上下文映射图" class="headerlink" title="上下文映射图"></a>上下文映射图</h3><p>在进行上下文划分之后，我们还需要进一步梳理上下文之间的关系。</p><blockquote><p><strong>康威（梅尔·康威）定律</strong></p><p>任何组织在设计一套系统（广义概念上的系统）时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。</p></blockquote><p>康威定律告诉我们，系统结构应尽量的与组织结构保持一致。这里，我们认为团队结构（无论是内部组织还是团队间组织）就是组织结构，限界上下文就是系统的业务结构。因此，团队结构应该和限界上下文保持一致。</p><p>梳理清楚上下文之间的关系，从团队内部的关系来看，有如下好处：</p><ol><li>任务更好拆分，一个开发人员可以全身心的投入到相关的一个单独的上下文中；</li><li>沟通更加顺畅，一个上下文可以明确自己对其他上下文的依赖关系，从而使得团队内开发直接更好的对接。</li></ol><p>从团队间的关系来看，明确的上下文关系能够带来如下帮助：</p><ol><li>每个团队在它的上下文中能够更加明确自己领域内的概念，因为上下文是领域的解系统；</li><li>对于限界上下文之间发生交互，团队与上下文的一致性，能够保证我们明确对接的团队和依赖的上下游。</li></ol><blockquote><p><strong>限界上下文之间的映射关系</strong></p><ul><li>合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损。</li><li>共享内核（Shared Kernel）：两个上下文依赖部分共享的模型。</li><li>客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖。</li><li>遵奉者（Conformist）：下游上下文只能盲目依赖上游上下文。</li><li>防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互。</li><li>开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问。</li><li>发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。</li><li>大泥球（Big Ball of Mud）：混杂在一起的上下文关系，边界不清晰。</li><li>另谋他路（SeparateWay）：两个完全没有任何联系的上下文。</li></ul></blockquote><p>上文定义了上下文映射间的关系，经过我们的反复斟酌，抽奖平台上下文的映射关系图如下：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-28-06.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>由于抽奖，风控，活动准入，库存，计数五个上下文都处在抽奖领域的内部，所以它们之间符合“一荣俱荣，一损俱损”的合作关系（PartnerShip，简称PS）。</p><p>同时，抽奖上下文在进行发券动作时，会依赖券码、平台券、外卖券三个上下文。抽奖上下文通过防腐层（Anticorruption Layer，ACL）对三个上下文进行了隔离，而三个券上下文通过开放主机服务（Open Host Service）作为发布语言（Published Language）对抽奖上下文提供访问机制。</p><p><strong>通过上下文映射关系，我们明确的限制了限界上下文的耦合性，即在抽奖平台中，无论是上下文内部交互（合作关系）还是与外部上下文交互（防腐层），耦合度都限定在数据耦合（Data Coupling）的层级。</strong></p><h2 id="战术建模——细化上下文"><a href="#战术建模——细化上下文" class="headerlink" title="战术建模——细化上下文"></a>战术建模——细化上下文</h2><p>梳理清楚上下文之间的关系后，我们需要从战术层面上剖析上下文内部的组织关系。首先看下DDD中的一些定义。</p><blockquote><p><strong>实体</strong></p><p>当一个对象由其标识（而不是属性）区分时，这种对象称为实体（Entity）。</p><p>例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。</p></blockquote><p>在实践上建议将属性的验证放到实体中。</p><blockquote><p><strong>值对象</strong></p><p>当一个对象用于对事务进行描述而没有唯一标识时，它被称作值对象（Value Object）</p><p>例：比如颜色信息，我们只需要知道{“name”:”黑色”，”css”:”#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。</p></blockquote><p>值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。</p><p>它具有不变性、相等性和可替换性。</p><p>在实践中，需要保证值对象创建后就不能被修改，即不允许外部再修改其属性。在不同上下文集成时，会出现模型概念的公用，如商品模型会存在于电商的各个上下文中。在订单上下文中如果你只关注下单时商品信息快照，那么将商品对象视为值对象是很好的选择。</p><blockquote><p><strong>聚合根</strong></p><p>Aggregate(聚合）是一组相关对象的集合，作为一个整体被外界访问，聚合根（Aggregate Root）是这个聚合的根节点。</p></blockquote><p>聚合是一个非常重要的概念，核心领域往往都需要用聚合来表达。其次，聚合在技术上有非常高的价值，可以指导详细设计。</p><p>聚合由根实体，值对象和实体组成。</p><p>如何创建好的聚合？</p><ul><li>边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。</li><li>设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。</li><li>通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。<br>如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。</li></ul><p>聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List&lt;值对象&gt;，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。</p><blockquote><p><strong>领域服务</strong></p><p>一些重要的领域行为或操作，可以归类为领域服务。它既不是实体，也不是值对象的范畴。</p></blockquote><p>当我们采用了微服务架构风格，一切领域逻辑的对外暴露均需要通过领域服务来进行。如原本由聚合根暴露的业务逻辑也需要依托于领域服务。</p><blockquote><p><strong>领域事件</strong></p><p>领域事件是对领域内发生的活动进行的建模。</p></blockquote><p>抽奖平台的核心上下文是抽奖上下文，接下来介绍下我们对抽奖上下文的建模。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-28-21.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>在抽奖上下文中，我们通过抽奖(DrawLottery)这个聚合根来控制抽奖行为，可以看到，一个抽奖包括了抽奖ID（LotteryId）以及多个奖池（AwardPool），而一个奖池针对一个特定的用户群体（UserGroup）设置了多个奖品（Award）。</p><p>另外，在抽奖领域中，我们还会使用抽奖结果（SendResult）作为输出信息，使用用户领奖记录（UserLotteryLog）作为领奖凭据和存根。</p><p><strong>谨慎使用值对象</strong></p><p>在实践中，我们发现虽然一些领域对象符合值对象的概念，但是随着业务的变动，很多原有的定义会发生变更，值对象可能需要在业务意义具有唯一标识，而对这类值对象的重构往往需要较高成本。因此在特定的情况下，我们也要根据实际情况来权衡领域对象的选型。</p><h2 id="DDD工程实现"><a href="#DDD工程实现" class="headerlink" title="DDD工程实现"></a>DDD工程实现</h2><p>在对上下文进行细化后，我们开始在工程中真正落地DDD。</p><h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><p>模块（Module）是DDD中明确提到的一种控制限界上下文的手段，在我们的工程中，一般尽量用一个模块来表示一个领域的限界上下文。</p><p>如代码中所示，一般的工程中包的组织方式为{com.公司名.组织架构.业务.上下文.*}，这样的组织结构能够明确的将一个上下文限定在包的内部。</p><pre><code>import com.company.team.bussiness.lottery.*;//抽奖上下文import com.company.team.bussiness.riskcontrol.*;//风控上下文import com.company.team.bussiness.counter.*;//计数上下文import com.company.team.bussiness.condition.*;//活动准入上下文import com.company.team.bussiness.stock.*;//库存上下文</code></pre><p>代码演示1 模块的组织</p><p>对于模块内的组织结构，一般情况下我们是按照领域对象、领域服务、领域资源库、防腐层等组织方式定义的。</p><pre><code>import com.company.team.bussiness.lottery.domain.valobj.*;//领域对象-值对象import com.company.team.bussiness.lottery.domain.entity.*;//领域对象-实体import com.company.team.bussiness.lottery.domain.aggregate.*;//领域对象-聚合根import com.company.team.bussiness.lottery.service.*;//领域服务import com.company.team.bussiness.lottery.repo.*;//领域资源库import com.company.team.bussiness.lottery.facade.*;//领域防腐层</code></pre><p>代码演示2 模块的组织</p><p>每个模块的具体实现，我们将在下文中展开。</p><h3 id="领域对象"><a href="#领域对象" class="headerlink" title="领域对象"></a>领域对象</h3><p>前文提到，领域驱动要解决的一个重要的问题，就是解决对象的贫血问题。这里我们用之前定义的抽奖（DrawLottery）聚合根和奖池（AwardPool）值对象来具体说明。</p><p>抽奖聚合根持有了抽奖活动的id和该活动下的所有可用奖池列表，它的一个最主要的领域功能就是根据一个抽奖发生场景（DrawLotteryContext），选择出一个适配的奖池，即chooseAwardPool方法。</p><p>chooseAwardPool的逻辑是这样的：DrawLotteryContext会带有用户抽奖时的场景信息（抽奖得分或抽奖时所在的城市），DrawLottery会根据这个场景信息，匹配一个可以给用户发奖的AwardPool。</p><pre><code>package com.company.team.bussiness.lottery.domain.aggregate;import ...;public class DrawLottery {    private int lotteryId; //抽奖id    private List&lt;AwardPool&gt; awardPools; //奖池列表    //getter &amp; setter    public void setLotteryId(int lotteryId) {        if(id&lt;=0){            throw new IllegalArgumentException(&quot;非法的抽奖id&quot;);         }        this.lotteryId = lotteryId;    }    //根据抽奖入参context选择奖池    public AwardPool chooseAwardPool(DrawLotteryContext context) {        if(context.getMtCityInfo()!=null) {            return chooseAwardPoolByCityInfo(awardPools, context.getMtCityInfo());        } else {            return chooseAwardPoolByScore(awardPools, context.getGameScore());        }    }    //根据抽奖所在城市选择奖池    private AwardPool chooseAwardPoolByCityInfo(List&lt;AwardPool&gt; awardPools, MtCifyInfo cityInfo) {        for(AwardPool awardPool: awardPools) {            if(awardPool.matchedCity(cityInfo.getCityId())) {                return awardPool;            }        }        return null;    }    //根据抽奖活动得分选择奖池    private AwardPool chooseAwardPoolByScore(List&lt;AwardPool&gt; awardPools, int gameScore) {...}}</code></pre><p>代码演示3 DrawLottery</p><p>在匹配到一个具体的奖池之后，需要确定最后给用户的奖品是什么。这部分的领域功能在AwardPool内。</p><pre><code>package com.company.team.bussiness.lottery.domain.valobj;import ...;public class AwardPool {    private String cityIds;//奖池支持的城市    private String scores;//奖池支持的得分    private int userGroupType;//奖池匹配的用户类型    private List&lt;Awrad&gt; awards;//奖池中包含的奖品    //当前奖池是否与城市匹配    public boolean matchedCity(int cityId) {...}    //当前奖池是否与用户得分匹配    public boolean matchedScore(int score) {...}    //根据概率选择奖池    public Award randomGetAward() {        int sumOfProbablity = 0;        for(Award award: awards) {            sumOfProbability += award.getAwardProbablity();        }        int randomNumber = ThreadLocalRandom.current().nextInt(sumOfProbablity);        range = 0;        for(Award award: awards) {            range += award.getProbablity();            if(randomNumber&lt;range) {                return award;            }        }        return null;    }}</code></pre><p>代码演示4 AwardPool</p><p>与以往的仅有getter、setter的业务对象不同，领域对象具有了行为，对象更加丰满。同时，比起将这些逻辑写在服务内（例如**Service），领域功能的内聚性更强，职责更加明确。</p><h3 id="资源库"><a href="#资源库" class="headerlink" title="资源库"></a>资源库</h3><p>领域对象需要资源存储，存储的手段可以是多样化的，常见的无非是数据库，分布式缓存，本地缓存等。资源库（Repository）的作用，就是对领域的存储和访问进行统一管理的对象。在抽奖平台中，我们是通过如下的方式组织资源库的。</p><pre><code>//数据库资源import com.company.team.bussiness.lottery.repo.dao.AwardPoolDao;//数据库访问对象-奖池import com.company.team.bussiness.lottery.repo.dao.AwardDao;//数据库访问对象-奖品import com.company.team.bussiness.lottery.repo.dao.po.AwardPO;//数据库持久化对象-奖品import com.company.team.bussiness.lottery.repo.dao.po.AwardPoolPO;//数据库持久化对象-奖池import com.company.team.bussiness.lottery.repo.cache.DrawLotteryCacheAccessObj;//分布式缓存访问对象-抽奖缓存访问import com.company.team.bussiness.lottery.repo.repository.DrawLotteryRepository;//资源库访问对象-抽奖资源库</code></pre><p>代码演示5 Repository组织结构</p><p>资源库对外的整体访问由Repository提供，它聚合了各个资源库的数据信息，同时也承担了资源存储的逻辑（例如缓存更新机制等）。</p><p>在抽奖资源库中，我们屏蔽了对底层奖池和奖品的直接访问，而是仅对抽奖的聚合根进行资源管理。代码示例中展示了抽奖资源获取的方法（最常见的Cache Aside Pattern）。</p><p>比起以往将资源管理放在服务中的做法，由资源库对资源进行管理，职责更加明确，代码的可读性和可维护性也更强。</p><pre><code>package com.company.team.bussiness.lottery.repo;import ...;@Repositorypublic class DrawLotteryRepository {    @Autowired    private AwardDao awardDao;    @Autowired    private AwardPoolDao awardPoolDao;    @AutoWired    private DrawLotteryCacheAccessObj drawLotteryCacheAccessObj;    public DrawLottery getDrawLotteryById(int lotteryId) {        DrawLottery drawLottery = drawLotteryCacheAccessObj.get(lotteryId);        if(drawLottery!=null){            return drawLottery;        }        drawLottery = getDrawLotteyFromDB(lotteryId);        drawLotteryCacheAccessObj.add(lotteryId, drawLottery);        return drawLottery;    }    private DrawLottery getDrawLotteryFromDB(int lotteryId) {...}}</code></pre><p>代码演示6 DrawLotteryRepository</p><h3 id="防腐层"><a href="#防腐层" class="headerlink" title="防腐层"></a>防腐层</h3><p>亦称适配层。在一个上下文中，有时需要对外部上下文进行访问，通常会引入防腐层的概念来对外部上下文的访问进行一次转义。</p><p>有以下几种情况会考虑引入防腐层：</p><ul><li>需要将外部上下文中的模型翻译成本上下文理解的模型。</li><li>不同上下文之间的团队协作关系，如果是供奉者关系，建议引入防腐层，避免外部上下文变化对本上下文的侵蚀。</li><li>该访问本上下文使用广泛，为了避免改动影响范围过大。</li></ul><p>如果内部多个上下文对外部上下文需要访问，那么可以考虑将其放到通用上下文中。</p><p>在抽奖平台中，我们定义了用户城市信息防腐层(UserCityInfoFacade)，用于外部的用户城市信息上下文（微服务架构下表现为用户城市信息服务）。</p><p>以用户信息防腐层举例，它以抽奖请求参数(LotteryContext)为入参，以城市信息(MtCityInfo)为输出。</p><pre><code>package com.company.team.bussiness.lottery.facade;import ...;@Componentpublic class UserCityInfoFacade {    @Autowired    private LbsService lbsService;//外部用户城市信息RPC服务    public MtCityInfo getMtCityInfo(LotteryContext context) {        LbsReq lbsReq = new LbsReq();        lbsReq.setLat(context.getLat());        lbsReq.setLng(context.getLng());        LbsResponse resp = lbsService.getLbsCityInfo(lbsReq);        return buildMtCifyInfo(resp);    }    private MtCityInfo buildMtCityInfo(LbsResponse resp) {...}}</code></pre><p>代码演示7 UserCityInfoFacade</p><h3 id="领域服务"><a href="#领域服务" class="headerlink" title="领域服务"></a>领域服务</h3><p>上文中，我们将领域行为封装到领域对象中，将资源管理行为封装到资源库中，将外部上下文的交互行为封装到防腐层中。此时，我们再回过头来看领域服务时，能够发现领域服务本身所承载的职责也就更加清晰了，即就是通过串联领域对象、资源库和防腐层等一系列领域内的对象的行为，对其他上下文提供交互的接口。</p><p>我们以抽奖服务为例（issueLottery），可以看到在省略了一些防御性逻辑（异常处理，空值判断等）后，领域服务的逻辑已经足够清晰明了。</p><pre><code>package com.company.team.bussiness.lottery.service.implimport ...;@Servicepublic class LotteryServiceImpl implements LotteryService {    @Autowired    private DrawLotteryRepository drawLotteryRepo;    @Autowired    private UserCityInfoFacade UserCityInfoFacade;    @Autowired    private AwardSendService awardSendService;    @Autowired    private AwardCounterFacade awardCounterFacade;    @Override    public IssueResponse issueLottery(LotteryContext lotteryContext) {        DrawLottery drawLottery = drawLotteryRepo.getDrawLotteryById(lotteryContext.getLotteryId());//获取抽奖配置聚合根        awardCounterFacade.incrTryCount(lotteryContext);//增加抽奖计数信息        AwardPool awardPool = lotteryConfig.chooseAwardPool(bulidDrawLotteryContext(drawLottery, lotteryContext));//选中奖池        Award award = awardPool.randomChooseAward();//选中奖品        return buildIssueResponse(awardSendService.sendAward(award, lotteryContext));//发出奖品实体    }    private IssueResponse buildIssueResponse(AwardSendResponse awardSendResponse) {...}}</code></pre><p>代码演示8 LotteryService</p><h3 id="数据流转"><a href="#数据流转" class="headerlink" title="数据流转"></a>数据流转</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-28-44.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>在抽奖平台的实践中，我们的数据流转如上图所示。<br>首先领域的开放服务通过信息传输对象（DTO）来完成与外界的数据交互；在领域内部，我们通过领域对象（DO）作为领域内部的数据和行为载体；在资源库内部，我们沿袭了原有的数据库持久化对象（PO）进行数据库资源的交互。同时，DTO与DO的转换发生在领域服务内，DO与PO的转换发生在资源库内。</p><p>与以往的业务服务相比，当前的编码规范可能多造成了一次数据转换，但每种数据对象职责明确，数据流转更加清晰。</p><h3 id="上下文集成"><a href="#上下文集成" class="headerlink" title="上下文集成"></a>上下文集成</h3><p>通常集成上下文的手段有多种，常见的手段包括开放领域服务接口、开放HTTP服务以及消息发布-订阅机制。</p><p>在抽奖系统中，我们使用的是开放服务接口进行交互的。最明显的体现是计数上下文，它作为一个通用上下文，对抽奖、风控、活动准入等上下文都提供了访问接口。<br>同时，如果在一个上下文对另一个上下文进行集成时，若需要一定的隔离和适配，可以引入防腐层的概念。这一部分的示例可以参考前文的防腐层代码示例。</p><h3 id="分离领域"><a href="#分离领域" class="headerlink" title="分离领域"></a>分离领域</h3><p>接下来讲解在实施领域模型的过程中，如何应用到系统架构中。</p><p>我们采用的微服务架构风格，与Vernon在《实现领域驱动设计》并不太一致，更具体差异可阅读他的书体会。</p><p>如果我们维护一个从前到后的应用系统：</p><p>下图中领域服务是使用微服务技术剥离开来，独立部署，对外暴露的只能是服务接口，领域对外暴露的业务逻辑只能依托于领域服务。而在Vernon著作中，并未假定微服务架构风格，因此领域层暴露的除了领域服务外，还有聚合、实体和值对象等。此时的应用服务层是比较简单的，获取来自接口层的请求参数，调度多个领域服务以实现界面层功能。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-29-06.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>随着业务发展，业务系统快速膨胀，我们的系统属于核心时：</p><p>应用服务虽然没有领域逻辑，但涉及到了对多个领域服务的编排。当业务规模庞大到一定程度，编排本身就富含了业务逻辑（除此之外，应用服务在稳定性、性能上所做的措施也希望统一起来，而非散落各处），那么此时应用服务对于外部来说是一个领域服务，整体看起来则是一个独立的限界上下文。</p><p>此时应用服务对内还属于应用服务，对外已是领域服务的概念，需要将其暴露为微服务。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/2018-10-22-11-29-20.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>注：具体的架构实践可按照团队和业务的实际情况来，此处仅为作者自身的业务实践。除分层架构外，如CQRS架构也是不错的选择</p><p>以下是一个示例。我们定义了抽奖、活动准入、风险控制等多个领域服务。在本系统中，我们需要集成多个领域服务，为客户端提供一套功能完备的抽奖应用服务。这个应用服务的组织如下：</p><pre><code>package ...;import ...;@Servicepublic class LotteryApplicationService {    @Autowired    private LotteryRiskService riskService;    @Autowired    private LotteryConditionService conditionService;    @Autowired    private LotteryService lotteryService;    //用户参与抽奖活动    public Response&lt;PrizeInfo, ErrorData&gt; participateLottery(LotteryContext lotteryContext) {        //校验用户登录信息        validateLoginInfo(lotteryContext);        //校验风控         RiskAccessToken riskToken = riskService.accquire(buildRiskReq(lotteryContext));        ...        //活动准入检查        LotteryConditionResult conditionResult = conditionService.checkLotteryCondition(otteryContext.getLotteryId(),lotteryContext.getUserId());        ...        //抽奖并返回结果        IssueResponse issueResponse = lotteryService.issurLottery(lotteryContext);        if(issueResponse!=null &amp;&amp; issueResponse.getCode()==IssueResponse.OK) {            return buildSuccessResponse(issueResponse.getPrizeInfo());        } else {               return buildErrorResponse(ResponseCode.ISSUE_LOTTERY_FAIL, ResponseMsg.ISSUE_LOTTERY_FAIL)        }    }    private void validateLoginInfo(LotteryContext lotteryContext){...}    private Response&lt;PrizeInfo, ErrorData&gt; buildErrorResponse (int code, String msg){...}    private Response&lt;PrizeInfo, ErrorData&gt; buildSuccessResponse (PrizeInfo prizeInfo){...}}</code></pre><p>代码演示9 LotteryApplicationService</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>在本文中，我们采用了分治的思想，从抽象到具体阐述了DDD在互联网真实业务系统中的实践。通过领域驱动设计这个强大的武器，我们将系统解构的更加合理。</p><p>但值得注意的是，如果你面临的系统很简单或者做一些SmartUI之类，那么你不一定需要DDD。尽管本文对贫血模型、演进式设计提出了些许看法，但它们在特定范围和具体场景下会更高效。读者需要针对自己的实际情况，做一定取舍，适合自己的才是最好的。</p><p>本篇通过DDD来讲述软件设计的术与器，本质是为了高内聚低耦合，紧靠本质，按自己的理解和团队情况来实践DDD即可。</p><p>另外，关于DDD在迭代过程中模型腐化的相关问题，本文中没有提及，将在后续的文章中论述，敬请期待。</p><p>鉴于作者经验有限，我们对领域驱动的理解难免会有不足之处，欢迎大家共同探讨，共同提高。</p><h1 id="参考书籍"><a href="#参考书籍" class="headerlink" title="参考书籍"></a>参考书籍</h1><blockquote><p>Eric Evans.领域驱动设计.赵俐 盛海艳 刘霞等译.人民邮电出版社，2016.<br>Vaughn Vernon.实现领域驱动设计.滕云译.电子工业出版社，2014.</p></blockquote><h1 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h1><p>文彬、子维，美团资深研发工程师，毕业于南京大学，现从事美团外卖营销相关的研发工作。<br>最后打波硬广，美团外卖上海研发中心长期招聘前端、客户端、后端、数据仓库和数据挖掘相关的工程师，欢迎有兴趣的同学发送简历到<a href="mailto:wenbin.lu@dianping.com" target="_blank" rel="noopener">wenbin.lu@dianping.com</a>。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;美团技术团队： &lt;a href=&quot;https://tech.meituan.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://tech.meituan.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;至少30年以前，一些软件设计人员就已经意识到领域建模和设计的重要性，并形成一种思潮，Eric Evans将其定义为领域驱动设计（Domain-Driven Design，简称DDD）。在互联网开发“小步快跑，迭代试错”的大环境下，DDD似乎是一种比较“古老而缓慢”的思想。然而，由于互联网公司也逐渐深入实体经济，业务日益复杂，我们在开发中也越来越多地遇到传统行业软件开发中所面临的问题。本文就先来讲一下这些问题，然后再尝试在实践中用DDD的思想来解决这些问题。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="架构" scheme="https://lincy.online/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>VMware centos 无法连接网络问题解决</title>
    <link href="https://lincy.online/2018/10/04/VMware-centos-%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <id>https://lincy.online/2018/10/04/VMware-centos-无法连接网络问题解决/</id>
    <published>2018-10-04T14:25:43.000Z</published>
    <updated>2018-10-04T14:44:08.824Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>VMware 安装 CentOS 虚拟机，使用NAT模式联网，无法联网<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/04/VMware-centos-无法连接网络问题解决/2018-10-04-22-31-20.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>执行命令 <code>dhclient -v</code></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/04/VMware-centos-无法连接网络问题解决/2018-10-04-22-33-05.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h2 id="添加到启动任务"><a href="#添加到启动任务" class="headerlink" title="添加到启动任务"></a>添加到启动任务</h2><ul><li><p>在 /etc/init.d/下创建文件，命名 “net-autostart”</p><pre><code class="sh">  #!/bin/bash  # Solution for &quot;No Internet Connection from VMware&quot;  #  ### BEGIN INIT INFO  # Default-Start: 2 3 4 5  # Default-Stop: 0 1 6  ### END INIT INFO  dhclient -v</code></pre></li><li><p>更改权限<br><code>chmod 755 net-autostart</code></p></li><li><p>自动启动<br><code>chkconfig --add net-autostart</code></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;VMware 安装 CentOS 虚拟机，使用NAT模式联网，无法联网&lt;br&gt;&lt;figure class=&quot;image-bubble&quot;&gt;
 
      
    
    </summary>
    
      <category term="杂七杂八" scheme="https://lincy.online/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>分布式服务治理-Dubbo</title>
    <link href="https://lincy.online/2018/09/23/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86-Dubbo/"/>
    <id>https://lincy.online/2018/09/23/分布式服务治理-Dubbo/</id>
    <published>2018-09-23T09:26:52.000Z</published>
    <updated>2018-10-23T22:02:28.785Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dubbo-是什么"><a href="#Dubbo-是什么" class="headerlink" title="Dubbo 是什么"></a>Dubbo 是什么</h1><p>Dubbo是一个分布式的服务框架，提供高性能的以及透明化的RPC远程服务调用解决方法，以及SOA服务治理方案。</p><ul><li>远程通信</li><li>集群容错</li><li>服务的自动发现</li><li>负债均衡</li></ul><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/23/分布式服务治理-Dubbo/2018-09-23-18-56-17.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h5 id="节点角色说明"><a href="#节点角色说明" class="headerlink" title="节点角色说明"></a>节点角色说明</h5><table><thead><tr><th>节点</th><th>角色说明</th></tr></thead><tbody><tr><td><code>Provider</code></td><td>暴露服务的服务提供方</td></tr><tr><td><code>Consumer</code></td><td>调用远程服务的服务消费方</td></tr><tr><td><code>Registry</code></td><td>服务注册与发现的注册中心</td></tr><tr><td><code>Monitor</code></td><td>统计服务的调用次数和调用时间的监控中心</td></tr><tr><td><code>Container</code></td><td>服务运行容器</td></tr></tbody></table><h5 id="调用关系说明"><a href="#调用关系说明" class="headerlink" title="调用关系说明"></a>调用关系说明</h5><ol><li>服务容器负责启动，加载，运行服务提供者。</li><li>服务提供者在启动时，向注册中心注册自己提供的服务。</li><li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li><li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li><li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li></ol><p>Dubbo 架构具有以下几个特点，分别是连通性、健壮性、伸缩性、以及向未来架构的升级性。</p><h2 id="连通性"><a href="#连通性" class="headerlink" title="连通性"></a>连通性</h2><ul><li>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小</li><li>监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示</li><li>服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间不包含网络开销</li><li>服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间包含网络开销</li><li>注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外</li><li>注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者</li><li>注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表</li><li>注册中心和监控中心都是可选的，服务消费者可以直连服务提供者</li></ul><h2 id="健壮性"><a href="#健壮性" class="headerlink" title="健壮性"></a>健壮性</h2><ul><li>监控中心宕掉不影响使用，只是丢失部分采样数据</li><li>数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务</li><li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台</li><li>注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯</li><li>服务提供者无状态，任意一台宕掉后，不影响使用</li><li>服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复</li></ul><h2 id="伸缩性"><a href="#伸缩性" class="headerlink" title="伸缩性"></a>伸缩性</h2><ul><li>注册中心为对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心</li><li>服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者</li></ul><h2 id="升级性"><a href="#升级性" class="headerlink" title="升级性"></a>升级性</h2><p>当服务集群规模进一步扩大，带动IT治理结构进一步升级，需要实现动态部署，进行流动计算，现有分布式服务架构不会带来阻力。下图是未来可能的一种架构：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/23/分布式服务治理-Dubbo/2018-09-23-18-55-53.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h5 id="节点角色说明-1"><a href="#节点角色说明-1" class="headerlink" title="节点角色说明"></a>节点角色说明</h5><table><thead><tr><th>节点</th><th>角色说明</th></tr></thead><tbody><tr><td><code>Deployer</code></td><td>自动部署服务的本地代理</td></tr><tr><td><code>Repository</code></td><td>仓库用于存储服务应用发布包</td></tr><tr><td><code>Scheduler</code></td><td>调度中心基于访问压力自动增减服务提供者</td></tr><tr><td><code>Admin</code></td><td>统一管理控制台</td></tr><tr><td><code>Registry</code></td><td>服务注册与发现的注册中心</td></tr><tr><td><code>Monitor</code></td><td>统计服务的调用次数和调用时间的监控中心</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Dubbo-是什么&quot;&gt;&lt;a href=&quot;#Dubbo-是什么&quot; class=&quot;headerlink&quot; title=&quot;Dubbo 是什么&quot;&gt;&lt;/a&gt;Dubbo 是什么&lt;/h1&gt;&lt;p&gt;Dubbo是一个分布式的服务框架，提供高性能的以及透明化的RPC远程服务调用解决方法
      
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="dubbo" scheme="https://lincy.online/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>分布式服务zookeeper应用场景</title>
    <link href="https://lincy.online/2018/09/22/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1zookeeper%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>https://lincy.online/2018/09/22/分布式服务zookeeper应用场景/</id>
    <published>2018-09-21T16:01:26.000Z</published>
    <updated>2018-10-23T22:02:37.251Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据发布订阅-配置中心"><a href="#数据发布订阅-配置中心" class="headerlink" title="数据发布订阅/配置中心"></a>数据发布订阅/配置中心</h2><p>实现配置信息的集中式管理和数据的动态更新</p><p>实现配置中心有两种模式：push 、pull。</p><p>zookeeper采用的是推拉相结合的方式。 <strong>客户端向服务器端注册自己需要关注的节点</strong>。<strong>一旦节点数据发生变化，那么服务器端就会向客户端发送watcher事件通知</strong>。客户端收到通知后，主动到服务器端获取更新后的数据。</p><p>配置中心数据要求：</p><ol><li>数据量比较小</li><li>数据内容在运行时会发生动态变更</li><li>集群中的各个机器共享配置</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/22/分布式服务zookeeper应用场景/2018-09-22-00-06-51.png" alt="配置中心实现原理" title>                </div>                <div class="image-caption">配置中心实现原理</div>            </figure><a id="more"></a><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>把ZooKeeper作为一个服务的注册中心，在其中登记每个服务，每台服务器知道自己是属于哪个服务，在服务器启动时，自己向所属服务进行登记，这样，一个树形的服务结构就呈现出来了<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/22/分布式服务zookeeper应用场景/2018-09-22-00-13-00.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>服务的调用者到注册中心里面查找：能提供所需服务的服务器列表，然后自己根据负载均衡算法，从中选取一台服务器进行连接</p><p>调用者取到服务器列表后，就可以缓存到自己内部，省得下次再取，当服务器列表发生变化，例如某台服务器宕机下线，或者新加了服务器，ZooKeeper会自动通知调用者重新获取服务器列表</p><p>由于ZooKeeper并没有内置负载均衡策略，需要调用者自己实现，这个方案只是利用了ZooKeeper的树形数据结构、watcher机制等特性，把ZooKeeper作为服务的注册和变更通知中心，解决了Nginx负载均衡方案带来的问题:<br>（1）配置维护的成本变高，因为节点太多<br>（2）单点故障的风险增加了，因为热点服务的访问量很高，如果这个服务集群内的负载均衡服务出现问题，这个服务将失效</p><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>通常实现分布式锁有几种方式:</p><ol><li>redis。 setNX 存在则会返回0， 不存在</li><li>数据方式去实现, 2种方式<ul><li>创建一个表， 通过索引唯一的方式<br>create table (id , methodname …)   methodname增加唯一索引<br>insert 一条数据XXX   delete 语句删除这条记录</li><li>mysql innodb select for update</li></ul></li></ol><p>zookeeper实现：</p><ul><li>排他锁<br>客户端写入临时节点，利用节点名称不能相同的特性<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/22/分布式服务zookeeper应用场景/2018-09-22-00-22-13.png" alt title>                </div>                <div class="image-caption"></div>            </figure></li><li>共享锁<br>  <strong>利用有序节点特性</strong>。<br>  分布式进程在读写一个共享数据时，可以先在某个公共目录下创建一个有序子目录，然后判断该目录id是否最小。<br>  目录id最小则获得锁并消费共享数据，然后删除该目录。否则则等待，直到自己的目录id成为最小后，才获得锁。<br>  zookeeper所有目录操作事件都可以注册监听器，所以分布式进程不必循环查询子目录判断自己的目录id是否最小，可以注册一个监听器在前一个目录上，监听前一个目录是否被删除。<br><img src="/2018/09/22/分布式服务zookeeper应用场景/2018-09-22-01-11-52.png" alt></li></ul><h2 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h2><h2 id="master-选举"><a href="#master-选举" class="headerlink" title="master 选举"></a>master 选举</h2>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;数据发布订阅-配置中心&quot;&gt;&lt;a href=&quot;#数据发布订阅-配置中心&quot; class=&quot;headerlink&quot; title=&quot;数据发布订阅/配置中心&quot;&gt;&lt;/a&gt;数据发布订阅/配置中心&lt;/h2&gt;&lt;p&gt;实现配置信息的集中式管理和数据的动态更新&lt;/p&gt;
&lt;p&gt;实现配置中心有两种模式：push 、pull。&lt;/p&gt;
&lt;p&gt;zookeeper采用的是推拉相结合的方式。 &lt;strong&gt;客户端向服务器端注册自己需要关注的节点&lt;/strong&gt;。&lt;strong&gt;一旦节点数据发生变化，那么服务器端就会向客户端发送watcher事件通知&lt;/strong&gt;。客户端收到通知后，主动到服务器端获取更新后的数据。&lt;/p&gt;
&lt;p&gt;配置中心数据要求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据量比较小&lt;/li&gt;
&lt;li&gt;数据内容在运行时会发生动态变更&lt;/li&gt;
&lt;li&gt;集群中的各个机器共享配置&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/09/22/分布式服务zookeeper应用场景/2018-09-22-00-06-51.png&quot; alt=&quot;配置中心实现原理&quot; title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;配置中心实现原理&lt;/div&gt;
            &lt;/figure&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="zookeeper" scheme="https://lincy.online/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>分布式协调服务zookeeper</title>
    <link href="https://lincy.online/2018/09/17/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1zookeeper/"/>
    <id>https://lincy.online/2018/09/17/分布式协调服务zookeeper/</id>
    <published>2018-09-17T15:58:44.000Z</published>
    <updated>2018-10-23T22:02:43.237Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分布式环境的特点"><a href="#分布式环境的特点" class="headerlink" title="分布式环境的特点"></a>分布式环境的特点</h3><ul><li>分布式</li><li>并发性<br>程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源。数据库、分布式存储。</li><li>无序性<br>进程间的消息通信，会出现顺序不一致的情况。</li></ul><a id="more"></a><h3 id="分布式面临的问题"><a href="#分布式面临的问题" class="headerlink" title="分布式面临的问题"></a>分布式面临的问题</h3><ul><li>网络通信<br>网络本身不可靠</li><li>网络分区（脑裂）<br>当网络发生异常导致分布式系统中部分节点之间的网络延时不断增大，<strong>最终导致组成分布式架构的所有节点，只有部分节点能够正常通信</strong>。</li><li>三态<br>成功、失败、<strong>超时</strong></li><li>分布式事务<br>ACID（原子性、一致性、隔离性、持久性）</li></ul><h3 id="中心化和去中心化"><a href="#中心化和去中心化" class="headerlink" title="中心化和去中心化"></a>中心化和去中心化</h3><p>冷备或者热备</p><p>分布式架构里面，很多的架构思想采用的是：当集群发生故障的时候，集群中的人群会自动“选举”出一个新的领导。<br>最典型的是： zookeeper / etcd</p><h3 id="CAP-BASE-理论"><a href="#CAP-BASE-理论" class="headerlink" title="CAP/BASE 理论"></a>CAP/BASE 理论</h3><h4 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h4><p>C（一致性Consistency）：所有节点上的数据，时刻保持一致<br>A（可用性Availability）：每个请求都能够收到一个响应，无论响应成功或者失败<br>P（分区容错Partition-tolerance）：表示系统出现脑裂以后，可能导致某些Server与集群中的其他机器失去联系</p><p>CP / AP</p><p>CAP理论仅适用于原子读写的Nosql场景，不适用于数据库系统</p><h4 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h4><p>基于CAP理论，CAP理论并不适用于数据库事务（因为更新一些错误的数据而导致数据出现紊乱，无论什么样的数据库高可用方案都是<br>徒劳） ，虽然XA事务可以保证数据库在分布式系统下的ACID特性，但是会带来性能方面的影响；</p><p>eBay尝试了一种完全不同的套路，放宽了对事务ACID的要求。提出了BASE理论<br><strong>Basically available</strong>  ： 数据库采用分片模式， 把100W的用户数据分布在5个实例上。如果破坏了其中一个实例，仍然可以保证<br>80%的用户可用</p><p><strong>soft-state</strong>：  在基于client-server模式的系统中，server端是否有状态，决定了系统是否具备良好的水平扩展、负载均衡、故障恢复等特性。<br>Server端承诺会维护client端状态数据，这个状态仅仅维持一小段时间, 这段时间以后，server端就会丢弃这个状态，恢复正常状态</p><p><strong>Eventually consistent</strong>：数据的最终一致性</p><h3 id="zookeeper能做什么"><a href="#zookeeper能做什么" class="headerlink" title="zookeeper能做什么"></a>zookeeper能做什么</h3><p>数据的发布/订阅（配置中心:disconf）<br>负载均衡（dubbo利用了zookeeper机制实现负载均衡）<br>命名服务<br>master选举(kafka、hadoop、hbase)<br>分布式队列<br>分布式锁</p><h3 id="zookeeper的特性"><a href="#zookeeper的特性" class="headerlink" title="zookeeper的特性"></a>zookeeper的特性</h3><ul><li><strong>顺序一致性</strong><br>从同一个客户端发起的事务请求，最终会严格按照顺序被应用到zookeeper中。</li><li><strong>原子性</strong><br>所有的事务请求的处理结果在整个集群中的所有机器上的应用情况是一致的，也就是说，要么整个集群中的所有机器都成功应用了某一事务，要么全都不应用</li><li><strong>可靠性</strong><br>一旦服务器成功应用了某一个事务数据，并且对客户端做了响应，那么这个数据在整个集群中一定是同步并且保留下来的。</li><li><strong>实时性</strong><br>一旦一个事务被成功应用，客户端就能够立即从服务器端读取到事务变更后的最新数据状态；（<strong>zookeeper仅仅保证在一定时间内，近实时</strong>）</li></ul><h3 id="zookeeper-安装"><a href="#zookeeper-安装" class="headerlink" title="zookeeper 安装"></a>zookeeper 安装</h3><h4 id="单机环境安装"><a href="#单机环境安装" class="headerlink" title="单机环境安装"></a>单机环境安装</h4><ol><li>下载zookeeper的安装包<br><a href="http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gz" target="_blank" rel="noopener">http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gz</a></li><li>解压zookeeper<br>tar -zxvf zookeeper-3.4.10.tar.gz</li><li>cd 到 ZK_HOME/conf  , copy一份zoo.cfg<br>cp  zoo_sample.cfg  zoo.cfg</li><li>sh zkServer.sh<br>{start|start-foreground|stop|restart|status|upgrade|print-cmd}</li><li>sh zkCli.sh -server  ip:port</li></ol><h4 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h4><p>zookeeper集群, 包含三种角色: <strong>leader / follower /observer</strong></p><p><strong>observer</strong> 是一种特殊的zookeeper节点。可以帮助解决zookeeper的扩展性（如果大量客户端访问我们zookeeper集群，需要增加zookeeper集群机器数量。从而增加zookeeper集群的性能。 导致zookeeper写性能下降， zookeeper的数据变更需要半数以上服务器投票通过。造成网络消耗增加投票成本）</p><ol><li>observer不参与投票。 只接收投票结果。</li><li>不属于zookeeper的关键部位。</li></ol><p><img src="/2018/09/17/分布式协调服务zookeeper/2018-09-18-03-51-36.png" alt></p><p><strong>集群配置</strong></p><p>每一行此配置表示一个集群中的一台服务器。其中id为Server ID，用来标识该机器在集群中的编号。同时，在所在服务器的数据目录（/tmp/zookeeper）下创建一个myid文件，该文件只有一行内容，并且是一个数字，就是对应每台服务器的Server ID数字。</p><p>比如server.1=IP1:2888:3888的myid中的内容就是1。不同服务器的ID需要保持不同，并且和zoo.cfg文件中server.id中的id和myid文件的内容保持一致。id的取值范围为1~255。</p><p>其中，server.id中配置参数的<strong>第一个port是集群中其他机器与Leader之间通信的端口</strong>，<strong>第二个port为当Leader宕机或其他故障时，集群进行重新选举Leader时使用的端口</strong>。</p><p>按照以上相同步骤，配置集群中的其他机器。每个集群的zoo.cfg文件都是相同的，可通过版本控制或其他工具保证每台zookeeper服务器的配置文件相同。集群中每台机器唯一不同的是server.id对应的myid文件中的数字不同。server.id=host:port:port<br>id的取值范围： 1~255； 用id来标识该机器在集群中的机器序号<br><strong>2182是follower节点与leader节点交换信息的端口号；<br>3181表示leader节点挂掉了, 需要一个端口来重新选举。</strong></p><p>server.1=192.168.11.129:2182:3181<br>server.2=192.168.11.131:2182:3181<br>server.3=192.168.11.135:2182:3181</p><p><strong>observer配置</strong></p><p>peerType=observer<br>server.1=192.168.11.129:2182:3181:observer<br>server.2=192.168.11.131:2182:3181<br>server.3=192.168.11.135:2182:3181</p><p><strong>zoo.cfg</strong></p><p>tickTime=2000  zookeeper中最小的时间单位长度 （ms）</p><p>initLimit=10  follower节点启动后与leader节点完成数据同步的时间</p><p>syncLimit=5 leader节点和follower节点进行心跳检测的最大延时时间</p><p>dataDir=/tmp/zookeeper  表示zookeeper服务器存储快照文件的目录</p><p>dataLogDir 表示配置 zookeeper事务日志的存储路径，默认指定在dataDir目录下</p><p>clientPort 表示客户端和服务端建立连接的端口号： 2181</p><h3 id="zookeeper-的一些概念"><a href="#zookeeper-的一些概念" class="headerlink" title="zookeeper 的一些概念"></a>zookeeper 的一些概念</h3><p>zookeeper的数据模型和文件系统类似，每一个节点称为：<strong>znode</strong>.  是zookeeper中的最小数据单元。每一个znode上都可以 <strong>保存数据和挂载子节点</strong>。 从而构成一个层次化的属性结构</p><p><strong>节点特性</strong>：</p><ul><li><strong>持久化节点</strong>  ： 节点创建后会一直存在zookeeper服务器上，直到主动删除</li><li><strong>持久化有序节点</strong> ：每个节点都会为它的一级子节点维护一个顺序</li><li><strong>临时节点</strong> ： 临时节点的生命周期和客户端的会话保持一致。当客户端会话失效，该节点自动清理</li><li><strong>临时有序节点</strong> ： 在临时节点上多了一个顺序性特性</li></ul><h3 id="zookee-的命令操作"><a href="#zookee-的命令操作" class="headerlink" title="zookee 的命令操作"></a>zookee 的命令操作</h3><ol><li>create [-s] [-e] path data acl<br>-s 表示节点是否有序<br>-e 表示是否为临时节点<br>默认情况下，是持久化节点</li></ol><blockquote><p><strong>ACL</strong><br>  zookeeper提供控制节点访问权限的功能，用于有效的保证zookeeper中数据的安全性。避免误操作而导致系统出现重大事故。<br>  CREATE /READ/WRITE/DELETE/ADMIN</p></blockquote><ol start="2"><li>get path [watch]<br>获得指定 path的信息<blockquote><p> <strong>Watcher</strong><br>zookeeper提供了分布式数据发布/订阅,zookeeper允许客户端向服务器注册一个watcher监听。当服务器端的节点触发指定事件的时候会触发watcher。服务端会向客户端发送一个事件通知 <strong>watcher的通知是一次性，一旦触发一次通知后，该watcher就失效</strong></p></blockquote></li></ol><ol start="3"><li><p>set path data [version]<br>修改节点 path对应的data<br>乐观锁的概念<br>数据库里面有一个 version 字段去控制数据行的版本号</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/17/分布式协调服务zookeeper/2018-09-19-22-10-07.png" alt title>                </div>                <div class="image-caption"></div>            </figure></li><li><p>delete path [version]<br>删除节点</p></li></ol><p><strong>stat信息</strong><br>cversion = 0       子节点的版本号<br>aclVersion = 0     表示acl的版本号，修改节点权限<br>dataVersion = 1    表示的是当前节点数据的版本号</p><p>czxid    节点被创建时的事务ID<br>mzxid   节点最后一次被更新的事务ID<br>pzxid    当前节点下的子节点最后一次被修改时的事务ID</p><p>ctime = Sat Aug 05 20:48:26 CST 2017<br>mtime = Sat Aug 05 20:48:50 CST 2017</p><blockquote><p>cZxid = 0x500000015<br>ctime = Sat Aug 05 20:48:26 CST 2017<br>mZxid = 0x500000016<br>mtime = Sat Aug 05 20:48:50 CST 2017<br>pZxid = 0x500000015<br>cversion = 0<br>dataVersion = 1<br>aclVersion = 0<br>ephemeralOwner = 0x0   创建临时节点的时候，会有一个sessionId 。 该值存储的就是这个sessionid<br>dataLength = 3    数据值长度<br>numChildren = 0  子节点数</p></blockquote><h3 id="Java-API"><a href="#Java-API" class="headerlink" title="Java API"></a>Java API</h3><p>权限控制模式<br>schema：授权对象<br>ip     : 192.168.1.1<br>Digest  : username:password<br>world  : 开放式的权限控制模式，数据节点的访问权限对所有用户开放。 world:anyone<br>super  ：超级用户，可以对zookeeper上的数据节点进行操作</p><p>连接状态<br>KeeperStat.Expired  在一定时间内客户端没有收到服务器的通知， 则认为当前的会话已经过期了。<br>KeeperStat.Disconnected  断开连接的状态<br>KeeperStat.SyncConnected  客户端和服务器端在某一个节点上建立连接，并且完成一次version、zxid同步<br>KeeperStat.authFailed  授权失败<br>事件类型<br>NodeCreated  当节点被创建的时候，触发<br>NodeChildrenChanged  表示子节点被创建、被删除、子节点数据发生变化（子节点删除、新增的时候才会触发，子节点数据变更不会触发）<br>NodeDataChanged    节点数据发生变化<br>NodeDeleted        节点被删除<br>None   客户端和服务器端连接状态发生变化的时候，事件类型就是None</p><h3 id="zookeeper的实际应用场景"><a href="#zookeeper的实际应用场景" class="headerlink" title="zookeeper的实际应用场景"></a>zookeeper的实际应用场景</h3><ul><li>订阅发布<br> watcher机制<br> 统一配置管理（disconf）</li><li>分布式锁<br> redis<br> zookeeper<br> 数据库   </li></ul><ul><li>负载均衡</li><li>ID生成器</li><li>分布式队列</li><li>统一命名服务</li><li>master选举</li></ul><ul><li>master选举</li></ul><hr><h3 id="zookeeper-集群角色"><a href="#zookeeper-集群角色" class="headerlink" title="zookeeper 集群角色"></a>zookeeper 集群角色</h3><ul><li><p>leader</p><ol><li>事务请求的唯一调度者和处理者，保证集群事务处理的顺序性</li><li>集群内部各个服务器的调度者</li></ol></li><li><p>follower</p><ol><li>处理客户端非事务请求，以及转发事务请求给leader服务器</li><li>参与事务请求提议（proposal）的投票（客户端的一个事务请求，需要半数服务器投票通过以后才能通知leader commit； leader会发起一个提案，要求follower投票）</li><li>参与leader选举的投票</li></ol></li><li><p>observer<br>观察zookeeper集群中最新状态的变化并将这些状态同步到observer服务器上。增加observer不影响集群中事务处理能力，同时还能提升集群的非事务处理能力</p></li></ul><!-- more --><h3 id="zookeeper-集群组成"><a href="#zookeeper-集群组成" class="headerlink" title="zookeeper 集群组成"></a>zookeeper 集群组成</h3><p>zk集群要求集群的机器数为奇数（2n+1），并且任何时刻，<strong>存活的机器必须大于n+1，否则集群挂掉</strong>；</p><h3 id="leader选举"><a href="#leader选举" class="headerlink" title="leader选举"></a>leader选举</h3><p>三种算法：</p><ul><li>leaderElection</li><li>AuthFastLeaderElection </li><li>FastLeaderElection（默认）</li></ul><h4 id="FastLeaderElection-选举流程"><a href="#FastLeaderElection-选举流程" class="headerlink" title="FastLeaderElection 选举流程"></a>FastLeaderElection 选举流程</h4><p>几个概念:</p><ul><li>serverid : 在配置server集群的时候，给定服务器的标识id（myid）</li><li>zxid  : 服务器在运行时产生的数据ID， zxid的值越大，表示数据越新</li><li>Epoch: 选举的轮数</li><li>server的状态：Looking、 Following、Observering、Leading</li></ul><p>选举流程，第一次初始化启动的时候服务器状态为Looking</p><ul><li>所有在集群中的server都会 <strong>推荐自己为leader</strong>，然后 <strong>把（myid、zxid、epoch）作为广播信息</strong>，广播给集群中的其他server, 然后 <strong>等待其他服务器返回</strong></li><li>每个服务器都会 <strong>接收来自集群中的其他服务器的投票</strong>。集群中的每个服务器在接受到投票后，开始判断投票的有效性<ul><li>判断逻辑时钟(Epoch) ，<strong>如果Epoch大于自己当前的Epoch，说明自己保存的Epoch是过期</strong>。更新Epoch，同时clear其他服务器发送过来的选举数据。判断是否需要更新当前自己的选举情况</li><li>如果Epoch小于目前的Epoch，说明对方的epoch过期了，也就意味着对方服务器的选举轮数是过期的。这个时候，只需要讲自己的信息发送给对方</li><li>如果epoch等于目前的epoch，根据规则来判断是否有资格获得leader<ul><li>接收来自其他服务器的投票后，针对每一个投票，都需要将别人的投票和自己的投票进行PK zxid，zxid最大的服务器优先</li></ul></li></ul></li></ul><p><img src="/2018/09/17/分布式协调服务zookeeper/zookeeper几个原理分析/2018-09-22-11-33-01.png" alt></p><hr><h3 id="ZAB协议"><a href="#ZAB协议" class="headerlink" title="ZAB协议"></a>ZAB协议</h3><p>ZAB协议（Zookeeper atomic broadcast），基于paxos协议的一个改进。</p><ol><li>在zookeeper 的主备模式下，通过zab协议来保证集群中各个副本数据的一致性</li><li>zookeeper使用的是单一的主进程来接收并处理所有的事务请求，并采用zab协议， 把数据的状态变更以事务请求的形式广播到其他的节点</li><li>zab协议在主备模型架构中，保证了同一时刻只能有一个主进程来广播服务器的状态变更</li><li>所有的事务请求必须由全局唯一的服务器来协调处理，这个的服务器叫leader，其他的叫follower。 leader节点主要负责把客户端的事务请求转化成一个事务提议（proposal），并分发给集群中的所有follower节点, 再等待所有follower节点的反馈。一旦超过半数服务器进行了正确的反馈，那么leader就会commit这条消息</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/17/分布式协调服务zookeeper/2018-09-23-15-46-10.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h4 id="ZAB协议的工作原理"><a href="#ZAB协议的工作原理" class="headerlink" title="ZAB协议的工作原理"></a>ZAB协议的工作原理</h4><ol><li>什么情况下zab协议会进入 <strong>崩溃恢复</strong> 模式<ol><li>当服务器启动时</li><li>当leader服务器出现网络中断、崩溃或者重启的情况</li><li>集群中已经不存在过半的服务器与该leader保持正常通信</li></ol></li><li>zab协议进入崩溃恢复模式会做什么<ol><li><strong>当leader出现问题，zab协议进入崩溃恢复模式，并且选举出新的leader。当新的leader选举出来以后，如果集群中已经有过半机器完成了leader服务器的状态同（数据同步），退出崩溃恢复</strong>，进入 <strong>消息广播模式</strong></li><li>当新的机器加入到集群中的时候，如果已经存在leader服务器，那么新加入的服务器就会自觉进入数据恢复模式，找到leader进行数据同步</li></ol></li></ol><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>假设一个事务在leader服务器被提交了，并且已经有过半的follower返回了ack。 在leader节点把commit消息发送给folower机器之前, leader服务器挂了怎么办?</p><blockquote><p>zab协议，一定需要保证已经被leader提交的事务也能够被所有follower提交<br>zab协议需要保证，在崩溃恢复过程中跳过哪些已经被丢弃的事务</p></blockquote><h3 id="zookeeper-数据存储"><a href="#zookeeper-数据存储" class="headerlink" title="zookeeper 数据存储"></a>zookeeper 数据存储</h3><p>内存数据和磁盘数据，zookeeper会定时吧数据存储在磁盘上</p><p>DataDir: 存储数据快照</p><blockquote><p>快照： 存储某一个时刻全量的内存数据内容</p></blockquote><p>DataLogDir: 存储事务日志<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/09/17/分布式协调服务zookeeper/2018-09-23-17-13-05.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>查看事务日志的命令<br>java -cp :~/zookeeper-3.4.10/lib/slf4j-api-1.6.1.jar:~/zookeeper-3.4.10/zookeeper-3.4.10.jar org.apache.zookeeper.server.LogFormatter log.200000001</p><p>zookeeper 有三种日志<br>zookeeper.out  //运行日志<br>快照     存储某一时刻的全量数据<br>事务日志 事务操作的日志记录</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;分布式环境的特点&quot;&gt;&lt;a href=&quot;#分布式环境的特点&quot; class=&quot;headerlink&quot; title=&quot;分布式环境的特点&quot;&gt;&lt;/a&gt;分布式环境的特点&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;分布式&lt;/li&gt;
&lt;li&gt;并发性&lt;br&gt;程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源。数据库、分布式存储。&lt;/li&gt;
&lt;li&gt;无序性&lt;br&gt;进程间的消息通信，会出现顺序不一致的情况。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="zookeeper" scheme="https://lincy.online/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>分布式通信协议-HTTP</title>
    <link href="https://lincy.online/2018/08/30/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE-HTTP/"/>
    <id>https://lincy.online/2018/08/30/分布式通信协议-HTTP/</id>
    <published>2018-08-30T15:34:31.000Z</published>
    <updated>2018-10-23T22:01:47.388Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HTTP协议概述"><a href="#HTTP协议概述" class="headerlink" title="HTTP协议概述"></a>HTTP协议概述</h2><ul><li>客户端和服务端<br><img src="/2018/08/30/分布式通信协议-HTTP/2018-08-30-23-36-33.png" alt></li></ul><a id="more"></a><ul><li>资源<br>html/文本、word、avi等等</li><li>媒体类型<br>MIME类型。text/html、image/jpeg、application/json等等</li><li><p>URI和URL<br>URI：服务器资源的名字。index.html<br>URL:网络资源描述</p><blockquote><p><a href="http://lincy.online/2018/08/30/分布式通信协议-HTTP">http://lincy.online/2018/08/30/分布式通信协议-HTTP</a></p></blockquote><p>  schema: http/https/ftp<br>  host: web服务器的IP地址或域名。<br>  path: 资源访问路径。<br>  query-string: 查询参数。</p></li><li><p>method，方法<br>get/put/delete/post/patch/head</p></li><li><p>报文</p></li><li>状态码<br>  1XX    提示信息<br>  2XX    成功<br>  3XX    重定向<br>  4XX    客户端错误<br>  5XX    服务器端的错误</li><li>缓存</li></ul><h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><h3 id="https工作原理"><a href="#https工作原理" class="headerlink" title="https工作原理"></a>https工作原理</h3><p><img src="/2018/08/30/分布式通信协议-HTTP/2018-08-30-23-53-32.png" alt></p><p>第一步，使用对称加解密<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-30-23-54-25.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>第二步，密钥是公开的，所有的客户端都可以拿到<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-30-23-55-42.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>第三步 针对不同的客户端使用不同的密钥<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-30-23-55-59.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>问题：协商过程是没有加密的，所以还会出现被截断的问题</p><p>第四步：使用非对称加密（公钥、私钥）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-31-00-03-36.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>客户端如何拿到公钥：</p><ol><li>服务器端把公钥发送给每一个客户端</li><li>服务器端把公钥放到远程服务器，客户端可以请求到</li><li>让浏览器保存所有的公钥（不现实）</li></ol><p>第五步 <strong>公钥被调包的问题按照上面的方案，永远存在。</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-31-00-18-51.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>第六步：使用第三方机构来解决</p><p>通过第三方机构，使用第三方机构的私钥对我们【需要传输的公钥】进行加密<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-31-00-23-35.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-08-31-00-26-41.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>问题：数字证书有可能颁发给了窃密者</p><p>第七步：<br>数字证里面包含的内容：<br> 公司信息、网站信息、数字证书的算法、公钥</p><blockquote><p><a href="http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html</a></p></blockquote><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议-HTTP/2018-09-22-10-53-25.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>https握手过程：</p><ol><li>客户端发起一个https请求<br>a)    客户端支持的加密方式<br>b)    客户端生成的随机数（第一个随机数）<br>c)  协议版本号</li></ol><ol start="2"><li><p>服务端收到请求后，拿到随机数，返回<br>a)    证书（颁发机构（CA）、证书内容本身的数字签名（使用第三方机构的私钥加密）、证书持有者的公钥、证书签名用到的hash算法）<br>b)    生成一个随机数，返回给客户端（第二个随机数）</p></li><li><p>客户端拿到证书以后做验证<br>a)    根据颁发机构找到本地的跟证书<br>b)    根据CA得到根证书的公钥，通过公钥对数字签名解密，得到证书的内容摘要 A<br>c)    用证书提供的算法对证书内容进行摘要，得到摘要 B<br>d)    通过A和B的对比，也就是验证数字签名</p></li><li><p>验证通过以后，生成一个随机数（第三个随机数），通过证书内的公钥对这个随机数加密，发送给服务器端</p></li><li><p>（随机数1+2+3）通过对称加密得到一个密钥。（会话密钥）</p></li><li><p>通过会话密钥对内容进行对称加密传输</p></li></ol><h2 id="RESTful"><a href="#RESTful" class="headerlink" title="RESTful"></a>RESTful</h2><ol><li>在REST中，一切的内容都被认为是一种资源</li><li>每个资源都由URI唯一标识</li><li>使用统一的接口处理资源请求（POST/GET/PUT/DELETE/HEAD）</li><li>无状态</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;HTTP协议概述&quot;&gt;&lt;a href=&quot;#HTTP协议概述&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议概述&quot;&gt;&lt;/a&gt;HTTP协议概述&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;客户端和服务端&lt;br&gt;&lt;img src=&quot;/2018/08/30/分布式通信协议-HTTP/2018-08-30-23-36-33.png&quot; alt&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="分布式" scheme="https://lincy.online/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式通信-序列化</title>
    <link href="https://lincy.online/2018/08/30/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1-%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://lincy.online/2018/08/30/分布式通信-序列化/</id>
    <published>2018-08-30T14:06:59.000Z</published>
    <updated>2018-10-23T22:02:00.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Java序列化机制-——-Serialize接口"><a href="#Java序列化机制-——-Serialize接口" class="headerlink" title="Java序列化机制 —— Serialize接口"></a>Java序列化机制 —— Serialize接口</h2><ul><li>数据结果大、传输效率低</li><li>不能跨语言<a id="more"></a><h3 id="如何实现Java序列化操作："><a href="#如何实现Java序列化操作：" class="headerlink" title="如何实现Java序列化操作："></a>如何实现Java序列化操作：</h3></li><li>实现Serializable接口</li><li>ObjectInputStream： 读取字节数据转换成对象</li><li>ObjectOuputStream： 将对象转换成直接数据</li><li>serialVersionUID的作用：保证序列化的对象和反序列化后的对象是同一个，对类的签名。</li><li>transient 关键字：不参与序列化。<h3 id="父子类问题"><a href="#父子类问题" class="headerlink" title="父子类问题"></a>父子类问题</h3>如果父类没有实现序列化，而子类实现列序列化。那么父类中的成员没办法做序列化操作</li></ul><h3 id="序列化的存储规则"><a href="#序列化的存储规则" class="headerlink" title="序列化的存储规则"></a>序列化的存储规则</h3><p>对同一个对象进行多次写入，打印出的第一次存储结果和第二次存储结果，只多了5个字节的引用关系, 并不会导致文件累加。</p><h2 id="XML对象序列化"><a href="#XML对象序列化" class="headerlink" title="XML对象序列化"></a>XML对象序列化</h2><ul><li>跨语言，容易理解</li><li>基于XML的SOAP协议和对应的WebService框架在很长一段时间成为主流的技术。</li></ul><h2 id="基于JSON的HTTP-REST接口"><a href="#基于JSON的HTTP-REST接口" class="headerlink" title="基于JSON的HTTP REST接口"></a>基于JSON的HTTP REST接口</h2><ul><li>相比XML更简单易用，基本上取代了复杂的Web Service接口，成为分布式框架中远程通信的首要选择。</li><li>仍然存在占用空间大、性能低的问题。</li></ul><h2 id="主流的序列化技术"><a href="#主流的序列化技术" class="headerlink" title="主流的序列化技术"></a>主流的序列化技术</h2><ul><li>JSON</li><li>XML</li><li>Protobuf<ul><li>字节数小</li><li>速度快</li></ul></li><li>Hessian<ul><li>序列化速度比protobuf更快，但是字节数更大</li></ul></li><li>ProtoStuff</li><li>MsgPack</li><li>thrift</li><li>FST</li><li>Avro</li></ul><p><img src="/2018/08/30/分布式通信-序列化/2018-08-30-23-21-02.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Java序列化机制-——-Serialize接口&quot;&gt;&lt;a href=&quot;#Java序列化机制-——-Serialize接口&quot; class=&quot;headerlink&quot; title=&quot;Java序列化机制 —— Serialize接口&quot;&gt;&lt;/a&gt;Java序列化机制 —— Serialize接口&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据结果大、传输效率低&lt;/li&gt;
&lt;li&gt;不能跨语言&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="分布式" scheme="https://lincy.online/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式通信协议</title>
    <link href="https://lincy.online/2018/08/30/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"/>
    <id>https://lincy.online/2018/08/30/分布式通信协议/</id>
    <published>2018-08-29T18:26:33.000Z</published>
    <updated>2018-10-23T22:01:54.990Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h1><h2 id="tcp-ip"><a href="#tcp-ip" class="headerlink" title="tcp/ip"></a>tcp/ip</h2><ul><li>TCP五层模型<br><img src="/2018/08/30/分布式通信协议/2018-08-30-02-31-04.png" alt></li><li>OSI七层<ul><li>OSI模型多了表达层、会话层</li></ul></li></ul><a id="more"></a><h3 id="tcp三次握手"><a href="#tcp三次握手" class="headerlink" title="tcp三次握手"></a>tcp三次握手</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议/2018-08-30-02-32-52.png" alt title>                </div>                <div class="image-caption"></div>            </figure><ul><li>第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。</li><li>第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。</li><li>第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。</li></ul><h3 id="四次挥手协议"><a href="#四次挥手协议" class="headerlink" title="四次挥手协议"></a>四次挥手协议</h3><p>三次握手耳熟能详，四次挥手估计就听得比较少了，所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议/2018-08-30-02-37-26.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h3 id="udp协议"><a href="#udp协议" class="headerlink" title="udp协议"></a>udp协议</h3><h3 id="tcp通信原理"><a href="#tcp通信原理" class="headerlink" title="tcp通信原理"></a>tcp通信原理</h3><p>首先，对于TCP通信来说，每个TCP Socket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的<strong>滑动窗口</strong>就是依赖于这两个独立的Buffer和该Buffer的填充状态。 </p><p>接收缓冲区把数据缓存到内核，若应用进程一直没有调用Socket的read方法进行读取，那么该数据会一直被缓存在接收缓冲区内。不管进程是否读取Socket，对端发来的数据都会经过内核接收并缓存到Socket的内核接收缓冲区。<br>read索要做的工作，就是把内核接收缓冲区中的数据复制到应用层用户的Buffer里。</p><p>进程调用Socket的send发送数据的时候，一般情况下是讲数据从应用层用户的Buffer里复制到Socket的内核发送缓冲区，然后send就会在上层返回。换句话说，send返回时，数据不一定会被发送到对端。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议/2018-08-30-02-42-03.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h4 id="滑动窗口协议"><a href="#滑动窗口协议" class="headerlink" title="滑动窗口协议"></a>滑动窗口协议</h4><p>发送方和接收方都会维护一个数据帧的序列，这个序列被称作窗口。发送方的窗口大小由接收方确认，目的是控制发送速度，以免接收方的缓存不够大导致溢出，同时控制流量也可以避免网络拥塞。<br>下面图中的4,5,6号数据帧已经被发送出去，但是未收到关联的ACK，7,8,9帧则是等待发送。可以看出发送端的窗口大小为6，这是由接受端告知的（事实上必须考虑拥塞窗口cwnd，这里暂且考虑cwnd&gt;rwnd）。此时如果发送端收到4号ACK，则窗口的左边缘向右收缩，窗口的右边缘则向右扩展，此时窗口就向前“滑动了”，即数据帧10也可以被发送<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议/2018-08-30-02-47-14.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>明白了Socket读写数据的底层原理，我们就很容易理解“阻塞模式”：对于读取Socket数据的过程而言，如果接收缓冲区为空，则调用Socket的read方法的线程会阻塞，知道有数据进入接收缓冲区；而对于写数据到Socket中的线程来说，如果待发送的数据长度大于发送缓冲区空余长度，则会阻塞在write方法上，等待发送缓冲区的报文被发送到网络上，然后继续发送下一段数据，循环上述过程直到数据都被写入到发送缓冲区为止</p><p><strong>从前面分析的过程来看，传统的Socket阻塞模式直接导致每个Socket都必须绑定一个线程来操作数据，参与通信的任意一方如果处理数据的速度较慢，会直接拖累到另一方，导致另一方的线程不得不浪费大量的时间在I/O等待上，所以这就是Socket阻塞模式的“缺陷”。</strong> 但是这种模式在少量的TCP连接通信的情况下，双方都可以快速的传输数据，这个时候的性能是最高的。</p><p>BIO（同步阻塞）<br>NIO（同步非阻塞）<br>AIO（异步非阻塞）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议/2018-08-30-02-54-54.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="Multicst-组播"><a href="#Multicst-组播" class="headerlink" title="Multicst(组播)"></a>Multicst(组播)</h3><ul><li>单播</li><li>广播</li><li>组播</li></ul><p><img src="/2018/08/30/分布式通信协议/2018-08-30-02-49-52.png" alt="tcp/ip协议分层"></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式通信协议/2018-08-30-02-50-01.png" alt="java api socket操作" title>                </div>                <div class="image-caption">java api socket操作</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;网络协议&quot;&gt;&lt;a href=&quot;#网络协议&quot; class=&quot;headerlink&quot; title=&quot;网络协议&quot;&gt;&lt;/a&gt;网络协议&lt;/h1&gt;&lt;h2 id=&quot;tcp-ip&quot;&gt;&lt;a href=&quot;#tcp-ip&quot; class=&quot;headerlink&quot; title=&quot;tcp/ip&quot;&gt;&lt;/a&gt;tcp/ip&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;TCP五层模型&lt;br&gt;&lt;img src=&quot;/2018/08/30/分布式通信协议/2018-08-30-02-31-04.png&quot; alt&gt;&lt;/li&gt;
&lt;li&gt;OSI七层&lt;ul&gt;
&lt;li&gt;OSI模型多了表达层、会话层&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="分布式" scheme="https://lincy.online/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式架构概述</title>
    <link href="https://lincy.online/2018/08/30/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0/"/>
    <id>https://lincy.online/2018/08/30/分布式架构概述/</id>
    <published>2018-08-29T17:00:40.000Z</published>
    <updated>2018-10-23T22:02:16.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="特点：高并发、海量数据"><a href="#特点：高并发、海量数据" class="headerlink" title="特点：高并发、海量数据"></a>特点：高并发、海量数据</h1><h1 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h1><ul><li>任务分解</li><li>节点通信</li></ul><a id="more"></a><h1 id="分布式架构发展"><a href="#分布式架构发展" class="headerlink" title="分布式架构发展"></a>分布式架构发展</h1><h2 id="第一版"><a href="#第一版" class="headerlink" title="第一版"></a>第一版</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-01-19-59.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h2 id="第二版"><a href="#第二版" class="headerlink" title="第二版"></a>第二版</h2><p>单机负载越来越高，数据库和应用服务器分离<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-01-28-45.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="第三版"><a href="#第三版" class="headerlink" title="第三版"></a>第三版</h2><p>应用服务器做集群<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-01-29-21.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>引入问题:</p><ul><li>session共享<ul><li>session sticky</li><li>session replication</li><li>session 集中存储（db、缓存）</li><li>cookie (保存在cookie，不保存在服务端)<ul><li>access_token(userid/token/timestamp) </li></ul></li></ul></li><li>请求转发<h2 id="第四版"><a href="#第四版" class="headerlink" title="第四版"></a>第四版</h2>数据库高性能操作<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-01-47-22.png" alt title>                </div>                <div class="image-caption"></div>            </figure>引入问题：</li><li>数据库读写分离</li><li>数据库的数据同步</li><li>数据库路由（mycat）</li></ul><h2 id="第五版"><a href="#第五版" class="headerlink" title="第五版"></a>第五版</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-01-49-51.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>引入问题：</p><ul><li>搜索引擎的索引数据同步？实时增量同步？定时全量同步?</li></ul><h2 id="第六版"><a href="#第六版" class="headerlink" title="第六版"></a>第六版</h2><p>用户无上限，解决方式：</p><ul><li>缓存</li><li>限流</li><li>降级</li></ul><p><img src="/2018/08/30/分布式架构概述/2018-08-30-01-53-42.png" alt></p><h2 id="第七版"><a href="#第七版" class="headerlink" title="第七版"></a>第七版</h2><p>数据库的水平/垂直拆分<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-01-56-59.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="第八版"><a href="#第八版" class="headerlink" title="第八版"></a>第八版</h2><p><strong>应用拆分</strong></p><ul><li>SOA</li><li>微服务</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/08/30/分布式架构概述/2018-08-30-02-05-42.png" alt title>                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;特点：高并发、海量数据&quot;&gt;&lt;a href=&quot;#特点：高并发、海量数据&quot; class=&quot;headerlink&quot; title=&quot;特点：高并发、海量数据&quot;&gt;&lt;/a&gt;特点：高并发、海量数据&lt;/h1&gt;&lt;h1 id=&quot;什么是分布式&quot;&gt;&lt;a href=&quot;#什么是分布式&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式&quot;&gt;&lt;/a&gt;什么是分布式&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;任务分解&lt;/li&gt;
&lt;li&gt;节点通信&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="分布式" scheme="https://lincy.online/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>HashMap源码解析</title>
    <link href="https://lincy.online/2018/07/12/HashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>https://lincy.online/2018/07/12/HashMap源码解析/</id>
    <published>2018-07-12T12:08:26.000Z</published>
    <updated>2018-07-17T17:10:27.404Z</updated>
    
    <content type="html"><![CDATA[<p>本文基于JDK1.8</p><h1 id="HashMap-数据结构"><a href="#HashMap-数据结构" class="headerlink" title="HashMap 数据结构"></a>HashMap 数据结构</h1><p>在JDK1.8中HashMap进行了优化，桶除了链表，还新增了红黑树的数据结构，加快查找速度<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/07/12/HashMap源码解析/2018-07-12-20-31-38.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h1 id="类声明"><a href="#类声明" class="headerlink" title="类声明"></a>类声明</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/07/12/HashMap源码解析/2018-07-12-20-16-00.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h1 id="HashMap-构造函数"><a href="#HashMap-构造函数" class="headerlink" title="HashMap 构造函数"></a>HashMap 构造函数</h1><ul><li>initialCapacity：初始容量。</li><li>loadFactor（默认值为0.75）：负载因子。负载因子表示哈希表在扩充容量之前可以达到多满的尺度，负载因子越大，填充程度越高。</li></ul><pre><code class="Java">    public HashMap()    public HashMap(int initialCapacity)    public HashMap(int initialCapacity, float loadFactor) </code></pre><p>看一下第三个构造函数：</p><pre><code class="java">    public HashMap(int initialCapacity, float loadFactor) {        if (initialCapacity &lt; 0)            throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +                                               initialCapacity);        if (initialCapacity &gt; MAXIMUM_CAPACITY)            initialCapacity = MAXIMUM_CAPACITY;        if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))            throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +                                               loadFactor);        this.loadFactor = loadFactor;        this.threshold = tableSizeFor(initialCapacity);    }</code></pre><p>shreshold指HashMap容量达到多少时，HashMap会扩容，根据以上描述，可以很简单的认为 shreshold = capacity * loadFactor。 在初始化HashMap时shreshold先被赋值为initial capacity。</p><pre><code class="java">    static final int tableSizeFor(int cap) {        int n = cap - 1;        n |= n &gt;&gt;&gt; 1;        n |= n &gt;&gt;&gt; 2;        n |= n &gt;&gt;&gt; 4;        n |= n &gt;&gt;&gt; 8;        n |= n &gt;&gt;&gt; 16;        return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;    }</code></pre><h1 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h1><pre><code class="java">    public V put(K key, V value) {        return putVal(hash(key), key, value, false, true);    }    /**     * Implements Map.put and related methods     *     * @param hash hash for key     * @param key the key     * @param value the value to put     * @param onlyIfAbsent if true, don&#39;t change existing value     * @param evict if false, the table is in creation mode.     * @return previous value, or null if none     */    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,                   boolean evict) {        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;        if ((tab = table) == null || (n = tab.length) == 0)            // 如果HashMap为空，则初始化            n = (tab = resize()).length;        if ((p = tab[i = (n - 1) &amp; hash]) == null)            tab[i] = newNode(hash, key, value, null);        else {            Node&lt;K,V&gt; e; K k;            if (p.hash == hash &amp;&amp;                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))                e = p;            else if (p instanceof TreeNode)                e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);            else {                for (int binCount = 0; ; ++binCount) {                    if ((e = p.next) == null) {                        p.next = newNode(hash, key, value, null);                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st                            treeifyBin(tab, hash);                        break;                    }                    if (e.hash == hash &amp;&amp;                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                        break;                    p = e;                }            }            if (e != null) { // existing mapping for key                V oldValue = e.value;                if (!onlyIfAbsent || oldValue == null)                    e.value = value;                afterNodeAccess(e);                return oldValue;            }        }        ++modCount;        if (++size &gt; threshold)            resize();        afterNodeInsertion(evict);        return null;    }</code></pre><h1 id="resize-方法"><a href="#resize-方法" class="headerlink" title="resize()方法"></a>resize()方法</h1><p>初始化表大小或扩容</p><pre><code class="java">    final Node&lt;K,V&gt;[] resize() {        Node&lt;K,V&gt;[] oldTab = table;        int oldCap = (oldTab == null) ? 0 : oldTab.length;        int oldThr = threshold;        int newCap, newThr = 0;        // capacity &gt; 0 的情况，对应需要扩容的情景        if (oldCap &gt; 0) {            if (oldCap &gt;= MAXIMUM_CAPACITY) {                // 如果原先容量已经到了最大值，则无法扩容，直接返回                threshold = Integer.MAX_VALUE;                return oldTab;            }            else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;                     oldCap &gt;= DEFAULT_INITIAL_CAPACITY)                // shreshold翻倍                newThr = oldThr &lt;&lt; 1;         }        // capacity==0的情况，HashMap刚刚经过初始化还没有值的情景        else if (oldThr &gt; 0)             // 构造函数（2）（3）初始化HashMap时threshold被设定为initialCapacity            newCap = oldThr;        else {               // zero initial threshold signifies using defaults            //threshold==0, 使用默认配置，对应无参构造函数（1）的情景            newCap = DEFAULT_INITIAL_CAPACITY;            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);        }        if (newThr == 0) {            float ft = (float)newCap * loadFactor;            newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?                      (int)ft : Integer.MAX_VALUE);        }        threshold = newThr;        @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;})            Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];        table = newTab;        if (oldTab != null) {            for (int j = 0; j &lt; oldCap; ++j) {                Node&lt;K,V&gt; e;                if ((e = oldTab[j]) != null) {                    oldTab[j] = null;                    if (e.next == null)                        // 桶中只有一个元素                        newTab[e.hash &amp; (newCap - 1)] = e;                    else if (e instanceof TreeNode)                        // 桶为红黑树                        ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);                    else { // preserve order                        // 桶为数组                        Node&lt;K,V&gt; loHead = null, loTail = null;                        Node&lt;K,V&gt; hiHead = null, hiTail = null;                        Node&lt;K,V&gt; next;                        do {                            next = e.next;                            if ((e.hash &amp; oldCap) == 0) {                                if (loTail == null)                                    loHead = e;                                else                                    loTail.next = e;                                loTail = e;                            }                            else {                                if (hiTail == null)                                    hiHead = e;                                else                                    hiTail.next = e;                                hiTail = e;                            }                        } while ((e = next) != null);                        if (loTail != null) {                            loTail.next = null;                            newTab[j] = loHead;                        }                        if (hiTail != null) {                            hiTail.next = null;                            newTab[j + oldCap] = hiHead;                        }                    }                }            }        }        return newTab;    }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文基于JDK1.8&lt;/p&gt;
&lt;h1 id=&quot;HashMap-数据结构&quot;&gt;&lt;a href=&quot;#HashMap-数据结构&quot; class=&quot;headerlink&quot; title=&quot;HashMap 数据结构&quot;&gt;&lt;/a&gt;HashMap 数据结构&lt;/h1&gt;&lt;p&gt;在JDK1.8中Hash
      
    
    </summary>
    
    
      <category term="JDK源码" scheme="https://lincy.online/tags/JDK%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>[转载]从实际案例聊聊Java应用的GC优化</title>
    <link href="https://lincy.online/2018/04/21/%E8%BD%AC%E8%BD%BD-%E4%BB%8E%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B%E8%81%8A%E8%81%8AJava%E5%BA%94%E7%94%A8%E7%9A%84GC%E4%BC%98%E5%8C%96/"/>
    <id>https://lincy.online/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/</id>
    <published>2018-04-20T23:55:37.000Z</published>
    <updated>2018-10-22T03:24:15.194Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>美团技术团队： <a href="https://tech.meituan.com/jvm_optimize.html" target="_blank" rel="noopener">https://tech.meituan.com/jvm_optimize.html</a></p></blockquote><p>当Java程序性能达不到既定目标，且其他优化手段都已经穷尽时，通常需要调整垃圾回收器来进一步提高性能，称为GC优化。但GC算法复杂，影响GC性能的参数众多，且参数调整又依赖于应用各自的特点，这些因素很大程度上增加了GC优化的难度。即便如此，GC调优也不是无章可循，仍然有一些通用的思考方法。本篇会介绍这些通用的GC优化策略和相关实践案例，主要包括如下内容：</p><blockquote><p>优化前准备: 简单回顾JVM相关知识、介绍GC优化的一些通用策略。<br>优化方法: 介绍调优的一般流程：明确优化目标→优化→跟踪优化结果。<br>优化案例: 简述笔者所在团队遇到的GC问题以及优化方案。</p></blockquote><a id="more"></a><h1 id="一、优化前的准备"><a href="#一、优化前的准备" class="headerlink" title="一、优化前的准备"></a>一、优化前的准备</h1><h2 id="GC优化需知"><a href="#GC优化需知" class="headerlink" title="GC优化需知"></a>GC优化需知</h2><p>为了更好地理解本篇所介绍的内容，你需要了解如下内容。</p><ol><li><p>GC相关基础知识，包括但不限于：<br>a) GC工作原理。<br>b) 理解新生代、老年代、晋升等术语含义。<br>c) 可以看懂GC日志。</p></li><li><p>GC优化不能解决一切性能问题，它是最后的调优手段。</p></li></ol><p>如果对第一点中提及的知识点不是很熟悉，可以先阅读小结-JVM基础回顾；如果已经很熟悉，可以跳过该节直接往下阅读。</p><h2 id="JVM基础回顾"><a href="#JVM基础回顾" class="headerlink" title="JVM基础回顾"></a>JVM基础回顾</h2><h3 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h3><p>简单介绍一下JVM内存结构和常见的垃圾回收器。</p><p>当代主流虚拟机（Hotspot VM）的垃圾回收都采用“分代回收”的算法。“分代回收”是基于这样一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。</p><p>Hotspot VM将内存划分为不同的物理区，就是“分代”思想的体现。如图所示，JVM内存主要由新生代、老年代、永久代构成。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-00-37.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>① 新生代（Young Generation）：大多数对象在新生代中被创建，其中很多对象的生命周期很短。每次新生代的垃圾回收（又称Minor GC）后只有少量对象存活，所以选用复制算法，只需要少量的复制成本就可以完成回收。</p><p>新生代内又分三个区：一个Eden区，两个Survivor区（一般而言），大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到两个Survivor区（中的一个）。当这个Survivor区满时，此区的存活且不满足“晋升”条件的对象将被复制到另外一个Survivor区。对象每经历一次Minor GC，年龄加1，达到“晋升年龄阈值”后，被放到老年代，这个过程也称为“晋升”。显然，“晋升年龄阈值”的大小直接影响着对象在新生代中的停留时间，在Serial和ParNew GC两种回收器中，“晋升年龄阈值”通过参数MaxTenuringThreshold设定，默认值为15。</p><p>② 老年代（Old Generation）：在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。</p><p>③ 永久代（Perm Generation）：主要存放元数据，例如Class、Method的元信息，与垃圾回收要回收的Java对象关系不大。相对于新生代和年老代来说，该区域的划分对垃圾回收影响比较小。</p><h3 id="常见垃圾回收器"><a href="#常见垃圾回收器" class="headerlink" title="常见垃圾回收器"></a>常见垃圾回收器</h3><p>不同的垃圾回收器，适用于不同的场景。常用的垃圾回收器：</p><ul><li>串行（Serial）回收器是单线程的一个回收器，简单、易实现、效率高。</li><li>并行（ParNew）回收器是Serial的多线程版，可以充分的利用CPU资源，减少回收的时间。</li><li>吞吐量优先（Parallel Scavenge）回收器，侧重于吞吐量的控制。</li><li>并发标记清除（CMS，Concurrent Mark Sweep）回收器是一种以获取最短回收停顿时间为目标的回收器，该回收器是基于“标记-清除”算法实现的。</li></ul><h3 id="GC日志"><a href="#GC日志" class="headerlink" title="GC日志"></a>GC日志</h3><p>每一种回收器的日志格式都是由其自身的实现决定的，换而言之，每种回收器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个回收器的日志都维持一定的共性。<a href="http://blog.csdn.net/wanglha/article/details/48713217" target="_blank" rel="noopener">JavaGC日志</a> 中简单介绍了这些共性。</p><h2 id="参数基本策略"><a href="#参数基本策略" class="headerlink" title="参数基本策略"></a>参数基本策略</h2><p>各分区的大小对GC的性能影响很大。如何将各分区调整到合适的大小，分析活跃数据的大小是很好的切入点。</p><p><strong>活跃数据的大小</strong>是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是Full GC后堆中老年代占用空间的大小。可以通过GC日志中Full GC之后老年代数据大小得出，比较准确的方法是在程序稳定后，多次获取GC数据，通过取平均值的方式计算活跃数据的大小。活跃数据和各分区之间的比例关系如下（见参考文献1）：</p><table><thead><tr><th>空间</th><th>倍数</th></tr></thead><tbody><tr><td>总大小</td><td><strong>3-4</strong> 倍活跃数据的大小</td></tr><tr><td>新生代</td><td><strong>1-1.5</strong> 活跃数据的大小</td></tr><tr><td>老年代</td><td><strong>2-3</strong> 倍活跃数据的大小</td></tr><tr><td>永久代</td><td><strong>1.2-1.5</strong> 倍Full GC后的永久代空间占用</td></tr></tbody></table><p>例如，根据GC日志获得老年代的活跃数据大小为300M，那么各分区大小可以设为：</p><blockquote><p>总堆：1200MB = 300MB × 4_<br>新生代：450MB = 300MB × 1.5_<br>老年代： 750MB = 1200MB - 450MB*</p></blockquote><p>这部分设置仅仅是堆大小的初始值，后面的优化中，可能会调整这些值，具体情况取决于应用程序的特性和需求。</p><h1 id="二、优化步骤"><a href="#二、优化步骤" class="headerlink" title="二、优化步骤"></a>二、优化步骤</h1><p>GC优化一般步骤可以概括为：确定目标、优化参数、验收结果。</p><h2 id="确定目标"><a href="#确定目标" class="headerlink" title="确定目标"></a>确定目标</h2><p>明确应用程序的系统需求是性能优化的基础，系统的需求是指应用程序运行时某方面的要求，譬如：</p><ul><li>高可用，可用性达到几个9。</li><li>低延迟，请求必须多少毫秒内完成响应。</li><li>高吞吐，每秒完成多少次事务。</li></ul><p>明确系统需求之所以重要，是因为上述性能指标间可能冲突。比如通常情况下，缩小延迟的代价是降低吞吐量或者消耗更多的内存或者两者同时发生。</p><p>由于笔者所在团队主要关注高可用和低延迟两项指标，所以接下来分析，如何量化GC时间和频率对于响应时间和可用性的影响。通过这个量化指标，可以计算出当前GC情况对服务的影响，也能评估出GC优化后对响应时间的收益，这两点对于低延迟服务很重要。</p><p>举例：假设单位时间T内发生一次持续25ms的GC，接口平均响应时间为50ms，且请求均匀到达，根据下图所示：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-02-02.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>那么有(50ms+25ms)/T比例的请求会受GC影响，其中GC前的50ms内到达的请求都会增加25ms，GC期间的25ms内到达的请求，会增加0-25ms不等，如果时间T内发生N次GC，<strong>受GC影响请求占比=(接口响应时间+GC时间)×N/T</strong> 。可见无论降低单次GC时间还是降低GC次数N都可以有效减少GC对响应时间的影响。</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>通过收集GC信息，结合系统需求，确定优化方案，例如选用合适的GC回收器、重新设置内存比例、调整JVM参数等。</p><p>进行调整后，将不同的优化方案分别应用到多台机器上，然后比较这些机器上GC的性能差异，有针对性的做出选择，再通过不断的试验和观察，找到最合适的参数。</p><h2 id="验收优化结果"><a href="#验收优化结果" class="headerlink" title="验收优化结果"></a>验收优化结果</h2><p>将修改应用到所有服务器，判断优化结果是否符合预期，总结相关经验。</p><p>接下来，我们通过三个案例来实践以上的优化流程和基本原则（本文中三个案例使用的垃圾回收器均为ParNew+CMS，CMS失败时Serial Old替补)。</p><h1 id="三、GC优化案例"><a href="#三、GC优化案例" class="headerlink" title="三、GC优化案例"></a>三、GC优化案例</h1><h2 id="案例一-Major-GC和Minor-GC频繁"><a href="#案例一-Major-GC和Minor-GC频繁" class="headerlink" title="案例一 Major GC和Minor GC频繁"></a>案例一 Major GC和Minor GC频繁</h2><h3 id="确定目标-1"><a href="#确定目标-1" class="headerlink" title="确定目标"></a>确定目标</h3><p>服务情况：Minor GC每分钟100次 ，Major GC每4分钟一次，单次Minor GC耗时25ms，单次Major GC耗时200ms，接口响应时间50ms。</p><p>由于这个服务要求低延时高可用，结合上文中提到的GC对服务响应时间的影响，计算可知由于Minor GC的发生，12.5%的请求响应时间会增加，其中8.3%的请求响应时间会增加25ms，可见当前GC情况对响应时间影响较大。</p><p><em>（50ms+25ms）× 100次/60000ms = 12.5%，50ms × 100次/60000ms = 8.3%</em> 。</p><p>优化目标：降低TP99、TP90时间。</p><h3 id="优化-1"><a href="#优化-1" class="headerlink" title="优化"></a>优化</h3><p>首先优化Minor GC频繁问题。通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁Minor GC，因此可以通过增大新生代空间来降低Minor GC的频率。例如在相同的内存分配率的前提下，新生代中的Eden区增加一倍，Minor GC的次数就会减少一半。</p><p>这时很多人有这样的疑问，扩容Eden区虽然可以减少Minor GC的次数，但会增加单次Minor GC时间么？根据上面公式，如果单次Minor GC时间也增加，很难保证最后的优化效果。我们结合下面情况来分析，单次Minor GC时间主要受哪些因素影响？是否和新生代大小存在线性关系？<br>首先，单次Minor GC时间由以下两部分组成：T1（扫描新生代）和 T2（复制存活对象到Survivor区）如下图。（注：这里为了简化问题，我们认为T1只扫描新生代判断对象是否存活的时间，其实该阶段还需要扫描部分老年代，后面案例中有详细描述。）</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-02-48.png" alt title>                </div>                <div class="image-caption"></div>            </figure><ul><li><p>扩容前：新生代容量为R ，假设对象A的存活时间为750ms，Minor GC间隔500ms，那么本次Minor GC时间= T1（扫描新生代R）+T2（复制对象A到S）。</p></li><li><p>扩容后：新生代容量为2R ，对象A的生命周期为750ms，那么Minor GC间隔增加为1000ms，此时Minor GC对象A已不再存活，不需要把它复制到Survivor区，那么本次GC时间 = 2 × T1（扫描新生代R），没有T2复制时间。</p></li></ul><p>可见，扩容后，Minor GC时增加了T1（扫描时间），但省去T2（复制对象）的时间，更重要的是对于虚拟机来说，复制对象的成本要远高于扫描成本，所以，单次<strong>Minor GC时间更多取决于GC后存活对象的数量，而非Eden区的大小</strong>。因此如果堆中短期对象很多，那么扩容新生代，单次Minor GC时间不会显著增加。下面需要确认下服务中对象的生命周期分布情况：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-03-05.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>通过上图GC日志中两处红色框标记内容可知：</p><ol><li>new threshold = 2（动态年龄判断，对象的晋升年龄阈值为2），对象仅经历2次Minor GC后就晋升到老年代，这样老年代会迅速被填满，直接导致了频繁的Major GC。</li><li>Major GC后老年代使用空间为300M+，意味着此时绝大多数(86% = 2G/2.3G)的对象已经不再存活，也就是说生命周期长的对象占比很小。</li></ol><p>由此可见，服务中存在大量短期临时对象，扩容新生代空间后，Minor GC频率降低，对象在新生代得到充分回收，只有生命周期长的对象才进入老年代。这样老年代增速变慢，Major GC频率自然也会降低。</p><h3 id="优化结果"><a href="#优化结果" class="headerlink" title="优化结果"></a>优化结果</h3><p>通过扩容新生代为为原来的三倍，单次Minor GC时间增加小于5ms，频率下降了60%，服务响应时间TP90，TP99都下降了10ms+，服务可用性得到提升。</p><p>调整前：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-03-31.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>调整后：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-03-46.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>如何选择各分区大小应该依赖应用程序中<strong>对象生命周期的分布情况：如果应用存在大量的短期对象，应该选择较大的年轻代；如果存在相对较多的持久对象，老年代应该适当增大。</strong></p><h3 id="更多思考"><a href="#更多思考" class="headerlink" title="更多思考"></a>更多思考</h3><p>关于上文中提到晋升年龄阈值为2，很多同学有疑问，为什么设置了MaxTenuringThreshold=15，对象仍然仅经历2次Minor GC，就晋升到老年代？这里涉及到“动态年龄计算”的概念。</p><p><strong>动态年龄计算</strong>：Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值。在本案例中，调优前：Survivor区 = 64M，desired survivor = 32M，此时Survivor区中age&lt;=2的对象累计大小为41M，41M大于32M，所以晋升年龄阈值被设置为2，下次Minor GC时将年龄超过2的对象被晋升到老年代。</p><p>JVM引入动态年龄计算，主要基于如下两点考虑：</p><ol><li><p>如果固定按照MaxTenuringThreshold设定的阈值作为晋升条件：<br>a）MaxTenuringThreshold设置的过大，原本应该晋升的对象一直停留在Survivor区，直到Survivor区溢出，一旦溢出发生，Eden+Svuvivor中对象将不再依据年龄全部提升到老年代，这样对象老化的机制就失效了。<br>b）MaxTenuringThreshold设置的过小，“过早晋升”即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的Major GC。分代回收失去了意义，严重影响GC性能。</p></li><li><p>相同应用在不同时间的表现不同：特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面相同的问题。</p></li></ol><p>总结来说，为了更好的适应不同程序的内存情况，虚拟机并不总是要求对象年龄必须达到Maxtenuringthreshhold再晋级老年代。</p><h2 id="案例二-请求高峰期发生GC，导致服务可用性下降"><a href="#案例二-请求高峰期发生GC，导致服务可用性下降" class="headerlink" title="案例二 请求高峰期发生GC，导致服务可用性下降"></a>案例二 请求高峰期发生GC，导致服务可用性下降</h2><h3 id="确定目标-2"><a href="#确定目标-2" class="headerlink" title="确定目标"></a>确定目标</h3><p>GC日志显示，高峰期CMS在重标记（Remark）阶段耗时1.39s。Remark阶段是Stop-The-World（以下简称为STW）的，即在执行垃圾回收时，Java应用程序中除了垃圾回收器线程之外其他所有线程都被挂起，意味着在此期间，用户正常工作的线程全部被暂停下来，这是低延时服务不能接受的。本次优化目标是降低Remark时间。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-04-03.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h3 id="优化-2"><a href="#优化-2" class="headerlink" title="优化"></a>优化</h3><p>解决问题前，先回顾一下CMS的四个主要阶段，以及各个阶段的工作内容。下图展示了CMS各个阶段可以标记的对象，用不同颜色区分。</p><ol><li>Init-mark初始标记(STW) ，该阶段进行可达性分析，标记GC ROOT能直接关联到的对象，所以很快。</li><li>Concurrent-mark并发标记，由前阶段标记过的绿色对象出发，所有可到达的对象都在本阶段中标记。</li><li>Remark重标记(STW) ，暂停所有用户线程，重新扫描堆中的对象，进行可达性分析，标记活着的对象。因为并发标记阶段是和用户线程并发执行的过程，所以该过程中可能有用户线程修改某些活跃对象的字段，指向了一个未标记过的对象，如下图中红色对象在并发标记开始时不可达，但是并行期间引用发生变化，变为对象可达，这个阶段需要重新标记出此类对象，防止在下一阶段被清理掉，这个过程也是需要STW的。特别需要注意一点，这个阶段是以新生代中对象为根来判断对象是否存活的。</li><li>并发清理，进行并发的垃圾清理。</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-04-16.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>可见，Remark阶段主要是通过扫描堆来判断对象是否存活。那么准确判断对象是否存活，需要扫描哪些对象？CMS对老年代做回收，Remark阶段仅扫描老年代是否可行？结论是不可行，原因如下：  </p><p><img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-04-25.png" alt></p><p>如果仅扫描老年代中对象，即以老年代中对象为根，判断对象是否存在引用，上图中，对象A因为引用存在新生代中，它在Remark阶段就不会被修正标记为可达，GC时会被错误回收。<br>新生代对象持有老年代中对象的引用，这种情况称为<strong>“跨代引用”</strong>。因它的存在，Remark阶段必须扫描整个堆来判断对象是否存活，包括图中灰色的不可达对象。</p><p>灰色对象已经不可达，但仍然需要扫描的原因：<strong>新生代GC和老年代的GC是各自分开独立进行的</strong>，只有Minor GC时才会使用根搜索算法，标记新生代对象是否可达，也就是说虽然一些对象已经不可达，但在Minor GC发生前不会被标记为不可达，CMS也无法辨认哪些对象存活，只能全堆扫描（新生代+老年代）。由此可见堆中对象的数目影响了Remark阶段耗时。<br>分析GC日志可以得出同样的规律，Remark耗时&gt;500ms时，新生代使用率都在75%以上。这样降低Remark阶段耗时问题转换成如何减少新生代对象数量。</p><p>新生代中对象的特点是“朝生夕灭”，这样如果Remark前执行一次Minor GC，大部分对象就会被回收。CMS就采用了这样的方式，在Remark前增加了一个可中断的并发预清理（CMS-concurrent-abortable-preclean），该阶段主要工作仍然是并发标记对象是否存活，只是这个过程可被中断。此阶段在Eden区使用超过2M时启动，当然2M是默认的阈值，可以通过参数修改。如果此阶段执行时等到了Minor GC，那么上述灰色对象将被回收，Reamark阶段需要扫描的对象就少了。</p><p>除此之外CMS为了避免这个阶段没有等到Minor GC而陷入无限等待，提供了参数CMSMaxAbortablePrecleanTime ，默认为5s，含义是如果可中断的预清理执行超过5s，不管发没发生Minor GC，都会中止此阶段，进入Remark。<br>根据GC日志红色标记2处显示，可中断的并发预清理执行了5.35s，超过了设置的5s被中断，期间没有等到Minor GC ，所以Remark时新生代中仍然有很多对象。</p><p>对于这种情况，CMS提供CMSScavengeBeforeRemark参数，用来保证Remark前强制进行一次Minor GC。</p><h3 id="优化结果-1"><a href="#优化结果-1" class="headerlink" title="优化结果"></a>优化结果</h3><p>经过增加CMSScavengeBeforeRemark参数，单次执行时间&gt;200ms的GC停顿消失，从监控上观察，GCtime和业务波动保持一致，不再有明显的毛刺。<br><img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-04-38.png" alt></p><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>通过案例分析了解到，由于跨代引用的存在，CMS在Remark阶段必须扫描整个堆，同时为了避免扫描时新生代有很多对象，增加了可中断的预清理阶段用来等待Minor GC的发生。只是该阶段有时间限制，如果超时等不到Minor GC，Remark时新生代仍然有很多对象，我们的调优策略是，通过参数强制Remark前进行一次Minor GC，从而降低Remark阶段的时间。</p><h3 id="更多思考-1"><a href="#更多思考-1" class="headerlink" title="更多思考"></a>更多思考</h3><p>案例中只涉及老年代GC，其实新生代GC存在同样的问题，即老年代可能持有新生代对象引用，所以Minor GC时也必须扫描老年代。</p><p><strong>JVM是如何避免Minor GC时扫描全堆的？</strong><br>经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性JVM引入了卡表（card table）来实现这一目的。如下图所示：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-04-48.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p><strong>卡表</strong>的具体策略是将老年代的空间分成大小为512B的若干张卡（card）。卡表本身是单字节数组，数组中的每个元素对应着一张卡，当发生老年代引用新生代时，虚拟机将该卡对应的卡表元素设置为适当的值。如上图所示，卡表3被标记为脏（卡表还有另外的作用，标识并发标记阶段哪些块被修改过），之后Minor GC时通过扫描卡表就可以很快的识别哪些卡中存在老年代指向新生代的引用。这样虚拟机通过空间换时间的方式，避免了全堆扫描。</p><p>总结来说，CMS的设计聚焦在获取最短的时延，为此它“不遗余力”地做了很多工作，包括尽量让应用程序和GC线程并发、增加可中断的并发预清理阶段、引入卡表等，虽然这些操作牺牲了一定吞吐量但获得了更短的回收停顿时间。</p><h2 id="案例三-发生Stop-The-World的GC"><a href="#案例三-发生Stop-The-World的GC" class="headerlink" title="案例三 发生Stop-The-World的GC"></a>案例三 发生Stop-The-World的GC</h2><h3 id="确定目标-3"><a href="#确定目标-3" class="headerlink" title="确定目标"></a>确定目标</h3><p>GC日志如下图（在GC日志中，Full GC是用来说明这次垃圾回收的停顿类型，代表STW类型的GC，并不特指老年代GC），根据GC日志可知本次Full GC耗时1.23s。这个在线服务同样要求低时延高可用。本次优化目标是降低单次STW回收停顿时间，提高可用性。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/21/转载-从实际案例聊聊Java应用的GC优化/2018-10-21-08-04-57.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h3 id="优化-3"><a href="#优化-3" class="headerlink" title="优化"></a>优化</h3><p>首先，什么时候可能会触发STW的Full GC呢？</p><ol><li>Perm空间不足；</li><li>CMS GC时出现promotion failed和concurrent mode failure（concurrent mode failure发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再被使用的对象，这时停止所有的线程，同时终止CMS，直接进行Serial Old GC）；</li><li>统计得到的Young GC晋升到老年代的平均大小大于老年代的剩余空间；</li><li>主动触发Full GC（执行jmap -histo:live [pid]）来避免碎片问题。</li></ol><p>然后，我们来逐一分析一下：</p><ul><li>排除原因2：如果是原因2中两种情况，日志中会有特殊标识，目前没有。</li><li>排除原因3：根据GC日志，当时老年代使用量仅为20%，也不存在大于2G的大对象产生。</li><li>排除原因4：因为当时没有相关命令执行。</li><li>锁定原因1：根据日志发现Full GC后，Perm区变大了，推断是由于永久代空间不足容量扩展导致的。</li></ul><p>找到原因后解决方法有两种：</p><ol><li>通过把-XX:PermSize参数和-XX:MaxPermSize设置成一样，强制虚拟机在启动的时候就把永久代的容量固定下来，避免运行时自动扩容。</li><li>CMS默认情况下不会回收Perm区，通过参数CMSPermGenSweepingEnabled、CMSClassUnloadingEnabled ，可以让CMS在Perm区容量不足时对其回收。</li></ol><p>由于该服务没有生成大量动态类，回收Perm区收益不大，所以我们采用方案1，启动时将Perm区大小固定，避免进行动态扩容。</p><h3 id="优化结果-2"><a href="#优化结果-2" class="headerlink" title="优化结果"></a>优化结果</h3><p>调整参数后，服务不再有Perm区扩容导致的STW GC发生。</p><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>对于性能要求很高的服务，建议将MaxPermSize和MinPermSize设置成一致（JDK8开始，Perm区完全消失，转而使用元空间。而元空间是直接存在内存中，不在JVM中），Xms和Xmx也设置为相同，这样可以减少内存自动扩容和收缩带来的性能损失。虚拟机启动的时候就会把参数中所设定的内存全部化为私有，即使扩容前有一部分内存不会被用户代码用到，这部分内存在虚拟机中被标识为虚拟内存，也不会交给其他进程使用。</p><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><p>结合上述GC优化案例做个总结：</p><ol><li>首先再次声明，在进行GC优化之前，需要确认项目的架构和代码等已经没有优化空间。我们不能指望一个系统架构有缺陷或者代码层次优化没有穷尽的应用，通过GC优化令其性能达到一个质的飞跃。</li><li>其次，通过上述分析，可以看出虚拟机内部已有很多优化来保证应用的稳定运行，所以不要为了调优而调优，不当的调优可能适得其反。</li><li>最后，GC优化是一个系统而复杂的工作，没有万能的调优策略可以满足所有的性能指标。GC优化必须建立在我们深入理解各种垃圾回收器的基础上，才能有事半功倍的效果。</li></ol><p>本文中案例均来北京业务安全中心（也称风控）对接服务的实践经验。同时感谢风控的小伙伴们，是他们专业负责的审阅，才让这篇文章更加完善。对于本文中涉及到的内容，欢迎大家指正和补充。</p><h1 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h1><p>录录，2016年加入美团点评，主要负责北京业务安全中心对接服务的后台研发工作。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;美团技术团队： &lt;a href=&quot;https://tech.meituan.com/jvm_optimize.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://tech.meituan.com/jvm_optimize.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当Java程序性能达不到既定目标，且其他优化手段都已经穷尽时，通常需要调整垃圾回收器来进一步提高性能，称为GC优化。但GC算法复杂，影响GC性能的参数众多，且参数调整又依赖于应用各自的特点，这些因素很大程度上增加了GC优化的难度。即便如此，GC调优也不是无章可循，仍然有一些通用的思考方法。本篇会介绍这些通用的GC优化策略和相关实践案例，主要包括如下内容：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;优化前准备: 简单回顾JVM相关知识、介绍GC优化的一些通用策略。&lt;br&gt;优化方法: 介绍调优的一般流程：明确优化目标→优化→跟踪优化结果。&lt;br&gt;优化案例: 简述笔者所在团队遇到的GC问题以及优化方案。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="JVM" scheme="https://lincy.online/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>深入理解JVM-（5）Class文件的结构</title>
    <link href="https://lincy.online/2018/04/03/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%EF%BC%885%EF%BC%89Class%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%93%E6%9E%84/"/>
    <id>https://lincy.online/2018/04/03/深入理解JVM-（5）Class文件的结构/</id>
    <published>2018-04-03T08:18:40.000Z</published>
    <updated>2018-07-17T17:10:27.416Z</updated>
    
    <content type="html"><![CDATA[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-16-20-01.png" alt="Class文件结构" title>                </div>                <div class="image-caption">Class文件结构</div>            </figure><a id="more"></a><h2 id="magic"><a href="#magic" class="headerlink" title="magic"></a>magic</h2><p>魔数，4个字节，表明这是一个Class文件，0xCAFEBABE<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-16-24-44.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h2><p>minor_version，major_version各两个字节<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-16-22-42.png" alt="Class文件版本号" title>                </div>                <div class="image-caption">Class文件版本号</div>            </figure></p><h2 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h2><h3 id="constant-pool-count，u2"><a href="#constant-pool-count，u2" class="headerlink" title="constant_pool_count，u2"></a>constant_pool_count，u2</h3><p>常量池容量计数（从1开始），第0项表达“<strong>不引用任何一个常量池项目</strong>”。如:0x0016(十进制的22)标识有21常量，索引值范围为1~21.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-33-21.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="constant-pool"><a href="#constant-pool" class="headerlink" title="constant_pool"></a>constant_pool</h3><ul><li>字面量(Literal)<ul><li>接近于Java语言的常量概念，如文本字符串、final的常量值</li></ul></li><li>符号引用<ul><li>类和接口的全限定名</li><li>字段的名称和描述符</li><li>方法的名称和描述符</li></ul></li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-16-57-49.png" alt="常量池的项目类型" title>                </div>                <div class="image-caption">常量池的项目类型</div>            </figure><p>例子（下图）：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-33-52.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>0x07从上图可知为：CONSTANT_Class_info类型常量。而COMSTANT_Class_info的结构如下图，tag就是0x07，name_index（代表这个类或接口的全限定名）（0x0002）指向常量池的第二项。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-35-45.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>看第二项的tag标识0x01，从上面的常量池的类型图可以看出，此项为CONSTANT_UTF8_info。CONSTANT_Utf8_info的结构如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-43-33.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>所以第二项的内容三部分如下:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-45-40.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>第三部分的utf编码转换为字符串为<code>org/fenixsoft/clazz/TestClass</code>，就是第一个常量（CONSTANT_Class_info）的值。</p><p>以此类推，可以得到所有的常量的值。</p><p>可以使用javap工具输出TestClass.class的文件字节码内容（省略了常量池意外的信息）：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-58-26.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p><strong>常量池的14种常量的结构：</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-49-24.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-49-37.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="访问标志"><a href="#访问标志" class="headerlink" title="访问标志"></a>访问标志</h2><p>在常量池结束后，紧接着<strong>2个字节</strong>代表访问标志，用于识别<strong>类或接口层次的访问信息</strong>。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-21-51-36.png" alt title>                </div>                <div class="image-caption"></div>            </figure><br>access_flags一共有16个标志位可用，当前只定义了其中8个。</p><h2 id="类索引、父类索引与接口索引集合"><a href="#类索引、父类索引与接口索引集合" class="headerlink" title="类索引、父类索引与接口索引集合"></a>类索引、父类索引与接口索引集合</h2><ul><li>类索引、父类索引是一个u2类型的数据（只能继承一个父类），<strong>指向一个Constant_class_info常量</strong>，通过constant_class_info常量中的索引值找到定义在constant_utf8_info中的全限定名字符串。</li><li>接口索引集合是一组u2类型的数据（可以实现多个接口）。入口的第一项——一个u2类型的数据标识接口索引的数量。如果没有实现任何接口，则计数器为0。</li></ul><h2 id="字段表集合"><a href="#字段表集合" class="headerlink" title="字段表集合"></a>字段表集合</h2><p>在所有字段表之前有一个u2类型的数据fields_count为字段计数器，表示这个类有多少字段。</p><p>字段表（field_info），描述接口或者类中声明的变量。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-04-14-23-36.png" alt="字段表结构" title>                </div>                <div class="image-caption">字段表结构</div>            </figure></p><p>access_flags: 标志位，如下图<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-04-14-25-54.png" alt="字段访问标志" title>                </div>                <div class="image-caption">字段访问标志</div>            </figure></p><p>name_index（简单名称）和descriptor_index（描述符）都是对常量池的引用。<code>inc()</code>方法和<code>m</code>字段的简单名称分别是<code>inc</code>和<code>m</code>。描述符比较复杂，用来描述字段的数据类型、方法的参数列表（包括数量、类型、顺序）和返回值。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-04-15-00-46.png" alt="描述符标识字符含义" title>                </div>                <div class="image-caption">描述符标识字符含义</div>            </figure><p>举几个例子：</p><ul><li><code>int[]</code>的描述符为<code>[I</code>。（<code>[</code>表示数组）</li><li><code>java.lang.String[][]</code>的描述符为：<code>[[Ljava/lang/String;</code></li><li>方法<code>void inc()</code>的描述符为<code>()V</code></li><li>方法<code>java.lang.String toString()</code>的描述符为<code>()Ljava/lang/String;</code></li><li>方法<code>int indexOf(char[]source,int sourceOffset,int sourceCount,char[]target,int targetOffset,int targetCount,int fromIndex)</code>的描述符为<code>([CII[CIII)I</code></li></ul><p><strong>还有一部分是属性表集合，attribute_info</strong>，将在下面介绍。</p><h2 id="方法表集合"><a href="#方法表集合" class="headerlink" title="方法表集合"></a>方法表集合</h2><p>基本上同字段表结合一样。在字段表集合里已经有涉及。 </p><h2 id="属性表集合"><a href="#属性表集合" class="headerlink" title="属性表集合"></a>属性表集合</h2><p>虚拟机规范预定义的属性（Java SE 7）</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-04-16-34-14.png" alt="虚拟机预定义的属性类型(1)" title>                </div>                <div class="image-caption">虚拟机预定义的属性类型(1)</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-04-16-34-56.png" alt="虚拟机预定义的属性类型(2)" title>                </div>                <div class="image-caption">虚拟机预定义的属性类型(2)</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-08-16-06-17.png" alt="属性表结构" title>                </div>                <div class="image-caption">属性表结构</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/04/03/深入理解JVM-（5）Class文件的结构/2018-04-03-16-20-01.png&quot; alt=&quot;Class文件结构&quot; title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;Class文件结构&lt;/div&gt;
            &lt;/figure&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JVM" scheme="https://lincy.online/tags/JVM/"/>
    
      <category term="笔记" scheme="https://lincy.online/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>深入理解JVM-（4）内存分配与回收策略</title>
    <link href="https://lincy.online/2018/03/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%EF%BC%884%EF%BC%89%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5/"/>
    <id>https://lincy.online/2018/03/15/深入理解JVM-（4）内存分配与回收策略/</id>
    <published>2018-03-15T09:13:09.000Z</published>
    <updated>2018-10-22T22:24:50.404Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>如何查看GC日志：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/15/深入理解JVM-（4）内存分配与回收策略/2018-10-23-06-23-56.png" alt title>                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/15/深入理解JVM-（4）内存分配与回收策略/2018-10-23-06-24-40.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h1 id="对象优先分配在Eden"><a href="#对象优先分配在Eden" class="headerlink" title="对象优先分配在Eden"></a>对象优先分配在Eden</h1><a id="more"></a><p>使用JDK7实验新生代的GC：</p><pre><code class="java">public class CH03_05 {    private static final int _1MB = 1024 * 1024;    /**     * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC     */    public static void testAllocation() {        byte[] allocation1, allocation2, allocation3, allocation4;        allocation1 = new byte[2 * _1MB];        allocation2 = new byte[2 * _1MB];        allocation3 = new byte[2 * _1MB];        // 出现一次Minor GC        allocation4 = new byte[4 * _1MB];      }    public static void main(String args[]) {        testAllocation();    }}</code></pre><p>gc日志如下：</p><pre><code>[GC[DefNew: 7801K-&gt;524K(9216K), 0.0050620 secs] 7801K-&gt;6668K(19456K), 0.0050979 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation   total 9216K, used 5034K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000)  eden space 8192K,  55% used [0x00000000f9a00000, 0x00000000f9e67560, 0x00000000fa200000)  from space 1024K,  51% used [0x00000000fa300000, 0x00000000fa3832f0, 0x00000000fa400000)  to   space 1024K,   0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation   total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000)   the space 10240K,  60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen  total 21248K, used 2970K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000)   the space 21248K,  13% used [0x00000000fae00000, 0x00000000fb0e6a58, 0x00000000fb0e6c00, 0x00000000fc2c0000)</code></pre><p>allocation1、2、3在Eden区占用了6M的空间。在分配allocation4时，发现新生代无法容纳，发生一次Minor GC。而survivor区无法并无法容纳2M的大小，因此将allocation1、2、3移动到老年代。<br>gc后，将allocation4分配eden区。</p><h1 id="大对象直接进入老年代"><a href="#大对象直接进入老年代" class="headerlink" title="大对象直接进入老年代"></a>大对象直接进入老年代</h1><p><code>-XX:PretenureSizeThreshold=3145728</code> ：大于3M的对象直接进入老年代</p><h1 id="长期存活的对象直接进入老年代"><a href="#长期存活的对象直接进入老年代" class="headerlink" title="长期存活的对象直接进入老年代"></a>长期存活的对象直接进入老年代</h1><pre><code class="java">    private static final int _1MB = 1024 * 1024;    /**     * VM参数：-verbose:gc -Xms40M -Xmx40M -Xmn20M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1     * -XX:+PrintTenuringDistribution     */    @SuppressWarnings(&quot;unused&quot;)    public static void testTenuringThreshold() {        byte[] allocation1, allocation2, allocation3;        allocation1 = new byte[_1MB / 4];  // 什么时候进入老年代决定于XX:MaxTenuringThreshold设置        allocation2 = new byte[8 * _1MB];        allocation3 = new byte[8 * _1MB];        allocation3 = null;        allocation3 = new byte[8 * _1MB];    }    public static void main(String[] args) {        testTenuringThreshold();    }</code></pre><p>MaxTenuringThreshold=1，第一回收，allocation1依然在新生代（新生代占用784K）；第二次回收，allocation1已经转移到老年代（新生代0K）: </p><pre><code>[GC[DefNewDesired survivor size 1048576 bytes, new threshold 1 (max 1)- age   1:     804672 bytes,     804672 total: 10432K-&gt;785K(18432K), 0.0059603 secs] 10432K-&gt;8977K(38912K), 0.0059928 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC[DefNewDesired survivor size 1048576 bytes, new threshold 1 (max 1)- age   1:        760 bytes,        760 total: 9643K-&gt;0K(18432K), 0.0023646 secs] 17835K-&gt;8975K(38912K), 0.0023892 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation   total 18432K, used 8468K [0x00000000f8600000, 0x00000000f9a00000, 0x00000000f9a00000)  eden space 16384K,  51% used [0x00000000f8600000, 0x00000000f8e45000, 0x00000000f9600000)  from space 2048K,   0% used [0x00000000f9600000, 0x00000000f96002f8, 0x00000000f9800000)  to   space 2048K,   0% used [0x00000000f9800000, 0x00000000f9800000, 0x00000000f9a00000) tenured generation   total 20480K, used 8975K [0x00000000f9a00000, 0x00000000fae00000, 0x00000000fae00000)   the space 20480K,  43% used [0x00000000f9a00000, 0x00000000fa2c3ce8, 0x00000000fa2c3e00, 0x00000000fae00000) compacting perm gen  total 21248K, used 3098K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000)   the space 21248K,  14% used [0x00000000fae00000, 0x00000000fb106b08, 0x00000000fb106c00, 0x00000000fc2c0000)</code></pre><p>如果设置MaxTenuringThreshold=15(默认为15), 第二次gc新生代仍然有784K:</p><pre><code>[GC[DefNewDesired survivor size 1048576 bytes, new threshold 15 (max 15)- age   1:     804672 bytes,     804672 total: 10432K-&gt;785K(18432K), 0.0061502 secs] 10432K-&gt;8977K(38912K), 0.0061935 secs] [Times: user=0.02 sys=0.02, real=0.01 secs] [GC[DefNewDesired survivor size 1048576 bytes, new threshold 15 (max 15)- age   1:        968 bytes,        968 total- age   2:     802008 bytes,     802976 total: 9643K-&gt;784K(18432K), 0.0015832 secs] 17835K-&gt;8976K(38912K), 0.0016100 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation   total 18432K, used 9252K [0x00000000f8600000, 0x00000000f9a00000, 0x00000000f9a00000)  eden space 16384K,  51% used [0x00000000f8600000, 0x00000000f8e45000, 0x00000000f9600000)  from space 2048K,  38% used [0x00000000f9600000, 0x00000000f96c40a0, 0x00000000f9800000)  to   space 2048K,   0% used [0x00000000f9800000, 0x00000000f9800000, 0x00000000f9a00000) tenured generation   total 20480K, used 8192K [0x00000000f9a00000, 0x00000000fae00000, 0x00000000fae00000)   the space 20480K,  40% used [0x00000000f9a00000, 0x00000000fa200010, 0x00000000fa200200, 0x00000000fae00000) compacting perm gen  total 21248K, used 3098K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000)   the space 21248K,  14% used [0x00000000fae00000, 0x00000000fb106b08, 0x00000000fb106c00, 0x00000000fc2c0000)</code></pre><h1 id="空间分配担保"><a href="#空间分配担保" class="headerlink" title="空间分配担保"></a>空间分配担保</h1><p>发生MinorGC之前，<strong>检查老年代可用连续空间是否大于新生代的所有对象总空间</strong>。</p><ul><li>是，那么MinorGC可以确保是安全的</li><li>否。 查看HandlePromotionFailure设置值是否允许担保失败。<ul><li>允许。检查老年代最大连续空间是否大于历次晋升到老年代对象的平均大小：<ul><li>大于，尝试进行一次MinorGC，尽管是有风险的。</li><li>小于，直接FullGC</li></ul></li><li>不允许。FullGC。</li></ul></li></ul><p><strong>JDK6 Update24之后，HandlePromotionFailure不再起作用，只要老年代最大连续空间大于新生代对象总大小或历次平均大小，就进行MinorGC</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;如何查看GC日志：&lt;/p&gt;
&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/03/15/深入理解JVM-（4）内存分配与回收策略/2018-10-23-06-23-56.png&quot; alt title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;&lt;/div&gt;
            &lt;/figure&gt;
&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/03/15/深入理解JVM-（4）内存分配与回收策略/2018-10-23-06-24-40.png&quot; alt title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;&lt;/div&gt;
            &lt;/figure&gt;
&lt;h1 id=&quot;对象优先分配在Eden&quot;&gt;&lt;a href=&quot;#对象优先分配在Eden&quot; class=&quot;headerlink&quot; title=&quot;对象优先分配在Eden&quot;&gt;&lt;/a&gt;对象优先分配在Eden&lt;/h1&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JVM" scheme="https://lincy.online/tags/JVM/"/>
    
      <category term="笔记" scheme="https://lincy.online/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>深入理解JVM-（3）GC算法</title>
    <link href="https://lincy.online/2018/03/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%EF%BC%883%EF%BC%89GC%E7%AE%97%E6%B3%95/"/>
    <id>https://lincy.online/2018/03/02/深入理解JVM-（3）GC算法/</id>
    <published>2018-03-02T13:02:17.000Z</published>
    <updated>2018-07-17T17:10:27.414Z</updated>
    
    <content type="html"><![CDATA[<h1 id="标记清除算法"><a href="#标记清除算法" class="headerlink" title="标记清除算法"></a>标记清除算法</h1><p><strong>标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/标记清除算法.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure><br><a id="more"></a><br>缺点：</p><ul><li>效率低</li><li><strong>产生大量不连续的内存碎片</strong></li></ul><h1 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h1><p>将内存分为大小相等的两块，<strong>每次只使用其中的一块</strong>。<strong>当一块用完了，就将或者的对象复制到另外一块上面，然后把另一块一次清理掉</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/复制算法.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure><p>优点：</p><ul><li>简单效率高</li><li><strong>不产生内存碎片</strong></li></ul><p>缺点：<strong>浪费了一半的内存空间</strong></p><p>新生代就是用这种算法来回收对象的，不过新生代的对象大多存活时间都很短（98%活不过下一次gc），所以不要按1：1的比例来划分内存空间，而是：</p><ul><li><strong>将内存分为一块较大的Eden空间和两块较小的Survior空间（默认是8：1，这样只浪费10%的空间），每次使用Eden和其中的一块Survior。</strong></li><li><strong>回收时，将Eden和Survior中还存活着的对象一次性拷贝到另一块Survior上，最后清理掉Eden和刚刚的Survior。</strong></li><li><strong>但是没办法保证每次都只有10%的对象存活</strong>，有时还需要以来其他内存（老年代）分配担保。<strong>如果一块Survior无法容纳一次新生代gc存活下来的对象，那么这些对象将直接进入老年代</strong></li></ul><h1 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h1><p>标记-整理算法适用于存活率较高的老年代。(不适用复制算法，存活率高要复制的内存多，且浪费的空间大)</p><p><strong>标记过程和标记清除算法一样</strong>，后续步骤<strong>让所有存活的对象都向一端移动，然后清理掉边界以外的内存</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/标记整理算法.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h1 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h1><p>根据各个年特点代采用合适的清除算法：新生代采用复制算法，老年代采用标记-清除算法。</p><hr><h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/垃圾收集器.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure><p>连线表明它们可以搭配使用</p><h2 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h2><p>最基本最悠久的收集器，<strong>单线程收集器</strong>，<em>新生代</em>采用<strong>复制算法</strong>。gc时，必须暂停其他所有的工作线程（Stop The World）。<br>单个CPU环境下，效率较高，对于运行在Client模式下的虚拟机是个好选择。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/serial收集器.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h2><p><strong>Serial收集器的多线程版本</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/ParNew收集器.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h2><ul><li>是一个新生代收集器，采用复制算法</li><li>关注点与其他收集器不同，CMS等收集器关注的是尽可能地缩短垃圾收集时用户线程的等待时间，而Parallel Scavenge收集器目的是<strong>达到一个可控制的吞吐量（throughput=运行用户代码时间/(运行用户代码时间+垃圾收集时间)）</strong>。</li></ul><p>停顿时间短适合与用户交互的程序；而高吞吐量可以最高效率的利用cpu时间，适合后台运算而不需要太多交互的任务。</p><p>两个参数：</p><ul><li><strong>-XX：MaxGCPauseMillis</strong>，最大垃圾收集停顿时间（尽力保证）</li><li><strong>-XX：GCTimeRatio</strong>，吞吐量大小</li></ul><p><strong>-XX：+UseAdaptiveSizePolice</strong>，开关参数，不需要手工指定新生代大小（-Xmn）、Eden和Survior的比例（-XX:SurviorRatio）、晋升老年代对象年龄（-XX：PretenureSizeThreshold）等细节参数，虚拟机会根据收集的系统性能信息，动态调整这些参数。如果对虚拟机不熟，可以打开这个开关，然后使用MaxGCPauseMillis或GCTimeRatio给虚拟机设立一个优化目标，具体细节参数调节由虚拟机完成。</p><h2 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h2><p>Serial收集器的老年代版本<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/serial收集器.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h2><p>Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/ParallelOld收集器.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure><h2 id="CMS收集器（Concurrent-Mark-Sweep）"><a href="#CMS收集器（Concurrent-Mark-Sweep）" class="headerlink" title="CMS收集器（Concurrent Mark Sweep）"></a>CMS收集器（Concurrent Mark Sweep）</h2><p><strong>以获取最短回收停顿时间为目标的收集器</strong>，重视服务的相应速度，<strong>符合B/S<br>系统服务端的需求</strong>。基于标记-清除算法（Mark Sweep）。分为四个步骤：</p><ul><li><strong>初始标记</strong><br>  标记GC Roots能<strong>直接关联</strong>到的对象，速度很快（<strong>stop the world</strong>）</li><li><strong>并发标记</strong><br>  进行<strong>GC Roots Tracing</strong></li><li><strong>重新标记</strong><br>  修正并发标记阶段期间，用户程序继续运行而导致标记产生变动的那一部分对象的标记记录（<strong>stop the world</strong>）</li><li><strong>并发清除</strong></li></ul><p>整个过程耗时最长的并发标记和并发清除过程，收集线程可以和用户线程一起工作，总体上cms收集器的回收过程是与用户线程一起并发地执行的。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/cms收集器.PNG" alt="CMS收集器" title>                </div>                <div class="image-caption">CMS收集器</div>            </figure><p>CMS收集器仍然有三个显著的缺点：</p><ul><li><strong>对cpu资源非常敏感</strong><br>  默认回收线程数=（cpu数量+3）/4，当cpu数量&gt;=4时，收集线程占用的cpu资源&lt;25%；但是当cpu资源不足4时，比如2，那么回收线程将占用50%的cpu资源，导致用户线程速度降低50%。</li><li><strong>无法处理浮动垃圾</strong>（Floating Garbage，并发清理阶段，用户线程产生的新垃圾），可能出现“concurrent mode failure”而导致另一次Full GC的产生。<strong>由于垃圾收集阶段用户线程仍然在运行，所以需要预留空间提供程序运作使用。因此默认设置下，CMS在老年代使用了68%的空间后就会被激活（-XX:CMSInitiatingOccuPancyFraction参数可以用来设置这个比例值）</strong>。如果应用老年代增长不是很快，可以提高出发百分比，以便降低内存回收次数获得更好性能。要是CMS运行期间预留的内存空间无法满足程序需求，就会出现一次“Concurrent Mode Failure”，这时候虚拟机会临时启用<strong>Serial Old收集器</strong>来重新进行老年代的收集，这样停顿时间就更长了。因此-XX：CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量“Concurrent Mode Failure”，降低性能。</li><li>标记-清除算法，<strong>产生大量空间碎片</strong>，往往出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间，从而触发Full GC。CMS提供了一个<strong>-XX：+UseCMSCompactAtFullCollection</strong>开关参数，用于在Full GC后二外进行一个碎片整理过程，但停顿时间变常了。因此还提供了另一个参数<strong>-XX：CMSFullGCsBeforeComapction</strong>，用于设置执行多少次Full GC后，跟着来一次压缩。</li></ul><h2 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h2><p><strong>基于标记-整理算法</strong>，不会产生空间碎片。可以非常精确控制停顿，可以明确指定在一个长度为M毫秒的时间片段内，消耗在GC的时间不超过N好眠。</p><p>G1收集器，避免了全区域的垃圾收集（前面介绍的都是全区域的垃圾收集），它将整个Java堆划分为多个大小固定的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个优先队列，每次根据允许的收集时间，优先回收垃圾最多的区域（Garbage First<br>）。区域划分有优先级的区域回收，保证了G1收集器在有限的时间内可以获得最高的收集效率。</p><h1 id="GC常用参数总结"><a href="#GC常用参数总结" class="headerlink" title="GC常用参数总结"></a>GC常用参数总结</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（3）GC算法/GC常用参数.PNG" alt="CMS收集器" title>                </div>                <div class="image-caption">CMS收集器</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;标记清除算法&quot;&gt;&lt;a href=&quot;#标记清除算法&quot; class=&quot;headerlink&quot; title=&quot;标记清除算法&quot;&gt;&lt;/a&gt;标记清除算法&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/03/02/深入理解JVM-（3）GC算法/标记清除算法.PNG&quot; alt title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;&lt;/div&gt;
            &lt;/figure&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JVM" scheme="https://lincy.online/tags/JVM/"/>
    
      <category term="笔记" scheme="https://lincy.online/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>深入理解JVM-（2）垃圾回收, 对象已死？</title>
    <link href="https://lincy.online/2018/03/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%EF%BC%882%EF%BC%89%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>https://lincy.online/2018/03/02/深入理解JVM-（2）垃圾回收/</id>
    <published>2018-03-02T09:06:31.000Z</published>
    <updated>2018-07-17T17:10:27.411Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h1><p>算法：引用计数为0即为死对象<br>缺陷: 无法解决循环引用的问题，JDK不采用这种方法。</p><a id="more"></a><h1 id="根搜索算法"><a href="#根搜索算法" class="headerlink" title="根搜索算法"></a>根搜索算法</h1><p>根对象——GC Roots：</p><ul><li><strong>虚拟机栈中引用的对象（栈帧中的本地变量表）</strong></li><li><strong>方法去中的静态属性引用的对象</strong></li><li><strong>方法区中常量引用的对象</strong></li><li><strong>本地方法栈中JNI（Native方法）的引用的对象</strong></li></ul><p>不能从GC Roots追溯到的对象，为可回收的对象。</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ul><li><h2 id="强引用"><a href="#强引用" class="headerlink" title="强引用"></a>强引用</h2>  类似 “Object obj = new Object()”，只要强引用还在，就不会被回收</li><li><h2 id="软引用"><a href="#软引用" class="headerlink" title="软引用"></a>软引用</h2>  JDK中提供的SoftReference类——还有用，但并非必须的对象。<strong>在内存溢出之前，会把软引用对象列进回收范围，进行二次回收</strong>，如果还是没有足够的内存，才会抛出内存溢出异常。</li><li><h2 id="弱引用"><a href="#弱引用" class="headerlink" title="弱引用"></a>弱引用</h2>  WeakReference——非必需对象，只能生存到下一次垃圾收集之前。无论当前内存是否足够，都会回收掉弱引用对象。</li><li><h2 id="虚引用"><a href="#虚引用" class="headerlink" title="虚引用"></a>虚引用</h2>  PhantomReference——完全不会对对象的生存构成影响，也无法通过其获取对象实例，唯一的目的是对象被垃圾回收时收到一个系统通知。</li></ul><h1 id="生还是死"><a href="#生还是死" class="headerlink" title="生还是死"></a>生还是死</h1><p>根搜索算法中不可达的对象，并非“非死不可”，可以通过finalize()方法自救：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（2）垃圾回收/finalize.PNG" alt="finalize执行流程" title>                </div>                <div class="image-caption">finalize执行流程</div>            </figure></p><p>不建议使用finalize(), 应使用try-finally, 更好更及时。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引用计数法&quot;&gt;&lt;a href=&quot;#引用计数法&quot; class=&quot;headerlink&quot; title=&quot;引用计数法&quot;&gt;&lt;/a&gt;引用计数法&lt;/h1&gt;&lt;p&gt;算法：引用计数为0即为死对象&lt;br&gt;缺陷: 无法解决循环引用的问题，JDK不采用这种方法。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JVM" scheme="https://lincy.online/tags/JVM/"/>
    
      <category term="笔记" scheme="https://lincy.online/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>深入理解JVM-（1）Java内存结构</title>
    <link href="https://lincy.online/2018/03/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%EF%BC%881%EF%BC%89Java%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"/>
    <id>https://lincy.online/2018/03/02/深入理解JVM-（1）Java内存结构/</id>
    <published>2018-03-02T07:50:26.000Z</published>
    <updated>2018-07-17T17:10:27.410Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（1）Java内存结构/内存模型.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure><a id="more"></a><h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p>线程私有， 当前线程所执行的字节码的行号指示器，可以通过改变这个计数器的值来选取吓一跳需要执行的字节码指令。</p><h2 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h2><p>线程私有，生命周期与线程相同。<br>描述Java方法执行的内存模型，每个方法被执行都会创建一个栈帧用于<strong>存储局部变量表、操作栈、动态链接、方法出口等信息</strong>。每一个方法从调用到执行完成的过程，对应一个栈帧再虚拟机栈中从入栈到出栈的过程。</p><p>如果请求的栈深度超过虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈动态扩展无法申请得到足够的内存，将会排除OutOfMemoryError。</p><h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p>跟虚拟机栈类似，本地方法栈服务于Native方法</p><h2 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h2><p><strong>被所有线程共享，目的是存放对象实例</strong>(对象实例不一定都分配在Java堆上，也可能在栈上——逃逸分析、栈上分配)。</p><p>GC的主要区域。通过-Xms和-Xmx控制扩展大小，无法扩展时，抛出OutOfMemoryError。</p><h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p><strong>线程共享，存储类信息、常量、静态变量、即时编译器编译后的代码等数据</strong>。习惯称为<strong>永久代</strong>。<br>垃圾收集在这个区域较少出现，但数据也并非“永久”存在。</p><p>可能会抛出OutOfMemoryError。典型场景如Spring和Hibernate对类增强时，用到CGLib字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以载入内存。</p><h2 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h2><p>属于方法区的一部分，<strong>存放编译器生成的各种字面量和符号引用</strong>。</p><h2 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h2><p>堆外内存。NIO基于通道（channel）与缓冲区（buffer），使用Nativ函数直接分配堆外内存。因为避免了在Java堆和Navite堆中来回复制数据，所以可以提高性能。</p><h1 id="对象的引用"><a href="#对象的引用" class="headerlink" title="对象的引用"></a>对象的引用</h1><p>两种方式:</p><ul><li>通过句柄<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（1）Java内存结构/句柄.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></li><li>通过直接指针<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/03/02/深入理解JVM-（1）Java内存结构/直接指针.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></li></ul><p>直接指针速度优于句柄方式，因为少了一次寻址。Sun HotSpot（JDK默认）采用直接指针方式。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运行时数据区域&quot;&gt;&lt;a href=&quot;#运行时数据区域&quot; class=&quot;headerlink&quot; title=&quot;运行时数据区域&quot;&gt;&lt;/a&gt;运行时数据区域&lt;/h1&gt;&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/03/02/深入理解JVM-（1）Java内存结构/内存模型.PNG&quot; alt title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;&lt;/div&gt;
            &lt;/figure&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JVM" scheme="https://lincy.online/tags/JVM/"/>
    
      <category term="笔记" scheme="https://lincy.online/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>New Year&#39;s Day</title>
    <link href="https://lincy.online/2018/02/16/New-Year-s-Day/"/>
    <id>https://lincy.online/2018/02/16/New-Year-s-Day/</id>
    <published>2018-02-15T16:35:59.000Z</published>
    <updated>2018-02-16T06:25:45.952Z</updated>
    
    <content type="html"><![CDATA[<embed src="https://www.xiami.com/widget/1722104_2080749/singlePlayer.swf" type="application/x-shockwave-flash" width="257" height="33" wmode="transparent"><p>2018<br>I will be with you again<br>I will begin again</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;embed src=&quot;https://www.xiami.com/widget/1722104_2080749/singlePlayer.swf&quot; type=&quot;application/x-shockwave-flash&quot; width=&quot;257&quot; height=&quot;33&quot; wmod
      
    
    </summary>
    
      <category term="生活" scheme="https://lincy.online/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>责任链模式</title>
    <link href="https://lincy.online/2018/02/13/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/"/>
    <id>https://lincy.online/2018/02/13/责任链模式/</id>
    <published>2018-02-13T05:25:29.000Z</published>
    <updated>2018-02-13T15:10:50.721Z</updated>
    
    <content type="html"><![CDATA[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/02/13/责任链模式/捕获.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure><a id="more"></a><pre><code class="java">/** * 职责接口 * @author LinChangyi * @date 2018/2/13 **/public abstract class Handler {    /**     * 持有后继的职责对象     */    protected Handler successor;    public void setSuccessor(Handler successor) {        this.successor = successor;    }    /**     * 处理请求的方法     * 可以根据需求传入参数     */    public abstract void handleRequest();}</code></pre><pre><code class="java">/** * @author LinChangyi * @date 2018/2/13 **/public class ConcreteHandler1 extends Handler{    @Override    public void handleRequest() {        //根据某些条件来判断是否属于自己的职责范围        //判断条件比如，从外部传入的参数，或者这里主动去获取的外部数据        //如从数据库中获取等，下面只是个示意        boolean someCondition = false;        if(someCondition){            //属于自己的职责            System.out.println(&quot;ConcreteHandler1 handle request&quot;);        } else {            if(this.successor!=null){                this.successor.handleRequest();            }        }    }}</code></pre><pre><code class="java">/** * @author LinChangyi * @date 2018/2/13 **/public class Client {    public static void main(String[] args){        //组装责任链        Handler handler1 = new ConcreteHandler1();        Handler handler2 = new ConcreteHandler2();        handler1.setSuccessor(handler2);        //提交请求        handler1.handleRequest();    }}</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;/2018/02/13/责任链模式/捕获.PNG&quot; alt title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;&lt;/div&gt;
            &lt;/figure&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="设计模式" scheme="https://lincy.online/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot启动过程分析</title>
    <link href="https://lincy.online/2018/02/09/SpringBoot%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90/"/>
    <id>https://lincy.online/2018/02/09/SpringBoot启动过程分析/</id>
    <published>2018-02-09T03:49:43.000Z</published>
    <updated>2018-03-10T09:15:46.522Z</updated>
    
    <content type="html"><![CDATA[<h1 id="入口"><a href="#入口" class="headerlink" title="入口"></a>入口</h1><pre><code class="java">@SpringBootApplicationpublic class SpringbootstarterApplication {    public static void main(String[] args) {        SpringApplication.run(SpringbootstarterApplication.class, args);    }}</code></pre><a id="more"></a><h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><pre><code class="java">private void initialize(Object[] sources) {    //sources为入口的传入的class    if (sources != null &amp;&amp; sources.length &gt; 0) {        this.sources.addAll(Arrays.asList(sources));    }    //是否web应用    this.webEnvironment = deduceWebEnvironment();    //应用上下文初始化器    setInitializers((Collection) getSpringFactoriesInstances(            ApplicationContextInitializer.class));    //应用监听器监听器，使用观察者模式实现    setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));    this.mainApplicationClass = deduceMainApplicationClass();}</code></pre><p>加载的初始化器和监听器如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/02/09/SpringBoot启动过程分析/1.PNG" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="初始化器和监听器是如何创建的？"><a href="#初始化器和监听器是如何创建的？" class="headerlink" title="初始化器和监听器是如何创建的？"></a>初始化器和监听器是如何创建的？</h2><p>可以看到初始化器和监听器的创建都是通过 getSpringFactoriesInstances 这个方法：</p><pre><code class="java">private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type,        Class&lt;?&gt;[] parameterTypes, Object... args) {    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();    // SpringFactoriesLoader读取spring.factories文件，找到类名    Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;(            SpringFactoriesLoader.loadFactoryNames(type, classLoader));    //根据上面找到的类名，创建实例    List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes,            classLoader, args, names);    AnnotationAwareOrderComparator.sort(instances);    return instances;}</code></pre><p>springboot的一个jar包底下的\META-INF\spring.factories配置的初始化器和监听器:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/02/09/SpringBoot启动过程分析/springfactories.PNG" alt="spring.factories一部分配置" title>                </div>                <div class="image-caption">spring.factories一部分配置</div>            </figure></p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>SpringApplition.java</p><pre><code class="java">public ConfigurableApplicationContext run(String... args) {    StopWatch stopWatch = new StopWatch();    stopWatch.start();    FailureAnalyzers analyzers = null;    configureHeadlessProperty();    //SpringApplicationRunListener，也是通getSpringFactoriesInstances方式加载。    //是SpringApplicationRunListener的集合，监测应用上下文环境的事件：    //starting, environmentPrepared, contextPrepared, contextLoaded, finished     SpringApplicationRunListeners listeners = getRunListeners(args);    listeners.starting();    try  {        ApplicationArguments applicationArguments = new DefaultApplicationArguments(                args);        ConfigurableEnvironment environment = prepareEnvironment(listeners,                applicationArguments);        Banner printedBanner = printBanner(environment);        context = createApplicationContext();        analyzers = new FailureAnalyzers(context);        //初始化一些配置        prepareContext(context, environment, listeners, applicationArguments,                printedBanner);        refreshContext(context);        afterRefresh(context, applicationArguments);        listeners.finished(context, null);        stopWatch.stop();        if (this.logStartupInfo) {            new StartupInfoLogger(this.mainApplicationClass)                    .logStarted(getApplicationLog(), stopWatch);        }        return context;    }    catch (Throwable ex) {        handleRunFailure(context, listeners, analyzers, ex);        throw new IllegalStateException(ex);    }}</code></pre><h1 id="…未完待续"><a href="#…未完待续" class="headerlink" title="…未完待续"></a>…未完待续</h1>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;入口&quot;&gt;&lt;a href=&quot;#入口&quot; class=&quot;headerlink&quot; title=&quot;入口&quot;&gt;&lt;/a&gt;入口&lt;/h1&gt;&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;@SpringBootApplication
public class SpringbootstarterApplication {
    public static void main(String[] args) {
        SpringApplication.run(SpringbootstarterApplication.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="技术" scheme="https://lincy.online/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="springboot" scheme="https://lincy.online/tags/springboot/"/>
    
  </entry>
  
</feed>

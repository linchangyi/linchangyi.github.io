<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    

    

    



    <meta charset="utf-8">
    
    
    <link rel="canonical" href="lincy.online/2019/06/22/titanic_advanced/">
    
    
    <title>Titanic - Machine Learning from Disaster | Lincy&#39;s Blog | 归去来兮，Just Do IT.</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="机器学习">
    <meta name="description" content="Titanic: Machine Learning from DisasterLibraries">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="Titanic - Machine Learning from Disaster">
<meta property="og:url" content="https://lincy.online/2019/06/22/titanic_advanced/index.html">
<meta property="og:site_name" content="Lincy&#39;s Blog">
<meta property="og:description" content="Titanic: Machine Learning from DisasterLibraries">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_38_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_41_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_46_1.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_50_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_53_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_55_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_61_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_63_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_65_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_67_0.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_102_1.png">
<meta property="og:image" content="https://lincy.online/2019/06/22/titanic_advanced/output_106_0.png">
<meta property="og:updated_time" content="2019-08-17T07:44:00.831Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Titanic - Machine Learning from Disaster">
<meta name="twitter:description" content="Titanic: Machine Learning from DisasterLibraries">
<meta name="twitter:image" content="https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733">
    
        <link rel="alternate" type="application/atom+xml" title="Lincy&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    
    <link rel="stylesheet" href="/plugins/highlight/styles/vs.css">
</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Lincy</h5>
          <a href="mailto:talentlcy@hotmail.com" title="talentlcy@hotmail.com" class="mail">talentlcy@hotmail.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archieves
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories/技术"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/linchangyi" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-link"></i>
                about
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
                <i class="icon icon-lg icon-navicon"></i>
            </a>
        <div class="top-menu" id="top-menu">
            
                <a href="/"title="Home" class="header-icon waves-effect waves-circle waves-light on">
                    <i class="icon icon-lg icon-home"></i>
                </a>
            
                <a href="/archives"title="Archieves" class="header-icon waves-effect waves-circle waves-light on">
                    <i class="icon icon-lg icon-archives"></i>
                </a>
            
                <a href="/categories/技术"title="Categories" class="header-icon waves-effect waves-circle waves-light on">
                    <i class="icon icon-lg icon-th-list"></i>
                </a>
            
                <a href="/tags"title="Tags" class="header-icon waves-effect waves-circle waves-light on">
                    <i class="icon icon-lg icon-tags"></i>
                </a>
            
                <a href="https://github.com/linchangyi"title="Github" class="header-icon waves-effect waves-circle waves-light on">
                    <i class="icon icon-lg icon-github"></i>
                </a>
            
                <a href="/about"title="about" class="header-icon waves-effect waves-circle waves-light on">
                    <i class="icon icon-lg icon-link"></i>
                </a>
            
        </div>
        <span class="flex-col header-title ellipsis hidden" id="header-title">Titanic - Machine Learning from Disaster</span>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Titanic - Machine Learning from Disaster</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-06-22T10:00:04.000Z" itemprop="datePublished" class="page-time">
  2019-06-22
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/技术/">技术</a></li></ul>

            
        </h5>
    </div>

    


</header>



    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Titanic-Machine-Learning-from-Disaster"><span class="post-toc-number">1.</span> <span class="post-toc-text">Titanic: Machine Learning from Disaster</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Libraries"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">Libraries</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#加载数据"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">加载数据</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#数据分析"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">数据分析</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#概览"><span class="post-toc-number">1.3.1.</span> <span class="post-toc-text">概览</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#处理缺失的特征值"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">处理缺失的特征值</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Age"><span class="post-toc-number">1.4.1.</span> <span class="post-toc-text">Age</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Embarked"><span class="post-toc-number">1.4.2.</span> <span class="post-toc-text">Embarked</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Fare"><span class="post-toc-number">1.4.3.</span> <span class="post-toc-text">Fare</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Cabin"><span class="post-toc-number">1.4.4.</span> <span class="post-toc-text">Cabin</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#数据相关性"><span class="post-toc-number">1.4.5.</span> <span class="post-toc-text">数据相关性</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#各个特征的生存分布"><span class="post-toc-number">1.4.6.</span> <span class="post-toc-text">各个特征的生存分布</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#连续型特征"><span class="post-toc-number">1.4.6.1.</span> <span class="post-toc-text">连续型特征</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#离散型特征"><span class="post-toc-number">1.4.7.</span> <span class="post-toc-text">离散型特征</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#结论"><span class="post-toc-number">1.4.8.</span> <span class="post-toc-text">结论</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#特征工程"><span class="post-toc-number">1.5.</span> <span class="post-toc-text">特征工程</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#连续型特征-1"><span class="post-toc-number">1.5.1.</span> <span class="post-toc-text">连续型特征</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Fare-1"><span class="post-toc-number">1.5.1.1.</span> <span class="post-toc-text">Fare</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#家庭成员数量"><span class="post-toc-number">1.5.1.2.</span> <span class="post-toc-text">家庭成员数量</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#船票频率"><span class="post-toc-number">1.5.1.3.</span> <span class="post-toc-text">船票频率</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#称谓和婚姻状况"><span class="post-toc-number">1.5.1.4.</span> <span class="post-toc-text">称谓和婚姻状况</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#生还率"><span class="post-toc-number">1.5.1.5.</span> <span class="post-toc-text">生还率</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Frature-Transformation"><span class="post-toc-number">1.5.1.6.</span> <span class="post-toc-text">Frature Transformation</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#标签编码（Label-Encoding）"><span class="post-toc-number">1.5.1.6.1.</span> <span class="post-toc-text">标签编码（Label Encoding）</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#独热编码（One-Hot-Encoding）"><span class="post-toc-number">1.5.1.6.2.</span> <span class="post-toc-text">独热编码（One-Hot Encoding）</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#结果"><span class="post-toc-number">1.5.1.7.</span> <span class="post-toc-text">结果</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#机器学习"><span class="post-toc-number">1.6.</span> <span class="post-toc-text">机器学习</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#模型"><span class="post-toc-number">1.6.1.</span> <span class="post-toc-text">模型</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#评估"><span class="post-toc-number">1.6.2.</span> <span class="post-toc-text">评估</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Feature-Importance"><span class="post-toc-number">1.6.2.1.</span> <span class="post-toc-text">Feature Importance</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Roc-Curve"><span class="post-toc-number">1.6.2.2.</span> <span class="post-toc-text">Roc Curve</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#提交"><span class="post-toc-number">1.7.</span> <span class="post-toc-text">提交</span></a></li></ol></li></ol>
        </nav>
    </aside>
    


<div class="container body-wrap">
    <article id="post-titanic_advanced"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Titanic - Machine Learning from Disaster</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-06-22 18:00:04" datetime="2019-06-22T10:00:04.000Z"  itemprop="datePublished">2019-06-22</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/技术/">技术</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="Titanic-Machine-Learning-from-Disaster"><a href="#Titanic-Machine-Learning-from-Disaster" class="headerlink" title="Titanic: Machine Learning from Disaster"></a>Titanic: Machine Learning from Disaster</h1><h2 id="Libraries"><a href="#Libraries" class="headerlink" title="Libraries"></a>Libraries</h2><a id="more"></a>
<pre><code class="python">import numpy as np
import pandas as pd
</code></pre>
<pre><code class="python">import matplotlib.pyplot as plt
import seaborn as sns
</code></pre>
<pre><code class="python">sns.set(style=&quot;darkgrid&quot;)
</code></pre>
<pre><code class="python">from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import StratifiedKFold
</code></pre>
<pre><code class="python">import string
import warnings
</code></pre>
<pre><code class="python">warnings.filterwarnings(&#39;ignore&#39;)
</code></pre>
<pre><code class="python">SEED = 42
</code></pre>
<pre><code class="python">def pandas_df_to_markdown_table(df):
    from IPython.display import Markdown, display
    fmt = [&#39;---&#39; for i in range(len(df.columns))]
    df_fmt = pd.DataFrame([fmt], columns=df.columns)
    df_formatted = pd.concat([df_fmt, df])
    display(Markdown(df_formatted.to_csv(sep=&quot;|&quot;, index=False)))
</code></pre>
<ul>
<li><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2></li>
</ul>
<ul>
<li>训练数据 891 条，测试数据 418 条</li>
<li>训练数据 12 个特征，测试数据 11 个特征</li>
<li>训练数据 多了一个 ‘Survived’ 特征</li>
</ul>
<pre><code class="python">def concat_df(train_data, test_data):
    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)
</code></pre>
<pre><code class="python">def divide_df(all_data):
    return all_data.loc[:890], all_data[891:].drop([&#39;Survived&#39;], axis=1)
</code></pre>
<pre><code class="python">df_train = pd.read_csv(&#39;./data/train.csv&#39;)
df_test = pd.read_csv(&#39;./data/test.csv&#39;)
df_all: pd.DataFrame = concat_df(df_train, df_test)
</code></pre>
<pre><code class="python">df_train.name = &#39;Training Set&#39;
df_test.name = &#39;Test Set&#39;
df_all.name = &#39;All Set&#39;
</code></pre>
<pre><code class="python">print(&#39;Number of Training Examples = {}&#39;.format(df_train.shape[0]))
print(&#39;Number of Test Examples = {}\n&#39;.format(df_test.shape[0]))
print(&#39;Training X Shape = {}&#39;.format(df_train.shape))
print(&#39;Training y Shape = {}\n&#39;.format(df_train[&#39;Survived&#39;].shape[0]))
print(&#39;Test X Shape = {}&#39;.format(df_test.shape))
print(&#39;Test y Shape = {}\n&#39;.format(df_test.shape[0]))
print(df_train.columns)
print(df_test.columns)
</code></pre>
<pre><code>Number of Training Examples = 891
Number of Test Examples = 418

Training X Shape = (891, 12)
Training y Shape = 891

Test X Shape = (418, 11)
Test y Shape = 418

Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],
      dtype=&#39;object&#39;)
Index([&#39;PassengerId&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;,
       &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],
      dtype=&#39;object&#39;)
</code></pre><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><ul>
<li>PassengerId 是数据的主键，对预测没有任何影响</li>
<li>Survived 值为 0 or 1<ul>
<li>1 幸存</li>
<li>2 丧生</li>
</ul>
</li>
<li>Pclass 类别标示，乘客等级<ul>
<li><ol>
<li>高级</li>
</ol>
</li>
<li><ol start="2">
<li>中级</li>
</ol>
</li>
<li><ol start="3">
<li>普通</li>
</ol>
</li>
</ul>
</li>
<li>Name，Sex，Age</li>
<li>SibSp 乘客的兄弟姐妹数量</li>
<li>Parch 乘客的父母和子女的数量</li>
<li>Ticket 船票的号码</li>
<li>fare 船票费用</li>
<li>Cabin 船舱号码</li>
<li>Embarked 登船的码头<ul>
<li>C = Cherbourg</li>
<li>Q = Queenstown</li>
<li>S = Southampton</li>
</ul>
</li>
</ul>
<pre><code class="python">print(df_train.info())
pandas_df_to_markdown_table(df_train.sample(3))
</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
None
</code></pre><table>
<thead>
<tr>
<th>PassengerId</th>
<th>Survived</th>
<th>Pclass</th>
<th>Name</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Ticket</th>
<th>Fare</th>
<th>Cabin</th>
<th>Embarked</th>
</tr>
</thead>
<tbody>
<tr>
<td>95</td>
<td>0</td>
<td>3</td>
<td>Coxon, Mr. Daniel</td>
<td>male</td>
<td>59.0</td>
<td>0</td>
<td>0</td>
<td>364500</td>
<td>7.25</td>
<td></td>
<td>S</td>
</tr>
<tr>
<td>434</td>
<td>0</td>
<td>3</td>
<td>Kallio, Mr. Nikolai Erland</td>
<td>male</td>
<td>17.0</td>
<td>0</td>
<td>0</td>
<td>STON/O 2. 3101274</td>
<td>7.125</td>
<td></td>
<td>S</td>
</tr>
<tr>
<td>371</td>
<td>1</td>
<td>1</td>
<td>Harder, Mr. George Achilles</td>
<td>male</td>
<td>25.0</td>
<td>1</td>
<td>0</td>
<td>11765</td>
<td>55.4417</td>
<td>E50</td>
<td>C</td>
</tr>
</tbody>
</table>
<pre><code class="python">print(df_test.info())
</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 418 entries, 891 to 1308
Data columns (total 44 columns):
Age                        418 non-null int64
Deck                       418 non-null int64
Embarked                   418 non-null int64
Fare                       418 non-null int64
Name                       418 non-null object
Parch                      418 non-null int64
PassengerId                418 non-null int64
Pclass                     418 non-null int64
Sex                        418 non-null int64
SibSp                      418 non-null int64
Survived                   0 non-null float64
Ticket                     418 non-null object
Family_Size                418 non-null int64
Family_Size_Grouped        418 non-null int64
Ticket_Frequency           418 non-null int64
Title                      418 non-null int64
Is_Married                 418 non-null int64
Family                     418 non-null object
Family_Survival_Rate       418 non-null float64
Family_Survival_Rate_NA    418 non-null int64
Ticket_Survival_Rate       418 non-null float64
Ticket_Survival_Rate_NA    418 non-null int64
Survival_Rate              418 non-null float64
Survival_Rate_NA           418 non-null float64
Pclass_1                   418 non-null float64
Pclass_2                   418 non-null float64
Pclass_3                   418 non-null float64
Sex_1                      418 non-null float64
Sex_2                      418 non-null float64
Deck_1                     418 non-null float64
Deck_2                     418 non-null float64
Deck_3                     418 non-null float64
Deck_4                     418 non-null float64
Embarked_1                 418 non-null float64
Embarked_2                 418 non-null float64
Embarked_3                 418 non-null float64
Title_1                    418 non-null float64
Title_2                    418 non-null float64
Title_3                    418 non-null float64
Title_4                    418 non-null float64
Family_Size_Grouped_1      418 non-null float64
Family_Size_Grouped_2      418 non-null float64
Family_Size_Grouped_3      418 non-null float64
Family_Size_Grouped_4      418 non-null float64
dtypes: float64(25), int64(16), object(3)
memory usage: 143.8+ KB
None
</code></pre><pre><code class="python">
</code></pre>
<pre><code class="python">
pandas_df_to_markdown_table(df_test.sample(3))
</code></pre>
<table>
<thead>
<tr>
<th>Age</th>
<th>Deck</th>
<th>Embarked</th>
<th>Fare</th>
<th>Name</th>
<th>Parch</th>
<th>PassengerId</th>
<th>Pclass</th>
<th>Sex</th>
<th>SibSp</th>
<th>Survived</th>
<th>Ticket</th>
<th>Family_Size</th>
<th>Family_Size_Grouped</th>
<th>Ticket_Frequency</th>
<th>Title</th>
<th>Is_Married</th>
<th>Family</th>
<th>Family_Survival_Rate</th>
<th>Family_Survival_Rate_NA</th>
<th>Ticket_Survival_Rate</th>
<th>Ticket_Survival_Rate_NA</th>
<th>Survival_Rate</th>
<th>Survival_Rate_NA</th>
<th>Pclass_1</th>
<th>Pclass_2</th>
<th>Pclass_3</th>
<th>Sex_1</th>
<th>Sex_2</th>
<th>Deck_1</th>
<th>Deck_2</th>
<th>Deck_3</th>
<th>Deck_4</th>
<th>Embarked_1</th>
<th>Embarked_2</th>
<th>Embarked_3</th>
<th>Title_1</th>
<th>Title_2</th>
<th>Title_3</th>
<th>Title_4</th>
<th>Family_Size_Grouped_1</th>
<th>Family_Size_Grouped_2</th>
<th>Family_Size_Grouped_3</th>
<th>Family_Size_Grouped_4</th>
</tr>
</thead>
<tbody>
<tr>
<td>25</td>
<td>3</td>
<td>2</td>
<td>7</td>
<td>“Hocking, Miss. Ellen Nellie”””””</td>
<td>1</td>
<td>944</td>
<td>2</td>
<td>0</td>
<td>2</td>
<td></td>
<td>29105</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>0</td>
<td>Hocking</td>
<td>0.5</td>
<td>1</td>
<td>1.0</td>
<td>1</td>
<td>0.75</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr>
<td>49</td>
<td>0</td>
<td>1</td>
<td>12</td>
<td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td>
<td>0</td>
<td>1303</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td></td>
<td>19928</td>
<td>2</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>Minahan</td>
<td>0.5</td>
<td>1</td>
<td>0.5</td>
<td>1</td>
<td>0.5</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr>
<td>74</td>
<td>3</td>
<td>1</td>
<td>5</td>
<td>Lingane, Mr. John</td>
<td>0</td>
<td>1085</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td></td>
<td>235509</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>0</td>
<td>Lingane</td>
<td>0.3838383838383838</td>
<td>0</td>
<td>0.3838383838383838</td>
<td>0</td>
<td>0.3838383838383838</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>
<h2 id="处理缺失的特征值"><a href="#处理缺失的特征值" class="headerlink" title="处理缺失的特征值"></a>处理缺失的特征值</h2><ul>
<li>训练数据 Age，Cabin，Embarked  有缺失的记录</li>
<li>测试数据 Age，Cabin，Fare 有缺失的记录</li>
</ul>
<p>Age，Embarked，Fare 空值记录相对较少，可以用一些统计数据替代，比如平均值，中位数等。而 Cabin 有80%的记录都是</p>
<pre><code class="python">def display_missing(df):
    for col in df.columns.tolist():
        print(&#39;{} column missing values: {}&#39;.format(col, df[col].isnull().sum()))
    print(&#39;\n&#39;)
</code></pre>
<pre><code class="python">dfs = [df_train, df_test]
for df in dfs:
    print(&#39;{}&#39;.format(df.name))
    display_missing(df)
</code></pre>
<pre><code>Training Set
PassengerId column missing values: 0
Survived column missing values: 0
Pclass column missing values: 0
Name column missing values: 0
Sex column missing values: 0
Age column missing values: 177
SibSp column missing values: 0
Parch column missing values: 0
Ticket column missing values: 0
Fare column missing values: 0
Cabin column missing values: 687
Embarked column missing values: 2
</code></pre><p>​<br>​    Test Set<br>​    PassengerId column missing values: 0<br>​    Pclass column missing values: 0<br>​    Name column missing values: 0<br>​    Sex column missing values: 0<br>​    Age column missing values: 86<br>​    SibSp column missing values: 0<br>​    Parch column missing values: 0<br>​    Ticket column missing values: 0<br>​    Fare column missing values: 1<br>​    Cabin column missing values: 327<br>​    Embarked column missing values: 0</p>
<p>​    </p>
<h3 id="Age"><a href="#Age" class="headerlink" title="Age"></a>Age</h3><p>对于缺失的Age特征，我们很容易地想到可以用中位数来替代。但是仔细想想还有更好的方式，比如已知了Pclass（乘客等级），这个数据跟年龄很有相关性，我们可以根据Pclass来更好的填充Age。计算 Age 和 各个属性的相关性。</p>
<pre><code class="python">df_all_corr = df_all.corr().abs().unstack().sort_values(kind=&quot;quicksort&quot;, ascending=False).reset_index()
df_all_corr.rename(columns={&quot;level_0&quot;: &quot;Feature 1&quot;, &quot;level_1&quot;: &quot;Feature 2&quot;, 0: &#39;Correlation Coefficient&#39;}, inplace=True)
pandas_df_to_markdown_table(df_all_corr[df_all_corr[&#39;Feature 1&#39;] == &#39;Age&#39;])
</code></pre>
<table>
<thead>
<tr>
<th>Feature 1</th>
<th>Feature 2</th>
<th>Correlation Coefficient</th>
</tr>
</thead>
<tbody>
<tr>
<td>Age</td>
<td>Age</td>
<td>1.0</td>
</tr>
<tr>
<td>Age</td>
<td>Pclass</td>
<td>0.40810623423644476</td>
</tr>
<tr>
<td>Age</td>
<td>SibSp</td>
<td>0.24369899766477038</td>
</tr>
<tr>
<td>Age</td>
<td>Fare</td>
<td>0.1787398559996414</td>
</tr>
<tr>
<td>Age</td>
<td>Parch</td>
<td>0.15091709036354348</td>
</tr>
<tr>
<td>Age</td>
<td>Survived</td>
<td>0.07722109457217737</td>
</tr>
<tr>
<td>Age</td>
<td>PassengerId</td>
<td>0.028814450421119325</td>
</tr>
</tbody>
</table>
<p>除了乘客等级和年龄有相关性，性别在各自c里的年龄表现也有所区分。</p>
<pre><code class="python">age_by_pclass_sex = df_all.groupby([&#39;Sex&#39;, &#39;Pclass&#39;]).median()[&#39;Age&#39;]
for pclass in range(1, 4):
    for sex in [&#39;female&#39;, &#39;male&#39;]:
        print(&#39;Median age of Pclass {} {}s: {}&#39;.format(pclass, sex, age_by_pclass_sex[sex][pclass]))
print(&#39;Median age of all passengers: {}&#39;.format(df_all[&#39;Age&#39;].median()))
</code></pre>
<pre><code>Median age of Pclass 1 females: 36.0
Median age of Pclass 1 males: 42.0
Median age of Pclass 2 females: 28.0
Median age of Pclass 2 males: 29.5
Median age of Pclass 3 females: 22.0
Median age of Pclass 3 males: 25.0
Median age of all passengers: 28.0
</code></pre><pre><code class="python"># 根据各乘客等级性别填充年龄
df_all[&#39;Age&#39;] = df_all.groupby([&#39;Sex&#39;, &#39;Pclass&#39;])[&#39;Age&#39;].apply(lambda x: x.fillna(x.median()))
</code></pre>
<h3 id="Embarked"><a href="#Embarked" class="headerlink" title="Embarked"></a>Embarked</h3><p>Embarked 有两条缺失数据，都是女性，上流，船票是相同</p>
<pre><code class="python">pandas_df_to_markdown_table(df_all[df_all[&#39;Embarked&#39;].isnull()])
</code></pre>
<table>
<thead>
<tr>
<th>Age</th>
<th>Cabin</th>
<th>Embarked</th>
<th>Fare</th>
<th>Name</th>
<th>Parch</th>
<th>PassengerId</th>
<th>Pclass</th>
<th>Sex</th>
<th>SibSp</th>
<th>Survived</th>
<th>Ticket</th>
</tr>
</thead>
<tbody>
<tr>
<td>38.0</td>
<td>B28</td>
<td></td>
<td>80.0</td>
<td>Icard, Miss. Amelie</td>
<td>0</td>
<td>62</td>
<td>1</td>
<td>female</td>
<td>0</td>
<td>1.0</td>
<td>113572</td>
</tr>
<tr>
<td>62.0</td>
<td>B28</td>
<td></td>
<td>80.0</td>
<td>Stone, Mrs. George Nelson (Martha Evelyn)</td>
<td>0</td>
<td>830</td>
<td>1</td>
<td>female</td>
<td>0</td>
<td>1.0</td>
<td>113572</td>
</tr>
</tbody>
</table>
<p>通过Google搜索，知道Stone, Mrs. George Nelson (Martha Evelyn)女士是在 S (Southampton) 登船</p>
<pre><code class="python">df_all[&#39;Embarked&#39;] = df_all[&#39;Embarked&#39;].fillna(&#39;S&#39;)
</code></pre>
<h3 id="Fare"><a href="#Fare" class="headerlink" title="Fare"></a>Fare</h3><p>Fare 只有一条数据是空的</p>
<pre><code class="python">pandas_df_to_markdown_table(df_all[df_all[&#39;Fare&#39;].isnull()])
</code></pre>
<table>
<thead>
<tr>
<th>Age</th>
<th>Cabin</th>
<th>Embarked</th>
<th>Fare</th>
<th>Name</th>
<th>Parch</th>
<th>PassengerId</th>
<th>Pclass</th>
<th>Sex</th>
<th>SibSp</th>
<th>Survived</th>
<th>Ticket</th>
</tr>
</thead>
<tbody>
<tr>
<td>60.5</td>
<td></td>
<td>S</td>
<td></td>
<td>Storey, Mr. Thomas</td>
<td>0</td>
<td>1044</td>
<td>3</td>
<td>male</td>
<td>0</td>
<td></td>
<td>3701</td>
</tr>
</tbody>
</table>
<pre><code class="python">med_fare = df_all.groupby([&#39;Pclass&#39;, &#39;Parch&#39;, &#39;SibSp&#39;]).Fare.median()[3][0][0]
df_all[&#39;Fare&#39;] = df_all[&#39;Fare&#39;].fillna(med_fare)
</code></pre>
<h3 id="Cabin"><a href="#Cabin" class="headerlink" title="Cabin"></a>Cabin</h3><p>Cabin 缺失最多却不能忽视，因为船舱的位置极有可能影响乘客逃生。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733" alt="船舱示意图" title>
                </div>
                <div class="image-caption">船舱示意图</div>
            </figure>
<pre><code class="python"># 添加数据列甲板，M标示缺失
df_all[&#39;Deck&#39;] = df_all[&#39;Cabin&#39;].apply(lambda s: s[0] if pd.notnull(s) else &#39;M&#39;)
df_all_decks = df_all.groupby([&#39;Deck&#39;, &#39;Pclass&#39;]).count(). \
    drop(columns=[&#39;Survived&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;, &#39;Cabin&#39;, &#39;PassengerId&#39;, &#39;Ticket&#39;]). \
    rename(columns={&#39;Name&#39;: &#39;Count&#39;}).transpose()
pandas_df_to_markdown_table(df_all_decks)
</code></pre>
<p>A|B|C|D|D|E|E|E|F|F|G|M|M|M|T<br>1|1|1|1|2|1|2|3|2|3|3|1|2|3|1<br>—|—|—|—|—|—|—|—|—|—|—|—|—|—|—<br>22|65|94|40|6|34|4|3|13|8|5|67|254|693|1</p>
<pre><code class="python">def get_pclass_dist(df):
    # Creating a dictionary for every passenger class count in every deck
    deck_counts = {&#39;A&#39;: {}, &#39;B&#39;: {}, &#39;C&#39;: {}, &#39;D&#39;: {}, &#39;E&#39;: {}, &#39;F&#39;: {}, &#39;G&#39;: {}, &#39;M&#39;: {}, &#39;T&#39;: {}}
    decks = df.columns.levels[0]

    for deck in decks:
        for pclass in range(1, 4):
            try:
                count = df[deck][pclass][0]
                deck_counts[deck][pclass] = count
            except KeyError:
                deck_counts[deck][pclass] = 0

    df_decks = pd.DataFrame(deck_counts)
    deck_percentages = {}

    # Creating a dictionary for every passenger class percentage in every deck
    for col in df_decks.columns:
        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]

    return deck_counts, deck_percentages


def display_pclass_dist(percentages):
    df_percentages = pd.DataFrame(percentages).transpose()
    deck_names = (&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;M&#39;, &#39;T&#39;)
    bar_count = np.arange(len(deck_names))
    bar_width = 0.85

    pclass1 = df_percentages[0]
    pclass2 = df_percentages[1]
    pclass3 = df_percentages[2]

    plt.figure(figsize=(20, 10))
    plt.bar(bar_count, pclass1, color=&#39;#b5ffb9&#39;, edgecolor=&#39;white&#39;, width=bar_width, label=&#39;Passenger Class 1&#39;)
    plt.bar(bar_count, pclass2, bottom=pclass1, color=&#39;#f9bc86&#39;, edgecolor=&#39;white&#39;, width=bar_width,
            label=&#39;Passenger Class 2&#39;)
    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color=&#39;#a3acff&#39;, edgecolor=&#39;white&#39;, width=bar_width,
            label=&#39;Passenger Class 3&#39;)

    plt.xlabel(&#39;Deck&#39;, size=15, labelpad=20)
    plt.ylabel(&#39;Passenger Class Percentage&#39;, size=15, labelpad=20)
    plt.xticks(bar_count, deck_names)
    plt.tick_params(axis=&#39;x&#39;, labelsize=15)
    plt.tick_params(axis=&#39;y&#39;, labelsize=15)

    plt.legend(loc=&#39;upper left&#39;, bbox_to_anchor=(1, 1), prop={&#39;size&#39;: 15})
    plt.title(&#39;Passenger Class Distribution in Decks&#39;, size=18, y=1.05)

    plt.show()


all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)
display_pclass_dist(all_deck_per)
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_38_0.png" alt="png"></p>
<pre><code class="python">pandas_df_to_markdown_table(df_all[df_all[&#39;Deck&#39;] == &#39;T&#39;])
</code></pre>
<table>
<thead>
<tr>
<th>Age</th>
<th>Cabin</th>
<th>Embarked</th>
<th>Fare</th>
<th>Name</th>
<th>Parch</th>
<th>PassengerId</th>
<th>Pclass</th>
<th>Sex</th>
<th>SibSp</th>
<th>Survived</th>
<th>Ticket</th>
<th>Deck</th>
</tr>
</thead>
<tbody>
<tr>
<td>45.0</td>
<td>T</td>
<td>S</td>
<td>35.5</td>
<td>Blackwell, Mr. Stephen Weart</td>
<td>0</td>
<td>340</td>
<td>1</td>
<td>male</td>
<td>0</td>
<td>0.0</td>
<td>113784</td>
<td>T</td>
</tr>
</tbody>
</table>
<pre><code class="python"># T甲板只有一个乘客，且这个乘客是高级船舱的，是异常数据，将这个乘客归到A甲板
idx = df_all[df_all[&#39;Deck&#39;] == &#39;T&#39;].index
df_all.loc[idx, &#39;Deck&#39;] = &#39;A&#39;
</code></pre>
<pre><code class="python">df_all_decks_survived = df_all.groupby([&#39;Deck&#39;, &#39;Survived&#39;]).count() \
    .drop(columns=[&#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;, &#39;Pclass&#39;, &#39;Cabin&#39;, &#39;PassengerId&#39;, &#39;Ticket&#39;]) \
    .rename(columns={&#39;Name&#39;: &#39;Count&#39;}).transpose()

df_all_decks_survived


def get_survived_dist(df):
    # Creating a dictionary for every survival count in every deck
    surv_counts = {&#39;A&#39;: {}, &#39;B&#39;: {}, &#39;C&#39;: {}, &#39;D&#39;: {}, &#39;E&#39;: {}, &#39;F&#39;: {}, &#39;G&#39;: {}, &#39;M&#39;: {}}
    decks = df.columns.levels[0]

    for deck in decks:
        for survive in range(0, 2):
            surv_counts[deck][survive] = df[deck][survive][0]

    df_surv = pd.DataFrame(surv_counts)
    surv_percentages = {}

    for col in df_surv.columns:
        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]

    return surv_counts, surv_percentages


def display_surv_dist(percentages):
    df_survived_percentages = pd.DataFrame(percentages).transpose()
    deck_names = (&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;M&#39;)
    bar_count = np.arange(len(deck_names))
    bar_width = 0.85

    not_survived = df_survived_percentages[0]
    survived = df_survived_percentages[1]

    plt.figure(figsize=(20, 10))
    plt.bar(bar_count, not_survived, color=&#39;#b5ffb9&#39;, edgecolor=&#39;white&#39;, width=bar_width, label=&quot;Not Survived&quot;)
    plt.bar(bar_count, survived, bottom=not_survived, color=&#39;#f9bc86&#39;, edgecolor=&#39;white&#39;, width=bar_width,
            label=&quot;Survived&quot;)

    plt.xlabel(&#39;Deck&#39;, size=15, labelpad=20)
    plt.ylabel(&#39;Survival Percentage&#39;, size=15, labelpad=20)
    plt.xticks(bar_count, deck_names)
    plt.tick_params(axis=&#39;x&#39;, labelsize=15)
    plt.tick_params(axis=&#39;y&#39;, labelsize=15)

    plt.legend(loc=&#39;upper left&#39;, bbox_to_anchor=(1, 1), prop={&#39;size&#39;: 15})
    plt.title(&#39;Survival Percentage in Decks&#39;, size=18, y=1.05)

    plt.show()


all_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)
display_surv_dist(all_surv_per)
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_41_0.png" alt="png"></p>
<p>如同所预料的，每个甲板（船舱）都有不同的生存几率，这个信息不能被简单的丢弃。<br>B，C，D，E 有最高的生还率，这些船舱主要由高等级乘客组成。结论就是高等级的乘客比中级乘客和普通乘客有更高的生还率。<br>我认为，M甲板（缺失船舱数据）生存率最低因为无法死者很有可能无法获得确切的信息。<br>甲板这个属性是高数量类别特征（Deck feature has high-cardinality  ），可以根据相似度进行分类：</p>
<ul>
<li>A，B，C 归类为ABC，因为他们都是高级乘客</li>
<li>D，E 归类为DE 因为他们有相似的乘客分布</li>
<li>F，G 归类为FG，原因同上</li>
<li>M 自成一类，因为他蕴含了不同的信息</li>
</ul>
<pre><code class="python">df_all[&#39;Deck&#39;] = df_all[&#39;Deck&#39;].replace([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;], &#39;ABC&#39;)
df_all[&#39;Deck&#39;] = df_all[&#39;Deck&#39;].replace([&#39;D&#39;, &#39;E&#39;], &#39;DE&#39;)
df_all[&#39;Deck&#39;] = df_all[&#39;Deck&#39;].replace([&#39;F&#39;, &#39;G&#39;], &#39;FG&#39;)

df_all[&#39;Deck&#39;].value_counts()
</code></pre>
<pre><code>M      1014
ABC     182
DE       87
FG       26
Name: Deck, dtype: int64
</code></pre><p>cabin 属性可以丢弃了</p>
<pre><code class="python">df_all.drop([&#39;Cabin&#39;], inplace=True, axis=1)

df_train, df_test = divide_df(df_all)
dfs = [df_train, df_test]

for df in dfs:
    display_missing(df)
</code></pre>
<pre><code>Age column missing values: 0
Embarked column missing values: 0
Fare column missing values: 0
Name column missing values: 0
Parch column missing values: 0
PassengerId column missing values: 0
Pclass column missing values: 0
Sex column missing values: 0
SibSp column missing values: 0
Survived column missing values: 0
Ticket column missing values: 0
Deck column missing values: 0
</code></pre><p>​<br>​    Age column missing values: 0<br>​    Embarked column missing values: 0<br>​    Fare column missing values: 0<br>​    Name column missing values: 0<br>​    Parch column missing values: 0<br>​    PassengerId column missing values: 0<br>​    Pclass column missing values: 0<br>​    Sex column missing values: 0<br>​    SibSp column missing values: 0<br>​    Ticket column missing values: 0<br>​    Deck column missing values: 0</p>
<p>​    </p>
<pre><code class="python">survived = df_train[&#39;Survived&#39;].value_counts()[1]
not_survived = df_train[&#39;Survived&#39;].value_counts()[0]
survived_per = survived / df_train.shape[0] * 100
not_survived_per = not_survived / df_train.shape[0] * 100

print(&#39;{} of {} passengers survived and it is the {:.2f}% of the training set.&#39;.format(survived, df_train.shape[0],
                                                                                       survived_per))
print(&#39;{} of {} passengers didnt survive and it is the {:.2f}% of the training set.&#39;.format(not_survived,
                                                                                            df_train.shape[0],
                                                                                            not_survived_per))

plt.figure(figsize=(10, 8))
sns.countplot(df_train[&#39;Survived&#39;])

plt.xlabel(&#39;Survival&#39;, size=15, labelpad=15)
plt.ylabel(&#39;Passenger Count&#39;, size=15, labelpad=15)
plt.xticks((0, 1), [&#39;Not Survived ({0:.2f}%)&#39;.format(not_survived_per), &#39;Survived ({0:.2f}%)&#39;.format(survived_per)])
plt.tick_params(axis=&#39;x&#39;, labelsize=13)
plt.tick_params(axis=&#39;y&#39;, labelsize=13)

plt.title(&#39;Training Set Survival Distribution&#39;, size=15, y=1.05)

plt.show()
</code></pre>
<pre><code>342 of 891 passengers survived and it is the 38.38% of the training set.
549 of 891 passengers didnt survive and it is the 61.62% of the training set.
</code></pre><p><img src="/2019/06/22/titanic_advanced/output_46_1.png" alt="png"></p>
<h3 id="数据相关性"><a href="#数据相关性" class="headerlink" title="数据相关性"></a>数据相关性</h3><pre><code class="python">df_train_corr = df_train.drop([&#39;PassengerId&#39;], axis=1).corr().abs().unstack().sort_values(kind=&quot;quicksort&quot;,
                                                                                          ascending=False).reset_index()
df_train_corr.rename(columns={&quot;level_0&quot;: &quot;Feature 1&quot;, &quot;level_1&quot;: &quot;Feature 2&quot;, 0: &#39;Correlation Coefficient&#39;},
                     inplace=True)
df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)
df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr[&#39;Correlation Coefficient&#39;] == 1.0].index)

df_test_corr = df_test.corr().abs().unstack().sort_values(kind=&quot;quicksort&quot;, ascending=False).reset_index()
df_test_corr.rename(columns={&quot;level_0&quot;: &quot;Feature 1&quot;, &quot;level_1&quot;: &quot;Feature 2&quot;, 0: &#39;Correlation Coefficient&#39;},
                    inplace=True)
df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)
df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr[&#39;Correlation Coefficient&#39;] == 1.0].index)

# Training set high correlations
corr = df_train_corr_nd[&#39;Correlation Coefficient&#39;] &gt; 0.1

pandas_df_to_markdown_table(df_train_corr_nd[corr])
</code></pre>
<table>
<thead>
<tr>
<th>Feature 1</th>
<th>Feature 2</th>
<th>Correlation Coefficient</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pclass</td>
<td>Fare</td>
<td>0.5494996199439061</td>
</tr>
<tr>
<td>Pclass</td>
<td>Age</td>
<td>0.41766723369886644</td>
</tr>
<tr>
<td>SibSp</td>
<td>Parch</td>
<td>0.41483769862015263</td>
</tr>
<tr>
<td>Survived</td>
<td>Pclass</td>
<td>0.33848103596101586</td>
</tr>
<tr>
<td>Survived</td>
<td>Fare</td>
<td>0.2573065223849618</td>
</tr>
<tr>
<td>SibSp</td>
<td>Age</td>
<td>0.24974662870955514</td>
</tr>
<tr>
<td>Parch</td>
<td>Fare</td>
<td>0.21622494477076254</td>
</tr>
<tr>
<td>Age</td>
<td>Parch</td>
<td>0.17673256218946698</td>
</tr>
<tr>
<td>SibSp</td>
<td>Fare</td>
<td>0.15965104324216103</td>
</tr>
<tr>
<td>Age</td>
<td>Fare</td>
<td>0.12406104601800909</td>
</tr>
</tbody>
</table>
<pre><code class="python"># Test set high correlations
corr = df_test_corr_nd[&#39;Correlation Coefficient&#39;] &gt; 0.1
pandas_df_to_markdown_table(df_test_corr_nd[corr])
</code></pre>
<table>
<thead>
<tr>
<th>Feature 1</th>
<th>Feature 2</th>
<th>Correlation Coefficient</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fare</td>
<td>Pclass</td>
<td>0.5774887948232105</td>
</tr>
<tr>
<td>Age</td>
<td>Pclass</td>
<td>0.5267887447504006</td>
</tr>
<tr>
<td>Age</td>
<td>Fare</td>
<td>0.3453471879464391</td>
</tr>
<tr>
<td>SibSp</td>
<td>Parch</td>
<td>0.30689461547590147</td>
</tr>
<tr>
<td>Fare</td>
<td>Parch</td>
<td>0.2304099972191158</td>
</tr>
<tr>
<td>SibSp</td>
<td>Fare</td>
<td>0.17203193101051656</td>
</tr>
</tbody>
</table>
<pre><code class="python">fig, axs = plt.subplots(nrows=2, figsize=(20, 20))

sns.heatmap(df_train.drop([&#39;PassengerId&#39;], axis=1).corr(), ax=axs[0], annot=True, square=True, cmap=&#39;coolwarm&#39;,
            annot_kws={&#39;size&#39;: 14})
sns.heatmap(df_test.drop([&#39;PassengerId&#39;], axis=1).corr(), ax=axs[1], annot=True, square=True, cmap=&#39;coolwarm&#39;,
            annot_kws={&#39;size&#39;: 14})

for i in range(2):
    axs[i].tick_params(axis=&#39;x&#39;, labelsize=14)
    axs[i].tick_params(axis=&#39;y&#39;, labelsize=14)

axs[0].set_title(&#39;Training Set Correlations&#39;, size=15)
axs[1].set_title(&#39;Test Set Correlations&#39;, size=15)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_50_0.png" alt="png"></p>
<h3 id="各个特征的生存分布"><a href="#各个特征的生存分布" class="headerlink" title="各个特征的生存分布"></a>各个特征的生存分布</h3><h4 id="连续型特征"><a href="#连续型特征" class="headerlink" title="连续型特征"></a>连续型特征</h4><p>-两个特征都有明显的分割点和尖峰，这有利于决策树算法<br>-低于十五岁的乘客有更高的生存率<br>-船费特征中，生存率在分布末段更高</p>
<pre><code class="python">cont_features = [&#39;Age&#39;, &#39;Fare&#39;]
surv = df_train[&#39;Survived&#39;] == 1

fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))
plt.subplots_adjust(right=1.5)

for i, feature in enumerate(cont_features):
    # Distribution of survival in feature
    sns.distplot(df_train[~surv][feature], label=&#39;Not Survived&#39;, hist=True, color=&#39;#e74c3c&#39;, ax=axs[0][i])
    sns.distplot(df_train[surv][feature], label=&#39;Survived&#39;, hist=True, color=&#39;#2ecc71&#39;, ax=axs[0][i])

    # Distribution of feature in dataset
    sns.distplot(df_train[feature], label=&#39;Training Set&#39;, hist=False, color=&#39;#e74c3c&#39;, ax=axs[1][i])
    sns.distplot(df_test[feature], label=&#39;Test Set&#39;, hist=False, color=&#39;#2ecc71&#39;, ax=axs[1][i])

    axs[0][i].set_xlabel(&#39;&#39;)
    axs[1][i].set_xlabel(&#39;&#39;)

    for j in range(2):
        axs[i][j].tick_params(axis=&#39;x&#39;, labelsize=20)
        axs[i][j].tick_params(axis=&#39;y&#39;, labelsize=20)

    axs[0][i].legend(loc=&#39;upper right&#39;, prop={&#39;size&#39;: 20})
    axs[1][i].legend(loc=&#39;upper right&#39;, prop={&#39;size&#39;: 20})
    axs[0][i].set_title(&#39;Distribution of Survival in {}&#39;.format(feature), size=20, y=1.05)

axs[1][0].set_title(&#39;Distribution of {} Feature&#39;.format(&#39;Age&#39;), size=20, y=1.05)
axs[1][1].set_title(&#39;Distribution of {} Feature&#39;.format(&#39;Fare&#39;), size=20, y=1.05)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_53_0.png" alt="png"></p>
<h3 id="离散型特征"><a href="#离散型特征" class="headerlink" title="离散型特征"></a>离散型特征</h3><ul>
<li>每一个离散型特征都有一个类别有比较低的死亡率，这有助于判断是否生还</li>
<li>从S登船的乘客生还率比较低，而从C登船的乘客有超过一半都生还了，这可能和Pclass有关</li>
<li>Parch和SibSp 表明只有一个家庭成员的乘客有更高的生还率</li>
<li>最佳的分类特征是Pclass和Sex，因为他们是最同质的分类（没搞懂）</li>
</ul>
<pre><code class="python">cat_features = [&#39;Embarked&#39;, &#39;Parch&#39;, &#39;Pclass&#39;, &#39;Sex&#39;, &#39;SibSp&#39;, &#39;Deck&#39;]

fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))
plt.subplots_adjust(right=1.5, top=1.25)

for i, feature in enumerate(cat_features, 1):
    plt.subplot(2, 3, i)
    sns.countplot(x=feature, hue=&#39;Survived&#39;, data=df_train)

    plt.xlabel(&#39;{}&#39;.format(feature), size=20, labelpad=15)
    plt.ylabel(&#39;Passenger Count&#39;, size=20, labelpad=15)
    plt.tick_params(axis=&#39;x&#39;, labelsize=20)
    plt.tick_params(axis=&#39;y&#39;, labelsize=20)

    plt.legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper center&#39;, prop={&#39;size&#39;: 18})
    plt.title(&#39;Count of Survival in {} Feature&#39;.format(feature), size=20, y=1.05)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_55_0.png" alt="png"></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><ul>
<li>大部分的特征都互相关联。这种关联可以用来创造新的特征</li>
<li>连续型特征分布的分割点和尖峰很明显，不幸的是只有两个连续型特征。这些信息能够被决策树算法很好的捕捉到，但神经网络可能不行。</li>
<li>离散型特征中各个分类有着明显不同的生还率。这些类别可以用来进行 One-hot encoding（独热编码）。某些还可以用来结合其他类别，构造新的特征。</li>
<li>新加了Deck特征，去除了Cabin特征</li>
</ul>
<pre><code class="python">df_all = concat_df(df_train, df_test)
pandas_df_to_markdown_table(df_all.head())
</code></pre>
<table>
<thead>
<tr>
<th>Age</th>
<th>Deck</th>
<th>Embarked</th>
<th>Fare</th>
<th>Name</th>
<th>Parch</th>
<th>PassengerId</th>
<th>Pclass</th>
<th>Sex</th>
<th>SibSp</th>
<th>Survived</th>
<th>Ticket</th>
</tr>
</thead>
<tbody>
<tr>
<td>22.0</td>
<td>M</td>
<td>S</td>
<td>7.25</td>
<td>Braund, Mr. Owen Harris</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>male</td>
<td>1</td>
<td>0.0</td>
<td>A/5 21171</td>
</tr>
<tr>
<td>38.0</td>
<td>ABC</td>
<td>C</td>
<td>71.2833</td>
<td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>
<td>0</td>
<td>2</td>
<td>1</td>
<td>female</td>
<td>1</td>
<td>1.0</td>
<td>PC 17599</td>
</tr>
<tr>
<td>26.0</td>
<td>M</td>
<td>S</td>
<td>7.925</td>
<td>Heikkinen, Miss. Laina</td>
<td>0</td>
<td>3</td>
<td>3</td>
<td>female</td>
<td>0</td>
<td>1.0</td>
<td>STON/O2. 3101282</td>
</tr>
<tr>
<td>35.0</td>
<td>ABC</td>
<td>S</td>
<td>53.1</td>
<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
<td>0</td>
<td>4</td>
<td>1</td>
<td>female</td>
<td>1</td>
<td>1.0</td>
<td>113803</td>
</tr>
<tr>
<td>35.0</td>
<td>M</td>
<td>S</td>
<td>8.05</td>
<td>Allen, Mr. William Henry</td>
<td>0</td>
<td>5</td>
<td>3</td>
<td>male</td>
<td>0</td>
<td>0.0</td>
<td>373450</td>
</tr>
</tbody>
</table>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="连续型特征-1"><a href="#连续型特征-1" class="headerlink" title="连续型特征"></a>连续型特征</h3><h4 id="Fare-1"><a href="#Fare-1" class="headerlink" title="Fare"></a>Fare</h4><ul>
<li>Fare 特征是正偏态分布， 并且生存率在分布右端特别高</li>
<li>Fare 柱状图中分为13组，即使有些数量不是很多，但是也能提供可观的信息增益</li>
<li>分布图左端的死亡率高于右端，这是在分布图中看不到的信息</li>
<li>区间 (15.742, 23.25] 的组有异常高的生存率</li>
</ul>
<pre><code class="python">df_all[&#39;Fare&#39;] = pd.qcut(df_all[&#39;Fare&#39;], 13)

fig, axs = plt.subplots(figsize=(22, 9))
sns.countplot(x=&#39;Fare&#39;, hue=&#39;Survived&#39;, data=df_all)

plt.xlabel(&#39;Fare&#39;, size=15, labelpad=20)
plt.ylabel(&#39;Passenger Count&#39;, size=15, labelpad=20)
plt.tick_params(axis=&#39;x&#39;, labelsize=10)
plt.tick_params(axis=&#39;y&#39;, labelsize=15)

plt.legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper right&#39;, prop={&#39;size&#39;: 15})
plt.title(&#39;Count of Survival in {} Feature&#39;.format(&#39;Fare&#39;), size=15, y=1.05)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_61_0.png" alt="png"></p>
<h4 id="家庭成员数量"><a href="#家庭成员数量" class="headerlink" title="家庭成员数量"></a>家庭成员数量</h4><ul>
<li>Family_Size = SibSp + Parch +1</li>
<li>Family_Size = 1 标记为 Alone</li>
<li>Family_Size = 2,3,4 标记为 Small</li>
<li>Family_Size = 5,6 标记为 Medium</li>
<li>Family_Size = 7,8,11 标记为 Large</li>
</ul>
<pre><code class="python">df_all[&#39;Family_Size&#39;] = df_all[&#39;SibSp&#39;] + df_all[&#39;Parch&#39;] + 1

fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)
plt.subplots_adjust(right=1.5)

sns.barplot(x=df_all[&#39;Family_Size&#39;].value_counts().index, y=df_all[&#39;Family_Size&#39;].value_counts().values, ax=axs[0][0])
sns.countplot(x=&#39;Family_Size&#39;, hue=&#39;Survived&#39;, data=df_all, ax=axs[0][1])

axs[0][0].set_title(&#39;Family Size Feature Value Counts&#39;, size=20, y=1.05)
axs[0][1].set_title(&#39;Survival Counts in Family Size &#39;, size=20, y=1.05)

family_map = {1: &#39;Alone&#39;, 2: &#39;Small&#39;, 3: &#39;Small&#39;, 4: &#39;Small&#39;, 5: &#39;Medium&#39;, 6: &#39;Medium&#39;, 7: &#39;Large&#39;, 8: &#39;Large&#39;,
              11: &#39;Large&#39;}
df_all[&#39;Family_Size_Grouped&#39;] = df_all[&#39;Family_Size&#39;].map(family_map)

sns.barplot(x=df_all[&#39;Family_Size_Grouped&#39;].value_counts().index, y=df_all[&#39;Family_Size_Grouped&#39;].value_counts().values,
            ax=axs[1][0])
sns.countplot(x=&#39;Family_Size_Grouped&#39;, hue=&#39;Survived&#39;, data=df_all, ax=axs[1][1])

axs[1][0].set_title(&#39;Family Size Feature Value Counts After Grouping&#39;, size=20, y=1.05)
axs[1][1].set_title(&#39;Survival Counts in Family Size After Grouping&#39;, size=20, y=1.05)

for i in range(2):
    axs[i][1].legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper right&#39;, prop={&#39;size&#39;: 20})
    for j in range(2):
        axs[i][j].tick_params(axis=&#39;x&#39;, labelsize=20)
        axs[i][j].tick_params(axis=&#39;y&#39;, labelsize=20)
        axs[i][j].set_xlabel(&#39;&#39;)
        axs[i][j].set_ylabel(&#39;&#39;)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_63_0.png" alt="png"></p>
<h4 id="船票频率"><a href="#船票频率" class="headerlink" title="船票频率"></a>船票频率</h4><ul>
<li>这个和Family_Size是不一样的， 除了同一个家庭会使用相同的票，结伴出行的朋友也会使用相同的票</li>
<li>可不可以将tickets 按船票的前缀分组？如果船票的特征有什么有用的信息，那么这些信息已经被Pclass 和 Embarked 包含了</li>
<li>船票频率分布和Family_size分布很像</li>
<li>船票频率不需要像Family_size那样分组，因为相似性太高了。这样的特征不会提供任何有用的信息</li>
</ul>
<pre><code class="python">df_all[&#39;Ticket_Frequency&#39;] = df_all.groupby(&#39;Ticket&#39;)[&#39;Ticket&#39;].transform(&#39;count&#39;)

fig, axs = plt.subplots(figsize=(12, 9))
sns.countplot(x=&#39;Ticket_Frequency&#39;, hue=&#39;Survived&#39;, data=df_all)

plt.xlabel(&#39;Ticket Frequency&#39;, size=15, labelpad=20)
plt.ylabel(&#39;Passenger Count&#39;, size=15, labelpad=20)
plt.tick_params(axis=&#39;x&#39;, labelsize=15)
plt.tick_params(axis=&#39;y&#39;, labelsize=15)

plt.legend([&#39;Not Survived&#39;, &#39;Survived&#39;], loc=&#39;upper right&#39;, prop={&#39;size&#39;: 15})
plt.title(&#39;Count of Survival in {} Feature&#39;.format(&#39;Ticket Frequency&#39;), size=15, y=1.05)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_65_0.png" alt="png"></p>
<h4 id="称谓和婚姻状况"><a href="#称谓和婚姻状况" class="headerlink" title="称谓和婚姻状况"></a>称谓和婚姻状况</h4><ul>
<li>Title 是 从 Name 属性的前缀截取而来</li>
<li>Is_Married 根据 Title 中是否包含 Mrs 得来。</li>
</ul>
<pre><code class="python">df_all[&#39;Title&#39;] = df_all[&#39;Name&#39;].str.split(&#39;, &#39;, expand=True)[1].str.split(&#39;.&#39;, expand=True)[0]
df_all[&#39;Is_Married&#39;] = 0
df_all[&#39;Is_Married&#39;].loc[df_all[&#39;Title&#39;] == &#39;Mrs&#39;] = 1

fig, axs = plt.subplots(nrows=2, figsize=(20, 20))
sns.barplot(x=df_all[&#39;Title&#39;].value_counts().index, y=df_all[&#39;Title&#39;].value_counts().values, ax=axs[0])

axs[0].tick_params(axis=&#39;x&#39;, labelsize=10)
axs[1].tick_params(axis=&#39;x&#39;, labelsize=15)

for i in range(2):
    axs[i].tick_params(axis=&#39;y&#39;, labelsize=15)

axs[0].set_title(&#39;Title Feature Value Counts&#39;, size=20, y=1.05)

df_all[&#39;Title&#39;] = df_all[&#39;Title&#39;].replace([&#39;Miss&#39;, &#39;Mrs&#39;, &#39;Ms&#39;, &#39;Mlle&#39;, &#39;Lady&#39;, &#39;Mme&#39;, &#39;the Countess&#39;, &#39;Dona&#39;],
                                          &#39;Miss/Mrs/Ms&#39;)
df_all[&#39;Title&#39;] = df_all[&#39;Title&#39;].replace([&#39;Dr&#39;, &#39;Col&#39;, &#39;Major&#39;, &#39;Jonkheer&#39;, &#39;Capt&#39;, &#39;Sir&#39;, &#39;Don&#39;, &#39;Rev&#39;],
                                          &#39;Dr/Military/Noble/Clergy&#39;)

sns.barplot(x=df_all[&#39;Title&#39;].value_counts().index, y=df_all[&#39;Title&#39;].value_counts().values, ax=axs[1])
axs[1].set_title(&#39;Title Feature Value Counts After Grouping&#39;, size=20, y=1.05)

plt.show()
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_67_0.png" alt="png"></p>
<h4 id="生还率"><a href="#生还率" class="headerlink" title="生还率"></a>生还率</h4><ul>
<li>Family_Survival_Rate: 家庭生还率</li>
<li>Ticket_Survival_Rate: 同票生还率</li>
<li>Survival_Rate =(Family_Survival_Rate + Ticket_Survival_Rate )/ 2</li>
</ul>
<pre><code class="python">def extract_surname(data):
    # 提取乘客姓氏，用来对家庭分组
    families = []
    for i in range(len(data)):
        name = data.iloc[i]
        if &#39;(&#39; in name:
            name_no_bracket = name.split(&#39;(&#39;)[0]
        else:
            name_no_bracket = name
        family = name_no_bracket.split(&#39;,&#39;)[0]
        title = name_no_bracket.split(&#39;,&#39;)[1].strip().split(&#39; &#39;)[0]
        for c in string.punctuation:
            family = family.replace(c, &#39;&#39;).strip()
        families.append(family)
    return families
</code></pre>
<pre><code class="python">df_all[&#39;Family&#39;] = extract_surname(df_all[&#39;Name&#39;])
df_train = df_all.loc[:890]
df_test = df_all.loc[891:]
dfs = [df_train, df_test]
</code></pre>
<pre><code class="python"># Creating a list of families and tickets that are occuring in both training and test set
non_unique_families = [x for x in df_train[&#39;Family&#39;].unique() if x in df_test[&#39;Family&#39;].unique()]
non_unique_tickets = [x for x in df_train[&#39;Ticket&#39;].unique() if x in df_test[&#39;Ticket&#39;].unique()]
</code></pre>
<pre><code class="python">df_family_survival_rate = df_train.groupby(&#39;Family&#39;)[&#39;Survived&#39;, &#39;Family&#39;, &#39;Family_Size&#39;].median()
df_ticket_survival_rate = df_train.groupby(&#39;Ticket&#39;)[&#39;Survived&#39;, &#39;Ticket&#39;, &#39;Ticket_Frequency&#39;].median()
</code></pre>
<pre><code class="python">family_rates = {}
ticket_rates = {}
</code></pre>
<pre><code class="python">for i in range(len(df_family_survival_rate)):
    # Checking a family exists in both training and test set, and has members more than 1
    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] &gt; 1:
        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]
</code></pre>
<pre><code class="python">for i in range(len(df_ticket_survival_rate)):
    # Checking a ticket exists in both training and test set, and has members more than 1
    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] &gt; 1:
        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]
</code></pre>
<pre><code class="python">mean_survival_rate = np.mean(df_train[&#39;Survived&#39;])
</code></pre>
<pre><code class="python">train_family_survival_rate = []
train_family_survival_rate_NA = []
test_family_survival_rate = []
test_family_survival_rate_NA = []
</code></pre>
<pre><code class="python">for i in range(len(df_train)):
    if df_train[&#39;Family&#39;][i] in family_rates:
        train_family_survival_rate.append(family_rates[df_train[&#39;Family&#39;][i]])
        train_family_survival_rate_NA.append(1)
    else:
        train_family_survival_rate.append(mean_survival_rate)
        train_family_survival_rate_NA.append(0)
</code></pre>
<pre><code class="python">for i in range(len(df_test)):
    if df_test[&#39;Family&#39;].iloc[i] in family_rates:
        test_family_survival_rate.append(family_rates[df_test[&#39;Family&#39;].iloc[i]])
        test_family_survival_rate_NA.append(1)
    else:
        test_family_survival_rate.append(mean_survival_rate)
        test_family_survival_rate_NA.append(0)
</code></pre>
<pre><code class="python">df_train[&#39;Family_Survival_Rate&#39;] = train_family_survival_rate
df_train[&#39;Family_Survival_Rate_NA&#39;] = train_family_survival_rate_NA
df_test[&#39;Family_Survival_Rate&#39;] = test_family_survival_rate
df_test[&#39;Family_Survival_Rate_NA&#39;] = test_family_survival_rate_NA
</code></pre>
<pre><code class="python">train_ticket_survival_rate = []
train_ticket_survival_rate_NA = []
test_ticket_survival_rate = []
test_ticket_survival_rate_NA = []
</code></pre>
<pre><code class="python">for i in range(len(df_train)):
    if df_train[&#39;Ticket&#39;][i] in ticket_rates:
        train_ticket_survival_rate.append(ticket_rates[df_train[&#39;Ticket&#39;][i]])
        train_ticket_survival_rate_NA.append(1)
    else:
        train_ticket_survival_rate.append(mean_survival_rate)
        train_ticket_survival_rate_NA.append(0)
</code></pre>
<pre><code class="python">for i in range(len(df_test)):
    if df_test[&#39;Ticket&#39;].iloc[i] in ticket_rates:
        test_ticket_survival_rate.append(ticket_rates[df_test[&#39;Ticket&#39;].iloc[i]])
        test_ticket_survival_rate_NA.append(1)
    else:
        test_ticket_survival_rate.append(mean_survival_rate)
        test_ticket_survival_rate_NA.append(0)
</code></pre>
<pre><code class="python">df_train[&#39;Ticket_Survival_Rate&#39;] = train_ticket_survival_rate
df_train[&#39;Ticket_Survival_Rate_NA&#39;] = train_ticket_survival_rate_NA
df_test[&#39;Ticket_Survival_Rate&#39;] = test_ticket_survival_rate
df_test[&#39;Ticket_Survival_Rate_NA&#39;] = test_ticket_survival_rate_NA
</code></pre>
<pre><code class="python">for df in [df_train, df_test]:
    df[&#39;Survival_Rate&#39;] = (df[&#39;Ticket_Survival_Rate&#39;] + df[&#39;Family_Survival_Rate&#39;]) / 2
    df[&#39;Survival_Rate_NA&#39;] = (df[&#39;Ticket_Survival_Rate_NA&#39;] + df[&#39;Family_Survival_Rate_NA&#39;]) / 2
</code></pre>
<h4 id="Frature-Transformation"><a href="#Frature-Transformation" class="headerlink" title="Frature Transformation"></a>Frature Transformation</h4><h5 id="标签编码（Label-Encoding）"><a href="#标签编码（Label-Encoding）" class="headerlink" title="标签编码（Label Encoding）"></a>标签编码（Label Encoding）</h5><p>将类型编码为0,1,…,n</p>
<pre><code class="python">non_numeric_features = [&#39;Embarked&#39;, &#39;Sex&#39;, &#39;Deck&#39;, &#39;Title&#39;, &#39;Family_Size_Grouped&#39;, &#39;Age&#39;, &#39;Fare&#39;]
for df in dfs:
    for feature in non_numeric_features:
        df[feature] = LabelEncoder().fit_transform(df[feature])
</code></pre>
<h5 id="独热编码（One-Hot-Encoding）"><a href="#独热编码（One-Hot-Encoding）" class="headerlink" title="独热编码（One-Hot Encoding）"></a>独热编码（One-Hot Encoding）</h5><pre><code class="python">cat_features = [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Deck&#39;, &#39;Embarked&#39;, &#39;Title&#39;, &#39;Family_Size_Grouped&#39;]
encoded_features = []
for df in dfs:
    for feature in cat_features:
        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()
        n = df[feature].nunique()
        cols = [&#39;{}_{}&#39;.format(feature, n) for n in range(1, n + 1)]
        encoded_df = pd.DataFrame(encoded_feat, columns=cols)
        encoded_df.index = df.index
        encoded_features.append(encoded_df)
df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)
df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)
</code></pre>
<h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><pre><code class="python">df_all = concat_df(df_train, df_test)
drop_cols = [&#39;Deck&#39;, &#39;Embarked&#39;, &#39;Family&#39;, &#39;Family_Size&#39;, &#39;Family_Size_Grouped&#39;, &#39;Survived&#39;,
             &#39;Name&#39;, &#39;Parch&#39;, &#39;PassengerId&#39;, &#39;Pclass&#39;, &#39;Sex&#39;, &#39;SibSp&#39;, &#39;Ticket&#39;, &#39;Title&#39;,
             &#39;Ticket_Survival_Rate&#39;, &#39;Family_Survival_Rate&#39;, &#39;Ticket_Survival_Rate_NA&#39;, &#39;Family_Survival_Rate_NA&#39;]
df_all.drop(columns=drop_cols, inplace=True)
pandas_df_to_markdown_table(df_all.head())
</code></pre>
<table>
<thead>
<tr>
<th>Age</th>
<th>Deck_1</th>
<th>Deck_2</th>
<th>Deck_3</th>
<th>Deck_4</th>
<th>Embarked_1</th>
<th>Embarked_2</th>
<th>Embarked_3</th>
<th>Family_Size_Grouped_1</th>
<th>Family_Size_Grouped_2</th>
<th>Family_Size_Grouped_3</th>
<th>Family_Size_Grouped_4</th>
<th>Fare</th>
<th>Is_Married</th>
<th>Pclass_1</th>
<th>Pclass_2</th>
<th>Pclass_3</th>
<th>Sex_1</th>
<th>Sex_2</th>
<th>Survival_Rate</th>
<th>Survival_Rate_NA</th>
<th>Ticket_Frequency</th>
<th>Title_1</th>
<th>Title_2</th>
<th>Title_3</th>
<th>Title_4</th>
</tr>
</thead>
<tbody>
<tr>
<td>28</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0</td>
<td>0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.3838383838383838</td>
<td>0.0</td>
<td>1</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr>
<td>52</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>11</td>
<td>1</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>2</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr>
<td>34</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>3</td>
<td>0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.3838383838383838</td>
<td>0.0</td>
<td>1</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr>
<td>48</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>10</td>
<td>1</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.3838383838383838</td>
<td>0.0</td>
<td>2</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr>
<td>48</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>3</td>
<td>0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.3838383838383838</td>
<td>0.0</td>
<td>1</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>
<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><pre><code class="python">X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))
y_train = df_train[&#39;Survived&#39;].values
X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))
</code></pre>
<pre><code class="python">print(&#39;X_train shape: {}&#39;.format(X_train.shape))
print(&#39;y_train shape: {}&#39;.format(y_train.shape))
print(&#39;X_test shape: {}&#39;.format(X_test.shape))
</code></pre>
<pre><code>X_train shape: (891, 26)
y_train shape: (891,)
X_test shape: (418, 26)
</code></pre><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><pre><code class="python">single_best_model = RandomForestClassifier(criterion=&#39;gini&#39;,
                                           n_estimators=1100,
                                           max_depth=5,
                                           min_samples_split=4,
                                           min_samples_leaf=5,
                                           max_features=&#39;auto&#39;,
                                           oob_score=True,
                                           random_state=SEED,
                                           n_jobs=-1,
                                           verbose=1)
</code></pre>
<pre><code class="python">leaderboard_model = RandomForestClassifier(criterion=&#39;gini&#39;,
                                           n_estimators=1750,
                                           max_depth=7,
                                           min_samples_split=6,
                                           min_samples_leaf=6,
                                           max_features=&#39;auto&#39;,
                                           oob_score=True,
                                           random_state=SEED,
                                           n_jobs=-1,
                                           verbose=1)
</code></pre>
<pre><code class="python">N = 5
oob = 0
probs = pd.DataFrame(np.zeros((len(X_test), N * 2)),
                     columns=[&#39;Fold_{}_Prob_{}&#39;.format(i, j) for i in range(1, N + 1) for j in range(2)])
importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=[&#39;Fold_{}&#39;.format(i) for i in range(1, N + 1)],
                           index=df_all.columns)
fprs, tprs, scores = [], [], []
skf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)
for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):
    print(&#39;Fold {}\n&#39;.format(fold))
    # Fitting the model
    leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])
    # Computing Train AUC score
    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx],
                                                 leaderboard_model.predict_proba(X_train[trn_idx])[:, 1])
    trn_auc_score = auc(trn_fpr, trn_tpr)
    # Computing Validation AUC score
    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx],
                                                 leaderboard_model.predict_proba(X_train[val_idx])[:, 1])
    val_auc_score = auc(val_fpr, val_tpr)
    scores.append((trn_auc_score, val_auc_score))
    fprs.append(val_fpr)
    tprs.append(val_tpr)
    # X_test probabilities
    probs.loc[:, &#39;Fold_{}_Prob_0&#39;.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 0]
    probs.loc[:, &#39;Fold_{}_Prob_1&#39;.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 1]
    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_
    oob += leaderboard_model.oob_score_ / N
    print(&#39;Fold {} OOB Score: {}\n&#39;.format(fold, leaderboard_model.oob_score_))
print(&#39;Average OOB Score: {}&#39;.format(oob))
</code></pre>
<pre><code>Fold 1



[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.3s
[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.1s
[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s
[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished


Fold 1 OOB Score: 0.8581460674157303

Fold 2



[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.3s
[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.0s
[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.6s
[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.3s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.8s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished


Fold 2 OOB Score: 0.851123595505618

Fold 3



[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.2s
[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.0s
[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s
[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished


Fold 3 OOB Score: 0.8330995792426368

Fold 4



[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.2s
[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.1s
[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s
[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.4s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished


Fold 4 OOB Score: 0.8401122019635343

Fold 5



[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.3s
[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    1.1s
[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.7s
[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:    2.4s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.5s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished
[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.
[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s
[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.1s
[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.2s
[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s
[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.5s
[Parallel(n_jobs=16)]: Done 1750 out of 1750 | elapsed:    0.7s finished


Fold 5 OOB Score: 0.8431372549019608

Average OOB Score: 0.8451237398058962
</code></pre><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><h4 id="Feature-Importance"><a href="#Feature-Importance" class="headerlink" title="Feature Importance"></a>Feature Importance</h4><pre><code class="python">importances[&#39;Mean_Importance&#39;] = importances.mean(axis=1)
importances.sort_values(by=&#39;Mean_Importance&#39;, inplace=True, ascending=False)
plt.figure(figsize=(15, 20))
sns.barplot(x=&#39;Mean_Importance&#39;, y=importances.index, data=importances)
plt.xlabel(&#39;&#39;)
plt.tick_params(axis=&#39;x&#39;, labelsize=15)
plt.tick_params(axis=&#39;y&#39;, labelsize=15)
plt.title(&#39;Random Forest Classifier Mean Feature Importance Between Folds&#39;, size=15)
</code></pre>
<pre><code>Text(0.5, 1.0, &#39;Random Forest Classifier Mean Feature Importance Between Folds&#39;)
</code></pre><p><img src="/2019/06/22/titanic_advanced/output_102_1.png" alt="png"></p>
<pre><code class="python">plt.show()
</code></pre>
<h4 id="Roc-Curve"><a href="#Roc-Curve" class="headerlink" title="Roc Curve"></a>Roc Curve</h4><pre><code class="python">def plot_roc_curve(fprs, tprs):
    tprs_interp = []
    aucs = []
    mean_fpr = np.linspace(0, 1, 100)
    f, ax = plt.subplots(figsize=(15, 15))
    # Plotting ROC for each fold and computing AUC scores
    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):
        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))
        tprs_interp[-1][0] = 0.0
        roc_auc = auc(fpr, tpr)
        aucs.append(roc_auc)
        ax.plot(fpr, tpr, lw=1, alpha=0.3, label=&#39;ROC Fold {} (AUC = {:.3f})&#39;.format(i, roc_auc))
    # Plotting ROC for random guessing
    plt.plot([0, 1], [0, 1], linestyle=&#39;--&#39;, lw=2, color=&#39;r&#39;, alpha=0.8, label=&#39;Random Guessing&#39;)
    mean_tpr = np.mean(tprs_interp, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    std_auc = np.std(aucs)
    # Plotting the mean ROC
    ax.plot(mean_fpr, mean_tpr, color=&#39;b&#39;, label=&#39;Mean ROC (AUC = {:.3f} $\pm$ {:.3f})&#39;.format(mean_auc, std_auc), lw=2,
            alpha=0.8)
    # Plotting the standard deviation around the mean ROC Curve
    std_tpr = np.std(tprs_interp, axis=0)
    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color=&#39;grey&#39;, alpha=.2, label=&#39;$\pm$ 1 std. dev.&#39;)

    ax.set_xlabel(&#39;False Positive Rate&#39;, size=15, labelpad=20)
    ax.set_ylabel(&#39;True Positive Rate&#39;, size=15, labelpad=20)
    ax.tick_params(axis=&#39;x&#39;, labelsize=15)
    ax.tick_params(axis=&#39;y&#39;, labelsize=15)
    ax.set_xlim([-0.05, 1.05])
    ax.set_ylim([-0.05, 1.05])

    ax.set_title(&#39;ROC Curves of Folds&#39;, size=20, y=1.02)
    ax.legend(loc=&#39;lower right&#39;, prop={&#39;size&#39;: 13})

    plt.show()
</code></pre>
<pre><code class="python">plot_roc_curve(fprs, tprs)
</code></pre>
<p><img src="/2019/06/22/titanic_advanced/output_106_0.png" alt="png"></p>
<h2 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h2><pre><code class="python">class_survived = [col for col in probs.columns if col.endswith(&#39;Prob_1&#39;)]
probs[&#39;1&#39;] = probs[class_survived].sum(axis=1) / N
probs[&#39;0&#39;] = probs.drop(columns=class_survived).sum(axis=1) / N
probs[&#39;pred&#39;] = 0
pos = probs[probs[&#39;1&#39;] &gt;= 0.5].index
probs.loc[pos, &#39;pred&#39;] = 1
</code></pre>
<pre><code class="python">y_pred = probs[&#39;pred&#39;].astype(int)
</code></pre>
<pre><code class="python">submission_df = pd.DataFrame(columns=[&#39;PassengerId&#39;, &#39;Survived&#39;])
submission_df[&#39;PassengerId&#39;] = df_test[&#39;PassengerId&#39;]
submission_df[&#39;Survived&#39;] = y_pred.values
submission_df.to_csv(&#39;submissions.csv&#39;, header=True, index=False)
pandas_df_to_markdown_table(submission_df.head(10))
</code></pre>
<table>
<thead>
<tr>
<th>PassengerId</th>
<th>Survived</th>
</tr>
</thead>
<tbody>
<tr>
<td>892</td>
<td>0</td>
</tr>
<tr>
<td>893</td>
<td>1</td>
</tr>
<tr>
<td>894</td>
<td>0</td>
</tr>
<tr>
<td>895</td>
<td>0</td>
</tr>
<tr>
<td>896</td>
<td>1</td>
</tr>
<tr>
<td>897</td>
<td>0</td>
</tr>
<tr>
<td>898</td>
<td>1</td>
</tr>
<tr>
<td>899</td>
<td>0</td>
</tr>
<tr>
<td>900</td>
<td>1</td>
</tr>
<tr>
<td>901</td>
<td>0</td>
</tr>
</tbody>
</table>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-08-17T07:44:00.831Z" itemprop="dateUpdated">2019-08-17 15:44:00</time>
</span><br>


        
        原始链接：<a href="/2019/06/22/titanic_advanced/" target="_blank" rel="external">https://lincy.online/2019/06/22/titanic_advanced/</a>
        
    </div>
    
    <footer>
        <a href="https://lincy.online">
            <img src="/img/avatar.jpg" alt="Lincy">
            Lincy
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://lincy.online/2019/06/22/titanic_advanced/&title=《Titanic - Machine Learning from Disaster》 — Lincy's Blog&pic=https://lincy.online/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://lincy.online/2019/06/22/titanic_advanced/&title=《Titanic - Machine Learning from Disaster》 — Lincy's Blog&source=Titanic: Machine Learning from DisasterLibraries" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://lincy.online/2019/06/22/titanic_advanced/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Titanic - Machine Learning from Disaster》 — Lincy's Blog&url=https://lincy.online/2019/06/22/titanic_advanced/&via=https://lincy.online" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://lincy.online/2019/06/22/titanic_advanced/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/10/22/转载-领域驱动设计在互联网业务开发中的实践/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">[转载]领域驱动设计在互联网业务开发中的实践</h4>
      </a>
    </div>
  
</nav>



    





<section class="comments" id="comments">
    <div id="disqus_thread" align="center">
        <font style="color:#c8c8c8;font-weight:bold;">查看评论「请确保您的网络可以访问disqus.com」</font>
    </div>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>













</article>



</div>

        <footer class="footer">
    <div class="bottom">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
        <p><span>Lincy &copy; 2017 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a> 
                
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://lincy.online/2019/06/22/titanic_advanced/&title=《Titanic - Machine Learning from Disaster》 — Lincy's Blog&pic=https://lincy.online/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://lincy.online/2019/06/22/titanic_advanced/&title=《Titanic - Machine Learning from Disaster》 — Lincy's Blog&source=Titanic: Machine Learning from DisasterLibraries" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://lincy.online/2019/06/22/titanic_advanced/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Titanic - Machine Learning from Disaster》 — Lincy's Blog&url=https://lincy.online/2019/06/22/titanic_advanced/&via=https://lincy.online" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://lincy.online/2019/06/22/titanic_advanced/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACNklEQVR42u3aS3LjMAxFUe1/0+qpBxF1HyB1lcDLkSt2LJ4MEPyOA5/z51z9/Pfd8+Ksf+v33eONI0OGjM8yzuUh1yJU8po/9w+qDBkyNmBcRbCrz6TXXT+FUG/uLEOGDBnLdO0Eh4RmGTJkyHgj4N6kazjtI8FXhgwZMkgRuw64pJVGAK/X4jJkyPggg3fd///rV+YbMmTI+BTjDE/6bWkBXLyVDBkyRjN4gOONs2dTw+A+MmTI2IbBm1+1MFobdqLVMRkyZAxltPSNNlyaAt7cSoYMGaMZ5Opp2OWLFGmbDz1FhgwZQxk87NbGip0/R7ACIkOGjKGMNHSuL50ufhFYsC0iQ4aM0Yzahd5b1IgTTRkyZGzJqI0N0lFlp8S93BmRIUPGUEZaRpKCln++VsSiNQsZMmSMYPAgSErZ2gpsbdniCHwyZMiYwHhqMSL9nlpwD5YtZMiQMYLBW/k8svFBQn8VI55IyJAh4+OMtPjsp3rrsBu05GTIkDGawdOvtHDlLbZXUkkZMmSMYzzQ5AKFLklJW7W4DBkytmSkSxVpgtgZJ8iQIWNPBilr05FA2uZrLXbIkCFjKOMMT23ASdpnfMxw8x9DhgwZ4xidYWdntMCLVb7GIUOGjNmM/rIXJ5FAnA5KZciQsQ8jDXx8kFkbfPJSVoYMGTI6y15pw67VkpMhQ4aMxsJE2nQjax8PBFwZMmR8kMHTu9oI4dllCxkyZOzG4KVjZ+jYWTVLv1+GDBmDGP8AID1BzzmCmjUAAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script type="text/javascript">
    (function(){
        var storage = window.localStorage;
        if(storage.getItem('hide_menu')){
            var hide_menu = storage.getItem('hide_menu');
            if(hide_menu != 1){
                document.getElementById('top-menu').classList.add('disable');
                document.getElementById('menu').classList.remove('hide');
            }
        } else {
            storage.setItem('hide_menu', 1 );
        }
    })();
</script>
<script src="https://cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script src="/plugins/headroom.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



    <script type="text/javascript">
        var disqus_shortname = 'linchangyi';
    // lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
        $.ajax({
            url: '//' + disqus_shortname + '.disqus.com/embed.js',
            dataType: "script",
            timeout: 3000,
            success: function(){
                
                $('#comments').addClass('post-comments-card');
                
            }
        });
    </script>










<script src="/plugins/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

    
        <script type="text/javascript" alpha="0.2" src="/plugins/ribbon.min.js"></script>
    
    
        <script src="https://cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>
    
</body>
</html>
